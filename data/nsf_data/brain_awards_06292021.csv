"AwardNumber","Title","NSFOrganization","Program(s)","StartDate","LastAmendmentDate","PrincipalInvestigator","State","Organization","AwardInstrument","ProgramManager","EndDate","AwardedAmountToDate","Co-PIName(s)","PIEmailAddress","OrganizationStreet","OrganizationCity","OrganizationState","OrganizationZip","OrganizationPhone","NSFDirectorate","ProgramElementCode(s)","ProgramReferenceCode(s)","ARRAAmount","Abstract"
"2014217","NeuroNex: From Odor to Action: Discovering Principles of Olfactory-Guided Natural Behavior","DBI","PHYSICS OF LIVING SYSTEMS, Cross-BIO Activities, MATHEMATICAL BIOLOGY, MSPA-INTERDISCIPLINARY, Animal Behavior, CESER-Cyberinfrastructure for, Activation","09/01/2020","06/28/2021","John Crimaldi","CO","University of Colorado at Boulder","Continuing Grant","Sridhar Raghavachari","08/31/2025","$6,800,000.00","Brian Smith, Nathan Urban, Elizabeth Hong","crimaldi@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","BIO","7246, 7275, 7334, 7454, 7659, 7684, 7713","068Z, 8007, 8089, 8091, 9178, 9179, 9183","$0.00","The Odor2Action network consists of 16 investigators from 16 research institutions in the United States, the United Kingdom, and Canada. The composition and scientific goals of the effort are designed to leverage prior investments in neurotechnologies funded by the BRAIN Initiative, other domestic agencies and international partners. Specifically, Odor2Action will address a central question of neuroscience: How do animals use information from odor stimuli in their environment to guide natural behaviors? To synergistically study this problem, the network is subdivided into three interdisciplinary research groups (IRGs); each IRG contains experts in a wide range of experimental and theoretical approaches, and investigates how similar problems are solved by nervous systems in phylogenetically diverse species. IRG1 will test a novel framework for organizing olfactory stimulus space and olfactory codes around the statistical relationships among natural odors. IRG2 will work to understand how neural circuits translate odor signals into dynamic and adaptive behaviors, a critical component of our overall network goal of understanding how natural odors trigger natural behaviors. IRG3 will investigate the physical structure of odor environments and how animal motion and sensory capabilities interact with those environments to detect, discriminate and localize odor objects. Collectively, the network will determine how neural representations of odor are generated, how they are progressively reformatted across successive circuit layers, and how they support useful behaviors. While focusing on olfaction, this project will provide broad and fundamental insights into brain function. This compact circuit architecture associated with olfaction offers unique opportunities to achieve an end-to-end understanding of the core computational logic by which various brains organize and read out such high-dimensional, discrete variables to generate adaptive behaviors. This coordinated project on the neuroscience of olfaction across species will have important societal impacts in science, technology, health, and policy. Given the complexity and high dimensionality of chemical space and its primacy in driving behavior among most species, studying how odor leads to action promises to provide insight into optimal biological solutions for encoding complex information about the external world. Elucidating biological solutions to olfaction can inform the development of algorithms and engineered devices for detection and identification of chemicals in applications that span the range from homeland security to food safety.<br/><br/>The Odor2Action network will address a central question of neuroscience: How do animals use information from odor stimuli in their environment to guide natural behaviors? The network will approach this problem in the context of olfactory-guided behavior as an instance of a much more general problem of many complex brain systems - how are high-dimensional, discrete, and combinatorial variables that are not simply ordered along easily discernible axes represented in brain circuits and mapped to actions? The compact olfactory circuit architecture offers unique opportunities to achieve an end-to-end understanding of the core computational logic by which brains organize and read out such high-dimensional, discrete variables to generate adaptive behaviors. This network will study olfactory systems of mammals and insects, which have independently evolved common structural elements at successive levels of olfactory processing in their central nervous systems. These common elements possibly reflect convergent evolution towards a set of similar solutions to shared olfactory problems. The network comprises three interdisciplinary research groups (IRGs) that are designed around specific elements of an end-to-end investigation of olfaction. IRG1 aims to understand the first stages of how neural representations of odor are generated, and how they are progressively reformatted across successive circuit layers to support meaningful behaviors. IRG2 aims to understand how neural circuits translate odor signals into dynamic and adaptive behaviors, a critical component of our overall network goal of understanding how natural odors trigger natural behaviors. IRG3 will investigate the physical structure of odor environments and how animal motion and sensory capabilities interact with those environments to detect, discriminate and localize odor objects. Each IRG integrates theory and experimental approaches in two or more species in ways that produce complementary, synergistic interactions across levels of biological analysis. <br/><br/>This Neuronex award is co-funded by the Division of Emerging Frontiers and the Behavioral Systems Cluster within the Directorate for Biological Sciences, the Office of Advanced Cyberinfrastructure within the Directorate for Computer and Information Sciences, the Mathematical Biology Program and the Physics of Living Systems Program within the Directorate for Mathematical and Physical Sciences, as part of the BRAIN Initiative and NSF's Understanding the Brain activities.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1636893","BD Spokes: SPOKE: MIDWEST: Collaborative: Advanced Computational Neuroscience Network (ACNN)","IIS","BD Spokes -Big Data Regional I, IntgStrat Undst Neurl&Cogn Sys","09/01/2016","10/15/2020","Franco Pestilli","IN","Indiana University","Standard Grant","Alejandro Suarez","08/31/2022","$399,069.00","Olaf Sporns, Andrew Saykin, Lei Wang","pestilli@utexas.edu","509 E 3RD ST","Bloomington","IN","474013654","3172783473","CSE","024Y, 8624","028Z, 7433, 8083, 8089, 8091","$0.00","Novel neuroscience tools and techniques are necessary to enable insight into the building blocks of neural circuits, the interactions between these circuits that underpin the functions of the human brain, and modulation of these circuits that affect our behavior. To leverage rapid technological development in sensing, imaging, and data analysis new ground breaking advances in neuroscience are necessary to facilitate knowledge discovery using data science methods. To address this societal grand challenge, the project will foster new interdisciplinary collaborations across computing, biological, mathematical, and behavioral science disciplines together with partnerships in academia, industry, and government at multiple levels. The Big Data Neuroscience Spoke titled Midwest: Advanced Computational Neuroscience Network (ACNN) is strongly aligned with the national priority area of neuroscience and brings together a diverse set of committed regional partners to enable the Midwest region to realize the promise of Big Data for neuroscience. The ACNN Spoke will build broad consensus on the core requirements, infrastructure, and components needed to develop a new generation of sustainable interdisciplinary Neuroscience Big Data research. ACNN will leverage the strengths and resources in the Midwest region to increase innovation and collaboration for the understanding of the structure, physiology, and function of the human brain through partnerships and services in education, tools, and best practices. <br/><br/>The ACNN will design, pilot and support powerful neuroscientific computational resources for high-throughput, collaborative, and service-oriented data aggregation, processing and open-reproducible science. The ACNN Spoke framework will address three specific problems related to neuroscience Big Data: (1) data capture, organization, and management involving multiple centers and research groups, (2) quality assurance, preprocessing and analysis that incorporates contextual metadata, and (3) data communication to software and hardware computational resources that can scale with the volume, velocity, and variety of neuroscience datasets. The ACNN will build a sustainable ecosystem of neuroscience community partners in both academia and industry using existing technologies for collaboration and virtual meeting together with face-to-face group meetings. The planned activities of the ACNN Spoke will also allow the Midwest Big Data Hub to disseminate additional Big Data technologies resources to the neuroscience community, including access to supercomputing facilities, best practices, and platforms.<br/><br/>This award received co-funding from CISE Divisions of Advanced Cyberinfrastructure (ACI) and Information and Intelligent Systems (IIS)."
"2135859","CRCNS US-French Research Proposal: Advanced Spatiotemporal Statistical Models for Quantification and Estimation of Functional Connectivity: Q-FunC","IIS","IIBR: Infrastructure Innovatio, CRCNS-Computation Neuroscience","08/01/2021","06/28/2021","Alexander Petersen","UT","Brigham Young University","Standard Grant","Kenneth Whang","12/31/2023","$371,133.00","","petersen@pstat.ucsb.edu","A-285 ASB","Provo","UT","846021231","8014223360","CSE","084Y, 7327","1165, 7327, 8089, 8091","$0.00","Studies of functional neuroimaging data have provided compelling evidence that brains function as highly organized networks. This has prompted the need for computational and statistical tools to reliably construct networks from imaging data, and subsequently to discover patterns and differences between individuals or groups, for instance between cognitively normal subjects and others exhibiting particular pathologies.  The common approach to defining these networks is to compute temporal correlations between signals measured at distinct locations (voxels) in the brain, with stronger correlations corresponding to network connections.  Due to temporal trends and noise from physiological and other sources that can contaminate the measured signals, the seemingly simple task of quantifying functional connectivity between brain regions in fact requires careful statistical modeling and efficient computational tools in order to draw reliable inferences related to brain networks.  The primary aim of this project is to develop flexible statistical models of fMRI data that build on conventional correlation-based network construction to provide a more robust and complete picture of connectivity in the brain.  The project will develop a graphical user interface for computing and visualizing connectivity properties. And the project will provide trainees with extensive international collaborative experience. <br/><br/>The project consists of three parts.  In part 1, fMRI signals are modeled as a spatio-temporal process, where voxels within the same brain region share a common stochastic structure.  In contrast to conventional methods, the model does not assume stationarity of the process over time or perform a preliminary averaging of signals from voxels in the same region.  The removal of the stationarity assumption adds robustness to the method since such a property is unlikely to hold in experimental conditions.  Methods from functional data analysis allow for estimation using all voxel-wise data.  In part 2, a novel definition of functional connectivity is given that is parameter- and model-free.  For any two brain regions, the distribution of temporal correlations across all pairs of voxels within these regions constitutes their connectivity profile, and is termed the correlation density.  Methods for analyzing distributional data, including exploratory, clustering, and regression analyses, can be used to extract information from this rich representation.  Additionally, network analyses can still be performed as in conventional studies by evaluating specific quantiles of the correlation density, such as the median.  In part 3 of the project, validation of network construction through reliability and classification scores will be carried out on real data sets. These will include established data banks such as the Human Connectome Project, data gathered from small animals that have been anesthetized, and lesioned brains of individuals with consciousness disorders.<br/><br/>A companion project is being funded by the French National Research Agency (ANR).<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2011715","CRCNS US-French Research Proposal: Advanced Spatiotemporal Statistical Models for Quantification and Estimation of Functional Connectivity: Q-FunC","IIS","IIBR: Infrastructure Innovatio, CRCNS-Computation Neuroscience","01/01/2021","10/19/2020","Alexander Petersen","CA","University of California-Santa Barbara","Standard Grant","Kenneth Whang","07/31/2021","$388,943.00","","petersen@pstat.ucsb.edu","Office of Research","Santa Barbara","CA","931062050","8058934188","CSE","084Y, 7327","1165, 7327, 8089, 8091","$0.00","Studies of functional neuroimaging data have provided compelling evidence that brains function as highly organized networks. This has prompted the need for computational and statistical tools to reliably construct networks from imaging data, and subsequently to discover patterns and differences between individuals or groups, for instance between cognitively normal subjects and others exhibiting particular pathologies.  The common approach to defining these networks is to compute temporal correlations between signals measured at distinct locations (voxels) in the brain, with stronger correlations corresponding to network connections.  Due to temporal trends and noise from physiological and other sources that can contaminate the measured signals, the seemingly simple task of quantifying functional connectivity between brain regions in fact requires careful statistical modeling and efficient computational tools in order to draw reliable inferences related to brain networks.  The primary aim of this project is to develop flexible statistical models of fMRI data that build on conventional correlation-based network construction to provide a more robust and complete picture of connectivity in the brain.  The project will develop a graphical user interface for computing and visualizing connectivity properties. And the project will provide trainees with extensive international collaborative experience. <br/><br/>The project consists of three parts.  In part 1, fMRI signals are modeled as a spatio-temporal process, where voxels within the same brain region share a common stochastic structure.  In contrast to conventional methods, the model does not assume stationarity of the process over time or perform a preliminary averaging of signals from voxels in the same region.  The removal of the stationarity assumption adds robustness to the method since such a property is unlikely to hold in experimental conditions.  Methods from functional data analysis allow for estimation using all voxel-wise data.  In part 2, a novel definition of functional connectivity is given that is parameter- and model-free.  For any two brain regions, the distribution of temporal correlations across all pairs of voxels within these regions constitutes their connectivity profile, and is termed the correlation density.  Methods for analyzing distributional data, including exploratory, clustering, and regression analyses, can be used to extract information from this rich representation.  Additionally, network analyses can still be performed as in conventional studies by evaluating specific quantiles of the correlation density, such as the median.  In part 3 of the project, validation of network construction through reliability and classification scores will be carried out on real data sets. These will include established data banks such as the Human Connectome Project, data gathered from small animals that have been anesthetized, and lesioned brains of individuals with consciousness disorders.<br/><br/>A companion project is being funded by the French National Research Agency (ANR).<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1707398","NeuroNex Theory Team: Columbia University Theoretical Neuroscience Center","DBI","OFFICE OF MULTIDISCIPLINARY AC, STATISTICS, Cognitive Neuroscience, PHYSICS OF LIVING SYSTEMS, Cross-BIO Activities, MATHEMATICAL BIOLOGY, Activation","08/01/2017","06/01/2021","Laurence Abbott","NY","Columbia University","Cooperative Agreement","Sridhar Raghavachari","07/31/2022","$6,080,750.00","Kenneth Miller, Liam Paninski, Stefano Fusi, John Cunningham, Ashok Litwin-Kumar","lfa2103@columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","BIO","1253, 1269, 1699, 7246, 7275, 7334, 7713","8007, 8089, 8091, 9178, 9179, 9183","$0.00","Understanding how a healthy brain interprets sensory signals and guides actions, and why an unhealthy brain fails to perform these functions properly, is a profound and ambitious goal of 21st century science. Integrating knowledge of neural circuit function into a coherent picture of perception, cognition and action requires extraordinary cooperation and coordination between three research areas: experimentation, data analysis and modeling. The National Science Foundation Theory Team at Columbia University will unite exceptional resources in statistical data analysis and theoretical modeling with an extensive network of experimental collaborators to address the enormous challenges facing neuroscience. Never has the need been greater for theoretical insights and sophisticated data analysis. The field of neuroscience is facing a torrent of complex data from a system that is, itself, extraordinarily complex. Future progress requires developing the ability to extract knowledge and understanding from these data through analyses and modeling that capture the essence of what they mean. The goal of the NeuroNex Theory Team at Columbia is to establish, through the quality of its research, the excellence of its trainees, and the impact of its visitor, dissemination, and outreach programs, a new cooperative paradigm that will move neuroscience to unprecedented levels of discovery and understanding.<br/><br/>High-density electrode recording, wide-field calcium imaging and complex connectivity mapping are bringing neuroscience into an era of extensive multi-area and even whole-brain studies of neural activity and circuitry. The neuroscience community desperately needs new ways of interpreting data obtained from different species using myriad techniques and for thinking about neural processing over large length and time scales and across multiple brain areas. In response to these challenges, two major goals will drive and define research at the NeuroNex Theory Team at Columbia: first, integrating the analysis methods and theoretical models used to infer meaning from data with each other and with the experiments that generate these data; and second, providing analytic tools and theoretical frameworks to understand interactions between multiple brain regions and to draw important overarching lessons from experiments exploiting a variety of techniques across different species. Progress will be made through a tight integration of theoretical techniques with outstanding experimental collaborators working on a variety of systems and species. Graduate and postdoctoral training will stress technical excellence and broad perspectives in both theoretical and experimental neuroscience. Outreach will be made to other researchers through visitor and exchange programs, sponsored meetings and dissemination of research results and high-quality, user-friendly software. Outreach will be made to the broader community by sharing the excitement of neuroscience research with elementary and high school students and with the general public. This NeuroNex Theory Team award is co-funded by the Division of Emerging Frontiers within the Directorate for Biological Sciences, the Division of Physics and the Division of Mathematics within the Directorate of Mathematical and Physical Sciences, and by the Division of Brain and Cognitive Sciences within the Directorate of Social, Behavioral and Economic Sciences, as part of the BRAIN Initiative and NSF's Understanding the Brain activities."
"1822550","CRCNS Research Project: Solving the neural code of Hydra","EF","Cross-BIO Activities, CRCNS-Computation Neuroscience, Modulation","09/01/2018","07/14/2020","Adrienne Fairhall","WA","University of Washington","Continuing Grant","Edda Thiels","08/31/2022","$637,512.00","Rafael Yuste","fairhall@u.washington.edu","4333 Brooklyn Ave NE","Seattle","WA","981950001","2065434043","BIO","7275, 7327, 7714","7327, 8089, 8091, 9178, 9179","$0.00","One way to decipher a complex biological problem, such as understanding how the brain works, is by using a simpler system that enables greater experimental or computational access. Hydra is a small, transparent relative of the jellyfish, and represents the first animals to have evolved a nervous system. Correspondingly, the nervous system of Hydra is very simple, with a few hundred neurons forming a net which tiles the body of the animal, without ganglia or brain. In spite of this simplicity, Hydra's nerve net generates a rich range of nimble behaviors, including contracting, elongating, bending, searching and somersaulting. Recently, the investigators of this project developed genetically altered Hydra strains in which the activity of neurons and muscles causes them to generate a light signal. Thus, the investigators can directly observe the activation of every neuron and muscle cells in an animal while it is behaving. Because of this, they can use statistical methods to analyze how neural activity drives movements.  They discover basic principles of how simple nervous systems control muscles to produce behaviors. Given that Hydra has no brain, this project may reveal how complex movement can be organized without any central coordination. Further, Hydra has an extraordinary ability to regrow: its cells are constantly being replaced, and a complete Hydra body can reform from even very small pieces of the animal. Understanding how the nerve net of Hydra continues to produce stable behavior in the face of rapid turnover may advance understanding of how nervous systems can repair themselves. The study of Hydra with an integrated imaging/computational approach serves as an appealing platform for outreach opportunities.  The research introduces members of the general public to neuroimaging and essential biology and mathematical neuroscience.  It also provides training opportunities for researchers at all levels. The Hydra system is deeply integrated into summer courses at the Marine Biological Laboratory and provides cross-cutting projects for students from diverse backgrounds.<br/><br/>This project aims to decipher the relation between the activity of a nervous system, the muscles it controls and the behavior the muscles generate using the cnidarian Hydra. The investigators focus on decoding the neural basis of a few elementary behaviors that can be rigorously identified and that are generated by the endodermal and ectodermal nerve nets. The investigators use calcium imaging of every neuron and every muscle cell in mounted Hydra preparations during contractile behaviors. To analyze the required data sets, the investigators develop algorithms to track cells in the moving, deforming animal and apply dimensionality reduction methods to discover spatiotemporal patterns of movement corresponding to muscle activation patterns. The end product is a quantitative model that explains how contractile behaviors are generated. As another deliverable, the techniques developed to track neurons and discover spatiotemporal patterns are made widely available in an open source platform and may be of use in other systems. This proposed work will help establish Hydra as a model neural system for which a complete accounting of neural activity and behavior may be rigorously approached.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2014862","NeuroNex: Enabling Identification and Impact of Synaptic Weight in Functional Networks","DBI","Cross-BIO Activities, Modulation","08/15/2020","10/20/2020","Kristen Harris","TX","University of Texas at Austin","Continuing Grant","Edda Thiels","07/31/2025","$4,500,000.00","Mark Ellisman, Terrence Sejnowski, Robert Reid","kharris@mail.clm.utexas.edu","3925 W Braker Lane, Ste 3.340","Austin","TX","787595316","5124716424","BIO","7275, 7714","1228, 8089, 8091, 9178, 9179","$0.00","Trillions of synapses connect billions of neurons in neural circuits that allow sensation, thought, action, learning, and memory. This NeuroNex Network involves the development of new approaches to determine the strength of connections between neurons?synaptic weight--in the brain. Understanding synaptic weight is crucial, yet even a clear definition remains elusive, despite more than a century of searching. This NeuroNex Network assembles world experts to study synapses from molecules to behavior, to answer this fundamental and ambitious question: What constitutes synaptic weight, and what role does it play in shaping neural circuits? Synaptic weight is hypothesized to involve the differential composition and co-occurrence of key proteins and subcellular resources. Multidisciplinary approaches are used to assess these features in well-defined states of neural circuits involving multiple cell types, brain regions, and diverse behaviors. Consistent predictors of synaptic state are mapped onto neural connectomes to enhance understanding of how synaptic weight influences circuit organization and function. New electron microscopy technologies developed and used in this project bridge gaps in image size and resolution needed to achieve deeper understanding of brain function and regulation from nanoscale to circuit levels. A long-lasting, far-reaching impact involves leveraging work from this NeuroNex Network with other BRAIN Initiative projects to enable acquisition and sharing of the new knowledge. Future applications, even beyond the brain, of the knowledge and tools developed here will give rise to data that address fundamental and novel principles of complex self-organizing systems. The NeuroNex Network also involves training the next generation, including through inter-laboratory and fellow exchanges.<br/><br/>What constitutes synaptic weight, what role does it play in shaping neural circuits, and how does it change during growth and plasticity? Answers require a shift away from thinking about synapses as isolated entities. Synapses are not simply on or off one-bit machines; instead the information content stored in synapse size, as a proxy for weight, is much higher. Synaptic weight is controlled over broad temporal and spatial scales dynamically regulated by neural activity. New evidence points to subcellular resources (endoplasmic reticulum, mitochondria, endosomes, ribosomes) as brokers that drive synaptic efficacy and plasticity. This project seeks to understand how synapse composition and structure predict synaptic weight and function at a scale that reveals biological mechanisms at the subcellular level. A new 3D electron microscopy (EM) approach is developed using conical tilt tomography on the scanning EM operating in the transmission mode (tomoSEM). TomoSEM fills the current resolution-to-volume gap between methods of structural biology (high resolution, small volumes) and connectomics (relatively low resolution, larger volumes). TomoSEM eliminates major artifacts of other EM methods while reducing human effort and cost. The investigators comprise world experts in protein chemistry, cell biology, connectomics, and behavior. Experts in EM implement, validate, and deploy tomoSEM. Experts in image analysis, geometry, statistics, machine learning, and multilevel modeling create platforms to search data for hidden order. These strategies share international resources to overcome limits of accumulating data locally one synapse at a time. This project is co-funded by Emerging Frontiers in the Directorate for Biological Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1561214","Collaborative Research: Foundations of Quantitative Thought: Number, Space, Time, and Probability","DRL","ECR-EHR Core Research","07/01/2016","04/08/2021","Hilary Barth","CT","Wesleyan University","Standard Grant","Gregg Solomon","06/30/2022","$1,101,456.00","Andrea Patalano","hbarth@wesleyan.edu","237 HIGH ST","Middletown","CT","064593208","8606853683","EHR","7980","8089, 8091, 8817","$0.00","Humans have an innate ability to estimate quantities yet their intuitions often contain biases that interfere with learning new ways to think about quantity. Weaving together strands of psychology, neuroscience, economics, and education, researchers at Wesleyan University and Boston College shed light on the cognitive processes underlying our abilities to estimate 4 kinds of quantities: number, space, time, and probability. By comparing processes across these four distinct areas, the researchers aim to provide a unifying account of how children and adults estimate quantities, which has the potential to transform current understanding of the cognitive bases of how people learn in and across STEM disciplines. Achieving a simple unifying account is important because the ability to think well about quantity in all of these areas is fundamental to STEM learning. Other educational benefits include the establishment of partnerships with local museums that allow the research team to collect data from a diverse population while also supporting the museum's public education efforts. This project also contributes to STEM workforce development by training undergraduate students through a service-learning course offered at Wesleyan, and through a summer research internship exchange across the two universities. These aspects of the project, taken with its robust theoretical grounding, well-formulated research questions and tests of competing models of how people reason about quantity in childhood and adulthood, demonstrate its potential to guide and improve the design of STEM learning environments for all citizens.<br/><br/>This project exemplifies the Education and Human Resources Core Research program's commitment to fundamental research on learning in STEM that combines theory, techniques, and perspectives from a wide range of disciplines and contexts.  Specifically, it aims to provide a unifying account of how children and adults estimate quantities across four distinct domains: the development of numerical estimation; spatial categorization (remembering the location of items in space); the theoretical neuroscience of time processing (reproducing temporal durations); and decision making under risk (the processing of probabilities). Through a series of behavioral studies with adults and children, the researchers will test their hypothesis that proportion judgment underlies basic quantity estimation across these domains, across development, and across contexts (varying task constraints). This work is important because -- despite striking similarities in behaviors described across research in these literatures -- each one conceptualizes them quite differently, positing different accounts of the underlying mechanisms that yield quantity judgments. The project will advance and potentially transform our understanding of mental representations and processes involved in quantity judgments while also providing insight into how quantity biases may influence the processing of numerical information in educational contexts and real-life decisions. In this way the project builds a coherent, cumulative knowledge base, focusing on high-leverage topics."
"1845322","CAREER: From Connectome to Behavior: Computational Models of Multifunctional Neural Circuits in C. elegans","IIS","Robust Intelligence, IntgStrat Undst Neurl&Cogn Sys","09/01/2019","06/28/2021","Eduardo Izquierdo","IN","Indiana University","Continuing Grant","Kenneth Whang","08/31/2024","$623,969.00","","edizquie@indiana.edu","509 E 3RD ST","Bloomington","IN","474013654","3172783473","CSE","7495, 8624","1045, 7495, 8089, 8091, 9251","$0.00","How an animal flexibly coordinates multiple behaviors as a cohesive unit is one of the central problems of neuroscience; multifunctionality has also been recognized as one of the fundamental challenges in the development of a general artificial intelligence. Although the ability of neural circuits to flexibly reconfigure is widespread among organisms, most studies of the neural basis of behaviors focus on isolated circuits and individual behaviors. Studies that consider multifunctional circuitry tend to focus on the switching between distinct patterns of activity, with little insight into multifunctional sensorimotor integration. With the increasing amount of anatomical, physiological and behavioral data being generated, a computational modeling framework to understand the neural basis of behavior is essential. The goal of this project is to model multiple neural circuits that have been identified in isolation and to integrate them into a single model to better understand how multifunctionality arises in sensory-driven behavioral circuits. This project is an important step toward the long-term goal of developing a behaviorally-functional brain-body-environment model of a living organism at the level of individual neurons. The cross-disciplinary methodologies developed from this project will serve as a springboard for understanding multifunctional circuits in living organisms as well as for generating artificial systems capable of robustly and efficiently performing multiple functions. <br/><br/>The project focuses specifically on modeling and analyzing the circuits responsible for the wide range of spatial orientation behaviors in the nematode Caenorhabditis elegans. This model organism is a uniquely qualified target for integrated computational modeling of a complete animal because of the breadth of information known about its genetics, development, anatomy, and behavior. Despite this substantial knowledge, information about the electrophysiological properties of its nervous system is less complete. The project aims to constrain the model by what is known from the anatomy and physiology of the organism with reasoned simplifications about its body and environment. Then, stochastic optimization will be used to fill in electrophysiological unknowns such that the model produces behavior that matches what has been observed, including the effect of neural manipulations on behavior. The result of optimization will not be a unique model, but rather an ensemble of models that are consistent with current knowledge of the system. Each of these possibilities represents a testable hypothesis for C. elegans. The next step in the project will be to analyze the structure of this ensemble to formulate the key experiments that can distinguish between the various classes of possibilities in the worm. The results of such experiments can then be used as additional constraints for subsequent optimizations in an iterative cycle of model refinement. Besides the generation of experimentally-testable predictions that are specific to C. elegans, through the analysis of the ensemble of models, the project aims to discover general principles for how multifunctional circuits operate in living organisms more broadly.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2015317","NeuroNex: Communication, Coordination, and Control in Neuromechanical Systems (C3NS)","DBI","Cross-BIO Activities, Modulation","09/01/2020","10/20/2020","Roger Quinn","OH","Case Western Reserve University","Continuing Grant","Edda Thiels","08/31/2025","$3,200,000.00","Hillel Chiel, Charles Heckman, Matthew Tresch, Victoria Webster-Wood","rdq@po.cwru.edu","Nord Hall, Suite 615","CLEVELAND","OH","441064901","2163684510","BIO","7275, 7714","1228, 8089, 8091, 9178, 9179","$0.00","Despite the apparent differences between animals and their behaviors, they all are subject to the same constraints. All animals use a nervous system to control their motions, which must follow the laws of physics. Therefore, this NeuroNex Research Network seeks to understand how animals move by studying animals of different sizes and with unique evolutionary histories: Vertebrates (mice, rats, and cats), mollusks (sea hares), and insects (fruit flies). The differences between these species will inform how physics and evolution have shaped the nervous system. Understanding motion across different organisms and scales may lead to robots with more graceful, coordinated motion. Additionally, this Network enhances the training of American engineers and scientists by exchanging post-doctoral trainees and students between laboratories, providing them opportunities to work with different model organisms, and broadening the trainees? education. The activities of this Network enrich existing outreach programs through interactions with international, interdisciplinary collaborators and allow for new, larger initiatives. Public demonstrations, day camps, and internships carried out as part of this project expose K-12 students to interdisciplinary research and international collaborators? ideas and culture. This Network also constructs exhibits at natural science museums in its major cities and develops an interactive website describing how very different animals solve similar problems.<br/><br/>Animals move to seek food, mates, and shelter. In the phyla Arthropoda, Mollusca, and Chordata, the nervous system cephalized towards a higher-level brain and lower-level sensorimotor network. The brain would not exist without a body, and yet little is understood about how the nervous system controls and coordinates distributed body parts. Many fundamental questions remain unanswered: How is neural information encoded and communicated? How does the system correct for environmental perturbations? How do passive biomechanics affect the neuronal control of behavior? This leads to the foundational question: How do nervous systems control and execute interactions with the environment? This international Network of interdisciplinary research groups consists of modelers, engineers, and experimentalists to explore the Communication, Coordination, and Control of Neuromechanical Systems (C3NS). This NeuroNex Network investigates a foundational question in model genera from three phyla: adult Drosophila from Arthropoda, Aplysia from Mollusca, and small mammals from Chordata. Each interdisciplinary research group studies the control of a behavior in which the body interacts with the environment. Investigators explore how higher-level command centers (HLCCs) generate descending commands to lower-level motor centers (LLMCs), how LLMCs control the body to produce desired behavior, and how LLMCs generate ascending signals back to HLCCs. The animal models of C3NS allow the investigation of these questions across degrees of nervous system complexity and ranges of dynamic scale (i.e., size and speed) using the same conceptual modeling framework. This effort will create a bottom-up theory for how nervous systems control movement during environmental interactions. This project is co-funded by Emerging Frontiers in the Directorate for Biological Sciences and Robust Intelligence in the Directorate for Computer and Information Science and Engineering.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2100137","Collaborative Research: Learning Preferences and Domain Differences in Design Fixation","DRL","ECR-EHR Core Research","09/01/2021","05/21/2021","Evangelia Chrysikou","PA","Drexel University","Continuing Grant","Gregg Solomon","08/31/2024","$558,749.00","","lilachrysikou@drexel.edu","1505 Race St, 10th Floor","Philadelphia","PA","191021119","2158956342","EHR","7980","8089, 8091, 8817","$0.00","Learning to design in formal engineering and design education often involves the study of existing designs as examples. Research has shown that the use of pictorial examples during the presentation of design problems can support the learning of engineering principles and design constraints. But it can also bias designers and engineering design students toward replicating the examples they were shown, even in the presence of explicit instructions not to do so, rather than seeking innovative alternative solutions. This phenomenon is known as design fixation?the tendency to adhere to elements of prior ideas or solutions to a problem. Design fixation is a significant barrier to the generation of new design ideas and creative problem solving. Intriguingly, preliminary research on engineering education has suggested there is a disciplinary difference in the tendency to show design fixation to pictorial examples, such that industrial designers are markedly less likely to fixate than are mechanical engineers. The goal of this project, a collaboration between cognitive neuroscience researchers at Drexel University and design scientists at the University of North Carolina, is to focus on this difference as a means of understanding the cognitive and neural processes underlying design fixation. The driving hypothesis is that, as a result of their training, mechanical engineering students are more likely to fixate because they are less apt to draw on abstract principles. The studies will involve a combination of behavioral and brain imaging studies of first year and fourth year undergraduate students in different design disciplines. The results of this project will have the potential to generalize across much of STEM education by informing the development of curricula to ward off design fixation. This award is made by the EHR Core Research (ECR) program, which supports work that advances the fundamental research literature on STEM learning.<br/><br/>Drawing on the research literature in cognitive science, cognitive neuroscience, engineering education, and design science, this project will examine the premise that there are differences between undergraduate industrial design and mechanical engineering students in their tendencies to show design fixation and that these differences are arise from instruction that emphasizes the of abstraction (rule-based) learning in the former discipline and exemplar-based learning in the latter. The project will examine whether differences between students during concept building, captured by both behavioral and neural measures, can predict design fixation patterns. The researchers will collect multimodal data from first year and senior industrial design and mechanical engineering students on a design fixation task and a control design task. They will quantify design fixation behaviorally through (a) the coding of sketches according to an established design categorization scheme, and (b) the coding of verbal protocols with the established Function-Behavior-Structure (FBS) ontology for design. The FBS ontology segmentation and coding of verbal protocols will then be used in a novel attempt to analyze neural responses during the design fixation and control tasks. The behavioral and neural differences in learning tendencies ? rule-based and exemplar based ? between students in the two disciplines will then be used to predict behavioral and neural differences in design fixation. Ultimately, the investigators aim to put forth a mechanistic account of design fixation, grounded in cognitive neuroscience and design theory and practice, that will inform the development of instructional interventions.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1608111","US-German Collaboration: Testing Muscle Synergies in a Neuromechanical Rat Model for Nominal and Perturbed Locomotion","IIS","Cross-BIO Activities, CRCNS-Computation Neuroscience, Robust Intelligence, Dynamics, Control and System D","09/01/2016","09/06/2017","Roger Quinn","OH","Case Western Reserve University","Continuing Grant","Kenneth Whang","08/31/2021","$584,136.00","Hillel Chiel","rdq@po.cwru.edu","Nord Hall, Suite 615","CLEVELAND","OH","441064901","2163684510","CSE","7275, 7327, 7495, 7569","5936, 7327, 8089, 8091","$0.00","This project focuses on the neural and biomechanical principles that result in dynamic stability during locomotion. Medical treatments and diagnosis for neurological conditions that affect balance and coordination (e.g. spinal cord injury, stroke, Parkinson's) can be improved with a better understanding of mammalian spinal cord circuits. Neuromechanical models will also inspire improvements to the design of mechanical systems and controllers for assistive exoskeletons for human stability and mobility. For example, such a neural model could be effective for controlling a person's muscles in tandem with control of an exoskeleton's motors and with the person's intact systems. Control systems derived from this work may also provide autonomous legged robots greater mobility and adaptability for movement in unknown terrain.  This project will also involve international collaboration and interdisciplinary education and training at the intersection of neurobiology, zoology, mechanical engineering, and system control.<br/><br/>To better understand how the mammalian nervous system processes multi-sensory feedback for dynamic control of the many degrees of freedom in the rear legs, the investigators will: 1) Use simultaneous two-plane X-ray videography, force plates and EMG recordings to measure the kinematics, ground reaction forces, and muscle activations of rats running in various environments (treadmills of different speeds and flexibility, and on substrates with unexpected disturbances such as holes, a trapdoor and a shifting ground condition); 2) Use these data to  expand a sagittal plane biomechanical model and conductance-based neural model of the rat to produce self-supporting walking of the hind legs in three dimensions; and 3) Investigate mechanisms for control of synergistic muscle groups by exploring different organizational models and testing the capability of these models for adapting to perturbations and maintaining dynamic control of walking behavior.<br/><br/>A companion project is being funded by the Federal Ministry of Education and Research, Germany (BMBF)."
"1734853","NCS-FO: Connectome mapping algorithms with application to community services for big data neuroscience","BCS","CESER-Cyberinfrastructure for, IntgStrat Undst Neurl&Cogn Sys","09/01/2017","08/07/2017","Franco Pestilli","IN","Indiana University","Standard Grant","Jonathan Fritz","08/31/2021","$650,000.00","Ivo Dinov, Lei Wang, Robert Henschel, Eleftherios Garyfallidis","pestilli@utexas.edu","509 E 3RD ST","Bloomington","IN","474013654","3172783473","SBE","7684, 8624","040Z, 8089, 8091, 8551","$0.00","Neuroscience is advancing by dissolving disciplinary boundaries and promoting transdisciplinary research between psychologists, cognitive neuroscientists, computer scientists, and engineers, to name a few. The success of this scientific endeavor would be enhanced by establishing software mechanisms to improve reproducibility of scientific results. This project develops a software platform that facilitates publication of publicly-accessible data and implementation of data-analysis algorithms. Both functions will be achievable within high-performance computing environments. The platform will enable publication of reproducible code, and access to national supercomputers. It will also make available reference datasets for validating results and data quality. It is expected that the open online platform will promote voluntary data submissions in exchange for access to the system. In addition, this platform will provide a reusable database of ""data derivatives,"" which are data at different stages of preprocessing, including cortical segmentations, meshes, functional maps, brain connectivity matrices, or white-matter tracts. This open-derivatives database will allow computer scientists, mathematical scientists and engineers to use these data to develop and improve methods in their domains. Most generally, providing easy-to-use published data and methods will promote understanding the brain and allow diverse communities of scientists to use reproducible methods, and reuse the ""long tail"" of neuroimaging data.<br/><br/>The project focuses on providing seamless public access to data, computing, and reproducible algorithms, while promoting code sharing and upcycling the long tail of neuroscience data. It has three main objectives. First, to develop a platform to capture brain data, publish algorithms as reproducible applications, and perform data-intensive computing on high-performance compute clusters, as well as public clouds. Second, to develop novel algorithms for mapping brain-connectome individuality and variability. The algorithms will enhance discovery by leveraging the online platform for data intensive processing of large datasets. Third, to collate a large data set of brain data and data derivatives (processed data), such as connectome matrices, multi-parameters tractography models, cortical segmentation and functional maps. These derivatives will benefit scientists to develop algorithms for functional mapping, anatomical computing, and model optimization. This project is funded by Integrative Strategies for Understanding Neural and Cognitive Systems (NSF-NCS), a multidisciplinary program jointly supported by the Directorates for Computer and Information Science and Engineering (CISE), Education and Human Resources (EHR), Engineering (ENG), and Social, Behavioral, and Economic Sciences (SBE). It has also received funding from the CISE Office of Advanced Cyberinfrastructure."
"1908299","III: Small: Modeling Multi-Level Connectivity of Brain Dynamics","IIS","Info Integration & Informatics, IntgStrat Undst Neurl&Cogn Sys","10/01/2019","06/23/2021","Ruogu Fang","FL","University of Florida","Standard Grant","Wei-Shinn Ku","09/30/2022","$532,000.00","Mingzhou Ding","ruogu.fang@bme.ufl.edu","1 UNIVERSITY OF FLORIDA","GAINESVILLE","FL","326112002","3523923516","CSE","7364, 8624","7364, 7923, 8089, 8091, 9251","$0.00","The temporal dynamics of blood flows through the network of cerebral arteries and veins provides a window into the health of the human brain. Since the brain is vulnerable to disrupted blood supply, brain dynamics serves as a crucial indicator for many kinds of neurological diseases such as stroke, brain cancer, and Alzheimer's disease. Existing efforts at characterizing brain dynamics have predominantly centered on 'isolated' models in which data from single-voxel, single-modality, and single-subject are characterized. However, the brain is a vast network, naturally connected on structural and functional levels, and multimodal imaging provides complementary information on this natural connectivity. Thus, the current isolated models are deemed not capable of offering the platform necessary to enable many of the potential advancements in understanding, diagnosing, and treating neurological and cognitive diseases, leaving a critical gap between the current computational modeling capabilities and the needs in brain dynamics analysis. This project aims to bridge this gap by exploiting multi-scale structural (voxel, vasculature, tissue) connectivity and multi-modal (anatomical, angiography, perfusion) connectivity to develop an integrated connective computational paradigm for characterizing and understanding brain dynamics.<br/><br/>The approach consists of three thrusts: (1) multi-scale structural connectivity modeling to quantify brain dynamics beyond a single voxel; (2) multimodal dynamic dictionary learning for mining hidden complementary information; and (3) multicenter evaluation to assess the efficacy of the proposed models at three nationally renowned healthcare systems. Successful project completion would potentially transform the rapidly evolving field of brain dynamics modeling, facilitate basic neuroscience discovery and enable comprehensive identification of neurovascular diseases. Aiming to broaden its impact this project will also implement educational initiatives to expose students, middle school teachers, and medical professionals to 'CS for All,' to foster interests in STEM and cross-disciplinary careers, and to promote research on the convergence of computer science and computational thinking for brain health and neuromedicine.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1528214","CHS: Small: A Novel P300 Brain-Computer Interface","IIS","HCC-Human-Centered Computing, IntgStrat Undst Neurl&Cogn Sys","10/01/2015","06/23/2021","Virginia de Sa","CA","University of California-San Diego","Continuing Grant","Ephraim Glinert","09/30/2021","$504,431.00","","vdesa@cogsci.ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930934","8585344896","CSE","7367, 8624","7367, 7923, 8089, 8091, 9251","$0.00","Brain computer interfaces (BCIs) translate basic mental commands into computer-mediated actions, thereby allowing the user to bypass the peripheral motor system and interact with the world directly via brain activity.  These systems are being developed to aid users with motor deficits stemming from neurodegenerative disease, injury, or even environmental restrictions which make movement difficult or impossible.  One of the most successful classes of EEG-driven BCI systems is the P300, which works by detecting user responses to flashed stimuli.  In most P300 systems, a grid of letters and/or other symbols is presented and rows or columns of the symbols are flashed in random order; the user attends to the desired symbol (usually by silently counting when it flashes).  A major problem with these grid-based P300 systems is that the user must ideally look at the flashed target and minimally attend to the tiny letters, but late-stage ALS and other locked-in patients for whom these systems are most needed have trouble foveating targets and making controlled eye movements.  The PI's hypothesis is that a BCI that flashes segments of one large letter can retain the combinatorial efficiency that comes with querying several letters at once, while having the advantage of one central focus (no gaze shifts required).  This research aims to design and test this new segment speller idea.  Project outcomes have the potential to vastly improve the usability of P300 EEG-based BCI systems for those with visual, sensory and motor impairments.  All software written for EEG signal processing and analysis will be made available as add-ons to EEGLAB which is distributed by the Swartz Center for Computational Neuroscience (SCCN) at UCSD and part of the Temporal Dynamics of Learning Center.  Data will also be made available through the HeadIT data archive that is also run by the SCCN.<br/><br/>This research task can be broken down into three main objectives: develop and test the response to flashed segments; improve the single-trial classification of the responses to flashed segments; and design a logic for selecting segments and interpreting their responses.  The developed system will provide another method for BCI speller control that does not depend on the ability to shift gaze.  The PI argues that this method will have a higher information transfer rate than other space invariant BCI spellers due to being able to probe multiple letters at once.  Besides being advantageous for those with impaired eye movements and/or impaired vision, the method should have other advantages over the standard P300 systems.  When errors are made, they will tend to be to visually similar symbols. Incorporating language priors and active segment selection is easily accommodated, and this may result in higher information transfer rates with slower flash rates.  In addition the work on improving recognition of single-trial temporal EEG signals and incorporating Bayesian language models into spellers could be useful for other types of brain-computer interfaces."
"1747506","EAGER:  Engineering electrical synapses in a sensorimotor circuit","CBET","Engineering of Biomed Systems","09/01/2017","07/25/2017","Catherine von Reyn","PA","Drexel University","Standard Grant","Stephanie George","08/31/2021","$200,000.00","","crv33@drexel.edu","1505 Race St, 10th Floor","Philadelphia","PA","191021119","2158956342","ENG","5345","7916, 8089, 8091, 9102","$0.00","As scientists work to regrow nerves and replace connections in damaged nerves, the ability to create and direct the connection, or synapse, between the nerve and next structure remains illusive. To date, pharmacological treatments and neural implants show promise in generating new synaptic connections; however, neither offers control over where synapses are established. Because a neural circuit's function relies a precise connection, a need exists to generate targeted synaptic connections as part of neural circuit repair. This project focuses on how to correctly pair neurons and differentiate these connections into functionally relevant synapses. Genetic engineering is already utilized to determine how neural circuits assemble and generate behavior.  Building on this basic neuroscience research, this work will repurpose genetic engineering tools to achieve a novel goal: engineering neural circuits. These results will develop tools to precisely manipulate neural connections and establish key principles for designing connections to have intended functional behavioral outcomes. This will lay the groundwork for genetic therapies to restore function to injured and diseased circuits thereby enhancing quality of life and reducing financial burden on our healthcare system. Undergraduate students will be integrated into the research team and a biomedical engineering learning series will be developed for juniors at a local high school that serves at risk and underrepresented minority students.  The goal of both will be to improve interest and retention in STEM, in particular in biomedical engineering.<br/><br/>Proteins that bind across a synapse, including gap junction subunits connexins, show promise for selective pairing and electrical synapse formation. When expressed ectopically, their homophilic interactions can generate novel connections in vertebrate and invertebrate nervous systems. However, functional characterization of these putative electrical synapses remains limited. Here, the capacity for exogenous connexins (Cx36) to selectively engineer functional synapses will be investigated within an escape circuit of Drosophila melanogaster that contains the required genetic tractability to deliver genes to pre- and postsynaptic candidate neurons and neural accessibility to determine functional and behavioral consequences of engineering new connections. Synaptic function will be assessed through immunolabeling, optogenetics, in vivo whole-cell electrophysiology, and detailed behavioral analysis."
"1718853","RI: Small: Collaborative Research: A Topological Analysis of Uncertainly Representation in the Brain","IIS","Robust Intelligence, IntgStrat Undst Neurl&Cogn Sys","08/15/2017","08/04/2017","Junzhou Huang","TX","University of Texas at Arlington","Standard Grant","Rebecca Hwa","07/31/2021","$210,000.00","","jzhuang@uta.edu","701 S Nedderman Dr, Box 19145","Arlington","TX","760190145","8172722105","CSE","7495, 8624","7495, 7923, 8089, 8091","$0.00","Characterizing how brain regions activate, collaborate, and interact in cognition empowers us with advanced approaches to help humans make the right decisions on high stress jobs, prevent drug abuse, and treat neurological disorders. This project will study cognitive control in terms of the uncertainty representation, namely, how brains execute the same cognitive task with different levels of uncertainty. Based on theory and algorithms in topology data analysis, the project will analyze brain functional MRI images using novel topological descriptors, which directly model global interactions between brain regions in a principled manner. These descriptors will be used in novel learning models to discover brain activity patterns that are crucial for uncertainty representation. The outcome of the project will include (1) new knowledge in uncertainty representation, e.g., fine-scale activity patterns and interactions between brain regions correlated to the uncertainty level; (2) new topological analysis tools for brain imaging study. This project will bring research and educational opportunities to graduate and undergraduate students from both computer science and neuroscience. The PIs will also mentor students from underrepresented groups and high school students through the CUNY College Now program.<br/><br/>This project will create new computational topology algorithms to extract rich information from the intrinsic structure of data. Novel machine learning methods will be created in order to leverage the topological structures for not only prediction, but also knowledge discovery. A novel interactive data exploration platform based on topological features will be developed for brain imaging study. These techniques and software will be validated on task-evoked fMRI data to produce quantitative assessments of accuracy and to characterize advantages and limitations of these approaches. Domain experts will validate the quality of the approach in validating scientific hypotheses and data exploration."
"1652943","CAREER: Robust Brain Imaging Genomics Data Mining Framework for Improved Cognitive Health","IIS","Info Integration & Informatics","02/15/2017","06/21/2021","Hua Wang","CO","Colorado School of Mines","Continuing Grant","Sylvia Spengler","01/31/2022","$497,641.00","","huawang@mines.edu","1500 Illinois","Golden","CO","804011887","3032733000","CSE","7364","1045, 7364, 8089, 8091, 9251","$0.00","The goal of this CAREER project is to identify and establish a new robust data mining framework for better modeling, understanding and analyzing brain imaging genomics data that combine the concepts of sparsity-induced learning models and new and more efficient computational algorithms. The proposed research in this project is innovative and crucial not only to facilitating the development of new data mining techniques, but also to addressing emerging scientific questions in brain imaging genomics, and to greatly supporting the BRAIN Initiative which has recently been unveiled by the U.S. Government and become a national goal. Integrated with the research in this project are the educational goals to create and broadly disseminate new curricular and K-12 outreach materials that focus both on the challenges of large-scale, heterogeneous-modal and high dimensional data processing and on the principles behind the robust data mining techniques for alleviating them.<br/><br/>This project focuses on designing principled data mining algorithms for analyzing multi-modal brain imaging genomics data to yield mechanistic understanding from gene to brain function and to phenotypic outcomes. Of particular interests are (1) large-scale non-convex sparse learning models with linear convergence algorithms, (2) linear computational cost multi-task multi-dimensional data integration algorithms, and (3) evaluation and validation in large-scale brain imaging genomics studies. The research in this project will enable new computational applications in a large number of research areas. The educational materials developed as part of this project will give K-12 students a taste of some of the many fascinating topics in the machine learning and data mining fields while communicating to students the relevance of their mathematics and science classes to futures in engineering."
"1707356","NeuroNex Technology Hub: Enhanced resolution for 3DEM analysis of synapses across brain regions and taxa","DBI","Cross-BIO Activities, CESER-Cyberinfrastructure for","08/01/2017","06/08/2021","Kristen Harris","TX","University of Texas at Austin","Cooperative Agreement","Reed Beaman","07/31/2022","$7,890,003.00","James Carson","kharris@mail.clm.utexas.edu","3925 W Braker Lane, Ste 3.340","Austin","TX","787595316","5124716424","BIO","7275, 7684","8089, 8091","$0.00","As part of the NSF National Research Infrastructure for Neuroscience, this Neurotechnology Hub will develop new approaches to examine the brain in greater detail. Three-dimensional electron microscopy (3DEM) has helped reveal new insights into the role of tiny connections between cells in the brain.  However, 3DEM has been limited in impact by the rate of data analysis.  This Neurotechnology Hub will improve the 3DEM instrumentation to collect information in greater detail, develop better algorithms to process the information, and link the workflows with high performance computing to greatly increase the rate of knowledge discovery. These innovations and capabilities will be shared with the scientific community through active training on the approach, and through open access to the new software and data. By way of this Neurotechnology Hub, 3DEM will become part of the national infrastructure for neuroscience research. To help address the grand scientific challenge of understanding the brain, this project will apply the improved 3DEM approach across several different mammalian species including humans to identify similarities and differences, and their relationship to behavior, learning, and memory.<br/><br/>This Neurotechnology Hub is motivated by challenges in understanding synapses, the tiny points of inter-neuronal communication. The variance in synapse dimensions, connectivity, and subcellular content across species is simply not known, yet required to determine whether model systems represent human brain functions. Current approaches are limited by resolution, inefficient data collection, and analysis bottlenecks. Addressing these challenges, the project will: (1) Develop simultaneous multi-detector and tilt-tomography on the scanning electron microscope operating in the transmission mode. Add-on hardware and software will improve axial resolution from 45 to 10 nm (or less), while maintaining in-plane resolution of 1-2 nm. (2) Integrate automated and interactive tools that speed and improve analysis of synapses in large data volumes. The enhanced resolution will increase data volume but reduce major image processing difficulties by producing more isotropic images. (3) Integrate the enhanced electron microscopy (EM) with high performance computing to increase throughput; to disseminate images, metadata, analyses, and software in a way that facilitates uptake into existing cell type and brain databases; and to provide a venue to develop 3DEM communities. (4) Apply the new technology to image hippocampus and comparable parts of cortex in mice, rats, and humans.  This NeuroTechnology Hub award is co-funded by the Division of Emerging Frontiers within the Directorate for Biological Sciences and the Office of Advanced Cyberinfrastructure within the Directorate for Computer and Information Sciences, as part of the BRAIN Initiative and NSF's Understanding the Brain activities."
"1231216","A Center for Brains, Minds and Machines: the Science and the Technology of Intelligence","CCF","STC Integrative Partnrshps Adm, Information Technology Researc, STCs-2013 Class","09/01/2013","07/27/2020","Tomaso Poggio","MA","Massachusetts Institute of Technology","Cooperative Agreement","Phillip Regalia","08/31/2023","$40,359,625.00","Ellen Hildreth, Haym Hirsh, Lakshminarayana Mahadevan, Matthew Wilson, Gabriel Kreiman","tp@ai.mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","1297, 1640, 7202","8089, 8091, 9171, 9218, 9251","$0.00","Today's AI technologies, such as Watson, Siri and MobilEye, are impressive yet still confined to a single domain or task. Imagine how truly intelligent systems --- systems that actually understand their world --- could change our world.  The work of scientists and engineers could be amplified to help solve the world's most pressing technical problems. Education, healthcare and manufacturing could be transformed.  Mental health could be understood on a deeper level, leading in turn to more effective treatments of brain disorders.  These accomplishments will take decades.  The proposed Center for Brains, Minds, and Machines (CBMM) will enable the kind of research needed to ultimately achieve such ambitious goals. The vision of the Center is of a world where intelligence, and how it emerges from brain activity, is truly understood. A successful research plan for realizing this vision requires four main areas of inquiry and integrated work across all four guided by a unifying theoretical foundation. First, understanding intelligence requires discovering how it develops from the interplay of learning and innate structure. Second, understanding the physical machinery of intelligence requires analyzing brains across multiple levels of analysis, from neural circuits to large-scale brain architecture. Third, intelligence goes beyond the narrow expertise of chess or Jeopardy-playing computers, bridging several domains including vision, planning, action, social interactions, and language. Finally, intelligence emerges from the interactions among individuals ? it is the product of social interactions. Therefore, the research of the Center engages four major research thrusts (Reverse Engineering the Infant Mind, Neuronal Circuits Underlying Intelligence, Integrating Intelligence, and Social Intelligence) with interlocking teams and working groups, and a common theoretical, mathematical, and computational platform (Enabling Theory).<br/><br/>The intellectual merit of the Center is its focus on elucidating the mechanisms and architecture of intelligence in the most intelligent system known: the human brain.  Success in this project will ultimately enable us to understand ourselves better, to produce smarter machines, and perhaps even to make ourselves smarter. The Center's potential legacy of a deep understanding of intelligence, and the ability to engineer it, is tantalizing and timeless. It includes the creation of a community of researchers by programs such as an intensive summer school, technical workshops and online courses that will train the next generation of scientists and engineers in an emerging new field -- the Science and Engineering of Intelligence. This new field will catalyze continuing progress in and cross-fertilization between computer science, math and statistics, robotics, neuroscience, and cognitive science. Sitting between science and engineering, it will attract growing interest from the best students at all levels.  The broader impact of the Center program could be to revolutionize K-12, and also 0-K, and 12-life with a deeper understanding of the process of learning.  The ability to build more human-like intelligence in machines will transform our productivity, enabling robots to care for the aged, drive our cars, and help with small-business manufacturing. The Center team is composed of over 23 investigators, many having already made significant accomplishments in multiple research areas relevant to the science and the technology of intelligence. The Center team has a mix of junior and senior researchers, bringing expertise in Computer Science, Neuroscience, Cognitive Science and Mathematics. The institutional partners include nine institutions (MIT, Harvard, Cornell, Rockefeller, UCLA, Stanford, The Allen Institute, Wellesley, Howard, Hunter and the University of Puerto Rico), three of which have significant underrepresented student populations. The academic institutions are complemented by the Center's industrial partners (Microsoft, IBM, Google, DeepMind, Orcam, MobilEye, Willow Garage, RethinkRobotics, Boston Dynamics) and by world-renowned researchers at international institutions (Max Planck Institute, The Weizmann Institute, Italian Institute of Technology, The Hebrew University)."
"1753840","CIF21 DIBBs: EI: North East Storage Exchange","OAC","ADVANCES IN BIO INFORMATICS, XD-Extreme Digital, Data Cyberinfrastructure","07/01/2017","10/10/2017","James Cuff","MA","Trustees of Boston University","Standard Grant","Amy Walton","09/30/2022","$3,846,298.00","","james_cuff@harvard.edu","881 COMMONWEALTH AVE","BOSTON","MA","022151300","6173534365","CSE","1165, 7476, 7726","7433, 8048, 8089, 8091","$0.00","Research progress is increasingly dependent upon the available capacity of storage to flexibly exploit large volumes of digital information.  The North East Storage Exchange (NESE) project creates a next-generation storage infrastructure specifically targeted at enabling new levels of collaborative research in projects regularly involving petabytes of information.  This storage exchange will integrate with a computational and network infrastructure that links Harvard University, Boston University, the Massachusetts Institute of Technology (MIT), Northeastern University and the University of Massachusetts system.  This project contributes to building a national data infrastructure to support advanced research in such priority topics as health care, epidemiology, physics, and earth science, among others.<br/><br/>NESE will provide a high capacity, highly networked, secure, cost effective, scalable, and accessible data store that lowers barriers to research, collaboration, and information sharing within and beyond the participating multi-university community. Some examples of NESE projects that will be early users of NESE include one of the four US Tier 2 centers that store and process ATLAS data from the Large Hadron Collider; the Center for Brain Science at Harvard University, which is generating 300 million micron-resolution images to map the billion neurons and synapses that make up a cubic millimeter of the human brain; and MIT collaborations with NASA and DARPA in next generation global ocean modeling and monitoring systems.  NESE addresses several critical infrastructural challenges: the creation of a sustainable multi-institutional resource; advancement of methods for data retention, management, and access to sensitive research data; implementation of controls that simplify protection of sensitive data; and building a sustainable, collaborative operating infrastructure to support future research.<br/><br/>This award by the Advanced Cyberinfrastructure Division is jointly supported by the NSF Directorate for Biological Sciences (Division of Biological Infrastructure), and by NSF's Understanding the Brain and BRAIN initiative activities."
"1920682","Collaborative Research: Measuring and Enhancing Scientific Creative Thinking for STEM Education and Research: Classroom-Aligned Assessment and Network Neuroscience-Based Mechanisms","DRL","ECR-EHR Core Research","09/01/2019","07/16/2020","Adam Green","DC","Georgetown University","Continuing Grant","Gregg Solomon","08/31/2022","$459,874.00","","aeg58@Georgetown.edu","37th & O St N W","Washington","DC","200571789","2026250100","EHR","7980","7261, 8089, 8091, 8817","$0.00","This collaborative award to research teams at Pennsylvania State University, Georgetown University, and Johns Hopkins University will focus on creative thinking in STEM education and research.  Creative thinking is critical for success in STEM fields, which often require generating novel hypotheses, flexibly connecting diverse information, and envisioning solutions to ill-defined problems. Creative innovation is a valuable attribute of the U.S. workforce in the global economy, and the ability to maximize the nation's creative potential is projected to become even more essential for opportunity as creativity emerges as the human ability least achievable by artificial intelligence. The increasing value of creative thinking for STEM coincides with new applications of neuroscience methods that have the potential to predict, and perhaps even to enhance, creativity. Yet creativity is an under-researched contributor to STEM success. Indeed, there is not currently a measure of scientific creative thinking that educators can use to reliably determine what works (and what does not) in STEM education to foster creative thinking. This project will bring together a research team that represents an uncommon bridging of neuroscience and classroom-focused expertise. They will work with middle school and university educators to develop a new measure of scientific creative thinking and to use new neuroscientific tools to test whether a brain network that predicts an individual's general capacity for creative thinking can also predict their ability to think creatively with scientific content beyond what can be explained by their baseline cognitive ability. By testing whether neural data add value to traditional academic measures in predicting students' future creative thinking and STEM performance, this project will inform timely debates on the value of neuroscience for education. This work will also bridge the laboratory and the classroom in novel ways by longitudinally measuring change in brain network strength associated with of real-world STEM learning. By providing foundational knowledge on the nature and measurement of scientific creative thinking, the project will inform educational efforts to promote creative thinking in the classroom. This project will have additional impacts for broadening participation in STEM Fields by working with teachers of minority student populations underrepresented in STEM fields to optimize classroom usability for a test of scientific creative thinking. The project is funded by the EHR Core Research (ECR) program, which supports work that advances the fundamental research literature on STEM learning. The project directly fits the intent of ECR to facilitate the development, refinement, and testing of new education research, measurement, and evaluation methodologies.<br/><br/><br/>This project aims to provide foundational knowledge on the cognitive and neural basis of scientific creative thinking. To this end, we will collaborate with educators to develop and psychometrically validate a new test of scientific creative thinking, assessing students' ability to generate novel hypotheses, research questions, and experimental designs. We will also leverage developments in the network neuroscience of domain-general creativity, including the recent discovery of a specific network of brain regions in which functional connectivity strength can predict an individual's creative performance. Specifically, the project will 1) construct a new assessment of scientific creative thinking, incorporating classroom-usability (working with STEM teachers in urban Baltimore) and expanded psychometric scale development, and 2) use functional magnetic resonance imaging (fMRI) to extend our recent findings on the functional brain networks that support domain-general creativity to identify neural overlap/distinctness between domain-general and scientific creativity, and longitudinally to test whether strength of neural networks adds value to standard academic measures (e.g., grades) in predicting future creative thinking and STEM performance. This study will also provide the first large-scale analysis of cognitive and affective traits that support scientific creative thinking in STEM undergraduates, as well as preliminary data on whether network neuroscience methods developed in the lab can be used to measure neural strengthening of creative thinking ability through real-world STEM learning.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1840677","NeuroDataRR. Collaborative Research: Testing the relationship between musical training and enhanced neural coding and perception in noise","BCS","Cognitive Neuroscience, IntgStrat Undst Neurl&Cogn Sys","09/15/2018","08/29/2019","Anne Luebke","NY","University of Rochester","Standard Grant","Betty Tuller","08/31/2022","$191,670.00","Elizabeth Marvin, Ross Maddox","anne_luebke@urmc.rochester.edu","518 HYLAN, RC BOX 270140","Rochester","NY","146270140","5852754031","SBE","1699, 8624","040Z, 7298, 8089, 8091","$0.00","This project will determine whether formal musical training is associated with enhanced neural processing and perception of sounds, including speech in noisy backgrounds. Music forms an important part of the lives of millions of people around the world, and it is one of the few universals shared by all known human cultures. Yet its utility and potential evolutionary advantages remain a mystery. This project will test the hypothesis that early musical exposure has benefits that extend beyond music to critical aspects of human communication, such as speech perception in noise. In addition, the investigators will test whether early musical training is associated with less severe effects of aging on the ability to understand speech in noisy backgrounds. Degraded ability to understand speech in noise is a common complaint among older listeners and hearing loss has been shown to be associated with social isolation and more rapid cognitive and health declines. If formal musical training is shown to affect improved perception and speech communication in later life, the outcomes could have a potentially major impact on quality of life,<br/><br/>Earlier studies have suggested relationships between early musical training and improved auditory neural processing and perception, but the studies' impact has been limited by small sample numbers and inconsistent methods between different studies. This project will test a large number of participants (N=360) with uniform recruitment criteria and testing protocols across six different sites. Measures will include the neural frequency following response (FFR) to speech sounds, behavioral frequency selectivity, speech perception in noise, speech perception against a background of competing talkers, pitch discrimination, and auditory masking. The participants will also complete other assessments, including a personality inventory questionnaire, a profile of musical perception skills, a spatial reasoning test to assess general cognitive ability, as well as a background questionnaire to determine socio-economic status, education, and musical background. Participants will be selected to span a wide range of ages and musical experience. The neural data and the speech perception measures will be related to factors of musical training, such as the number of years of musical training and the age at which musical training began. Scientific rigor will be assured by preregistering the study and the analyses and by making the data and analysis code publicly available via a dedicated website.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1816732","CHS:Small: Improved Cross-Subject Cognitive and Emotional State Classification  Using Functional Near-Infrared Spectroscopy Data for Deep Learning","IIS","HCC-Human-Centered Computing","08/15/2018","10/31/2019","Leanne Hirshfield","NY","Syracuse University","Standard Grant","Ephraim Glinert","07/31/2022","$494,374.00","Michael Kalish, Senem Velipasalar","leanne.hirshfield@colorado.edu","OFFICE OF SPONSORED PROGRAMS","SYRACUSE","NY","132441200","3154432807","CSE","7367","7367, 7923, 8089, 8091, 9102","$0.00","New advances in bio-technology suggest devices to wear and measure the brain will be available to support many different activities. Future technologies may use brain activity data to adapt or customize educational software in real-time. Activity support based on interpreted brain activity could be used to reduce mental workload, modify emotional states, or help someone with post-traumatic stress disorder. However, brain activity data is complex and difficult to interpret. This project will use deep machine learning methods to overcome the challenge of classifying and interpreting brain activity data using real-time data from participants. The objective is to harness the tremendous potential of cognitive sensors and computational methods to help individuals function more effectively.  <br/><br/>Although many early successes were achieved using machine learning on brain data, several notable challenges have arisen, which significantly limit the impacts of these early successes. The technical approach in this project has three research thrusts. The investigators will develop models specifically for use on high density functional-near infrared spectroscopy (fNIRS) data. Thrust 1 involves the development of advanced deep learning techniques that are particularly well-suited for fNIRS data, and address spatial and temporal inter-relations. Thrust 2 involves development and adaptation of algorithm transparency (AT) techniques that are well-suited to shed light on brain dynamics embedded within the deep learning model structures. This will help the research team interpret the underlying structure of the models, with respect to brain spatial and temporal dynamics at the individual and group level. Thrust 3 collates the model and AT techniques developed in the prior thrusts and evaluates them using an extensive cross-subject and cross-participant fNIRS dataset. Using this data for evaluation purposes, the research team will work together to interpret results to improve upon classifier performance and model generalizability.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1810758","NSF-BSF: AF: Small: An Algorithmic Theory of Brain Networks","CCF","Algorithmic Foundations","06/01/2018","05/18/2018","Nancy Lynch","MA","Massachusetts Institute of Technology","Standard Grant","A. Funda Ergun","05/31/2022","$450,000.00","","lynch@csail.mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","7796","7923, 7934, 8089, 8091, 9102","$0.00","Understanding how the brain works, as a computational device, is a central challenge of modern neuroscience and AI.  Different research communities approach this challenge in different ways, including examining neural network structure as a clue to computational function, using functional imaging to study neural activation patterns, developing theory based on simplified models of neural computation, and engineering of neural-inspired machine learning  architectures. This project will approach the problem using techniques from distributed computing theory and other branches of theoretical computer science. This project has the potential to improve our understanding of computation in the brain, by identifying key problems that are solved in the brain and key mechanisms that may be used to solve them.  This work can also have impact on theoretical computer science, by contributing a new and fruitful direction for theoretical study. This collaboration between MIT and the Weizmann Institute in Israel will increase the participation of women and minority participants in this field and will seek to bridge the gap between computer scientists and biology researchers.<br/><br/>Specifically, the project develops an algorithmic theory for brain networks, based on novel stochastic Spiking Neural Network models with general interconnection patterns. It defines a collection of abstract problems to be solved by these networks, inspired by problems that are solved in actual brains, such as problems of focus, recognition, learning, and memory.  The project designs algorithms (networks) that solve the problems, and analyze them in terms of static costs such as network size, and dynamic costs such as time to converge to a correct solution.  The investigators consider tradeoffs between the various costs, and will prove corresponding lower bound results. The models, problems, and solutions should be simple enough to enable theoretical analysis, yet realistic enough to provide insight into the behavior of real neural networks.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2015276","NEURONEX: The fabric of the primate neocortex and the origin of mental representations. From transcriptomics to single neurons and neuronal networks.","DBI","RESEARCH RESOURCES, Cross-BIO Activities, CESER-Cyberinfrastructure for","08/15/2020","10/20/2020","Amy Arnsten","CT","Yale University","Continuing Grant","Reed Beaman","07/31/2025","$4,443,743.00","","amy.arnsten@yale.edu","Office of Sponsored Projects","New Haven","CT","065208327","2037854689","BIO","1101, 7275, 7684","8089, 8091, 9178, 9179","$0.00","This award provides support for the US component of a NeuroNex Network consisting of 15 research teams in the US, Canada, and Germany.  This consortium will address the molecular, cellular, and circuit mechanisms underlying working memory in primates.  This is fundamental to abstract thought and cognitive ability.  The central hypothesis to be tested is that there is an evolutionarily driven expansion of visual connectivity in different regions of the brain and along the visual processing pathway, and that this connectivity principal will be more pronounced in macaques than marmosets. The research targets three regions, reflecting three levels of the visual pathway. A long-lasting, far-reaching impact involves leveraging work from this NeuroNex Network with other BRAIN Initiative projects to enable acquisition and sharing of the new knowledge. Future applications, even beyond the brain, of the knowledge and tools developed here will give rise to data that address fundamental and novel principles of complex self-organizing systems. The NeuroNex Network also involves training the next generation, including through inter-laboratory and fellow exchanges. <br/><br/>This NeuroNex Network integrates teams of four Interdisciplinary Research Groups (IRGs).  The approach involves characterizing neurons in each of three regions of the dorsolateral prefrontal cortex (LPFC) and processing stage using genotyping and transcriptomics, and then examining linkages to basic electrophysiological properties.  These areas also represent three stages of information processing along the primate cortical pathways as well as in the evolution of cortical layers. It is hypothesized that the functional, anatomical and molecular dependencies of neurons vary across these regions, and that differences are prominent in macaques, and more subtle in marmosets.  The data are to be used to drive the development of computational models. The first IRG takes an in vivo physiology approach using laminar recordings. The second IRG addresses in vitro electrophysiology and neuronal circuitry.  The third IRG is a molecular characterization using transcriptomics and immuno electron microscopy. The fourth IRG takes a neuroinformatics approach that combines these data to inform computational models of cortical architectures that mimic the single neurons and population dynamics measured in the first IRG.  This IRG will also create a centralized resource to assess data across levels and IRGs. This project is co-funded by Emerging Frontiers in the Directorate for Biological Sciences and the Cyberinfrastructure for Emerging Science and Engineering Research (CESER) program within the Office of Advanced Cyberinfrastructure.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1850204","CRII: III: A Spatio-Temporal Data Mining Framework For Functional Neuroimaging Data","IIS","Info Integration & Informatics, IntgStrat Undst Neurl&Cogn Sys","06/01/2019","03/16/2020","Gowtham Atluri","OH","University of Cincinnati Main Campus","Standard Grant","Sylvia Spengler","05/31/2022","$191,000.00","","atlurigm@ucmail.uc.edu","University Hall, Suite 530","Cincinnati","OH","452210222","5135564358","CSE","7364, 8624","7364, 8089, 8091, 8228, 8551, 9251","$0.00","The human brain is an interconnected web of billions of neurons that enables humans to memorize, reason, perceive, imagine, and act. Understanding the relation between neuronal activity in the brain and the functionality it enables is crucial to the characterization, early diagnosis, and effective treatment of mental illness. Advances in brain imaging technologies allow researchers to collect large volumes of brain activity data while subjects are resting or while working on a task. Multiple such brain imaging datasets that are publicly available present a tremendous opportunity to study the relationship between brain activity and brain functionality. However, a major factor limiting progress is the lack of suitable computational data mining tools that can sift through large volumes of data with challenging properties to discover insights about brain functionality.  One major challenge in developing the necessary tools is due to the properties of the brain activity data that are different from traditionally studied data for which majority of the computational tools are originally developed.  Another challenge is due to the manner in which desired insights are represented in the brain activity data. This project will result in novel computational tools and techniques that will address these two general challenges. This work is expected to accelerate progress towards effective treatment procedures for mental illness.<br/><br/>The overall goals of this project will be accomplished by defining original neuroimaging data analytic problems without shoe-horning them into existing frameworks, tackling the unique spatio-temporal characteristics of neuroimaging data, and leveraging domain knowledge in neuroscience. The driving neuroscience questions include: 1) What are the representations of the functional activity that adheres to the underlying structure of the brain connections? 2) What are the brain activation maps that can be used to represent a variety of brain functions and to study relationships among them? 3) What is the utility of transient brain states in uniquely identifying subjects, in comparison to a static representation? The corresponding computational research involves developing techniques for: 1) Determining the brain parcellation such that the resultant parcels reflect the underlying topographic connectivity; 2) Simultaneously learning the dictionary as well as classification models for multiple task-fMRI datasets; 3) Discovering and using transient brain states and their transitions to uniquely identify subjects based on their fMRI data. The resultant tools and techniques will enable the investigation of hypotheses relevant to personalized neuroscience -- understanding the neurological processes that are shared and unique to individual subjects. This will help achieve the clinically relevant goals of personalized neuroscience and eventually alleviate the huge societal burden of mental illness.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2103042","Mind, Brain and Education in STEM Learning: Research, Policy and Practice Collaboratory","DRL","ECR-EHR Core Research","07/01/2020","11/17/2020","Vanessa Rodriguez","NY","New York University Medical Center","Standard Grant","Gregg Solomon","06/30/2022","$49,892.00","","vanessa.rodriguez@nyulangone.org","One Park Avenue, 6th FL","New York","NY","100165800","2122638822","EHR","7980","7556, 8089, 8091, 8817","$0.00","This award to New York University will provide support for a workshop on Mind, Brain, and Education scheduled to be held in New York City in January 2020. It will bring researchers from multiple fields (e.g., education research, cognitive science, neuroscience) together with education practitioners (e.g., teachers, district leaders, parents) to share ideas about brain research and STEM learning in both formal and informal contexts. It will be an opportunity for researchers to share the results of their cutting-edge work on such topics as numerical processing and STEM problem solving with educators and, in turn, for educators to have direct input to researchers about issues concerning the translation to practice. It will also provide educators with the opportunity to help drive basic and applied research agendas. The goal of the workshop is to develop new models for sustained collaborations among researchers, educators, parents, and policy influencers. The project is funded by the EHR Core Research program, which supports fundamental research that advances the research literature on STEM learning.<br/><br/>The workshop will explore innovative models of interaction between researchers and educators in the nascent field of Mind, Brain, and Education, centering on collaboratories - table discussions on specific topics led by a range of top experts so as to foster dialogue - as well as networking sessions, rapid-fire talks, keynote addresses, and a session devoted to discovering new models for sustained interaction of the gathered communities. The specific topics will may include cognitive neuroscientific findings related to inducing durable memories in STEM, cognitive findings about the geometric intuitions that underlie formal learning in mathematics, establishing researcher-practitioner partnerships in STEM education, teaching science at the secondary school level, supporting museum-university collaborations, and best practices in public outreach.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1661065","Collaborative research: Neural and cognitive strengthening of conceptual knowledge and reasoning in classroom-based spatial education","DRL","ECR-EHR Core Research","04/15/2017","04/10/2019","Adam Green","DC","Georgetown University","Continuing Grant","Gregg Solomon","03/31/2022","$829,865.00","","aeg58@Georgetown.edu","37th & O St N W","Washington","DC","200571789","2026250100","EHR","7980","1544, 8089, 8091, 8212, 8817","$0.00","Spatial thinking is a powerful driver of success in the STEM classroom and spatial thinking is a major predictor of future STEM success in the workforce. The brain systems that support spatial thinking have been well mapped by neuroscience to allow clear interpretation of new brain-imaging data. Recent advances in tools used to analyze brain activity allow detection of changes in the brains of students that signify accurate learning of STEM concepts. This advance may open a window onto biomarkers of precisely the type of learning that is the goal of educators. Using these new brain analysis methods, this project, a collaboration involving researchers from James Madison University, Georgetown University, Northwestern University, and Dartmouth College, will investigate how changes in the spatial thinking network support learning of specific STEM concepts, and how changes in the classroom can facilitate changes in the brain related to spatial thinking. This cross-disciplinary project brings together experts in geoscience classroom education, spatial cognition, and the neural bases of learning and reasoning. This team is committed to bridging the conspicuous gap between the laboratory and the high school classroom. A confluence of advances in neuroimaging, and the research team's partnership with Virginia school systems make this effort timely and tractable. Identifying possible effects of sex and STEM-related anxieties on conceptual learning in the brain, and testing the effectiveness of spatial education for reducing disparities, this research will point to critical targets for intervention. The project is funded by the EHR Core Research (ECR) program, which supports work that advances the fundamental research literature on STEM learning.<br/><br/>This project seeks to understand the neural mechanisms of spatial learning, to advance of spatial education, and to identify factors that affect disparities in STEM learning and participation. The research team will collect functional magnetic resonance imaging (fMRI) and behavioral data from students before and after learning in a high school geoscience course that uses a novel spatially-based curriculum to teach STEM concepts and spatial reasoning. Pilot data on this spatial curriculum have begun to characterize the underlying cognitive and neural mechanisms at work, and show promising effects of transfer to STEM problem solving and core measures of spatial ability. Consistent with methods that have demonstrated success in the lab (but not yet the classroom), the research team will use multivariate neural representations of a group of highly experienced and specially trained teachers as an expert standard to determine neural markers of students? conceptual knowledge and spatial reasoning. Leveraging recent multivariate pattern analysis (MVPA) and machine-learning advances in brain imaging, the team will compare the neural patterns of students before and after learning to test for a trajectory that moves students closer to expert representations. This project will also test, for the first time, whether it is possible to compare different curricula based on how much they strengthen the representation of a concept in the brain. Similarly, this work will test whether spatial education leads students to engage spatial brain resources for STEM-related reasoning, and seek to compare curricula on this basis. The project will test whether neural data add predictive value to traditional testing (e.g. conventional unit tests) for subsequent retention of conceptual knowledge and spatial reasoning. Assessments of STEM-related anxieties (e.g., math and spatial anxiety) and analyses of sex-related effects on cognitive and neural outcomes will newly characterize factors that influence disparities in STEM learning and participation."
"1835200","NCS-FO: Individual variation in the fine-grained structure of distributed cortical systems for cognition","BCS","ECR-EHR Core Research, IntgStrat Undst Neurl&Cogn Sys, EPSCoR Co-Funding","09/01/2018","08/14/2018","Maria Gobbini","NH","Dartmouth College","Standard Grant","Betty Tuller","08/31/2022","$1,000,000.00","James Haxby","Maria.I.Gobbini@Dartmouth.edu","OFFICE OF SPONSORED PROJECTS","HANOVER","NH","037551421","6036463007","SBE","7980, 8624, 9150","8089, 8091, 8551, 9150","$0.00","This research project will study how brain systems for face perception differ across individuals. Face perception plays a central role in interactions among people.  The ability to recognize faces and interpret expressions can vary greatly in healthy adults.  Efficient face perception develops slowly through childhood and into early adulthood.  Face perception is much more efficient for familiar individuals with whom we interact frequently.  We will use new, state-of-the-art methods for modeling the brain's system for face perception.  The model has interacting processing pathways.  Each pathway serves a different function.   These include recognition of identity, interpretation of expression, and activation of social knowledge.  We study individual differences using a new approach, called hyperalignment. Hyperalignment allows us to see how information is encoded in fine-scale brain patterns.  These studies can make it possible to address questions about the effects of development, education, culture, and clinical disorder on brain organization.   <br/><br/>The project will investigate individual variation in the human cortical functional architecture for face perception that leverages our previous work on multivariate models of information in the distributed neural system for face perception and our work creating hyperalignment to build high-dimensional common models of information spaces in cortex. Our approach discovers shared basis functions for information that is encoded in fine-scale cortical topographies, affording reliable measurement of individual differences in the representation of this detailed information.  We will investigate individual variation in cortical systems for face perception as a function of cognitive ability, development, and learning, and build the common model of cortical information spaces using fMRI data collected during viewing of naturalistic movies and in the resting state.  We will use response hyperalignment and connectivity hyperalignment to derive a common model of the face perception system with shared basis functions for fine-scale variation in response tuning and functional connectivity. By modeling shared neural representation at a fine scale, measures of deviations from shared representation are more sensitive to the inter-individual variation that underlies differences in cognitive function.  Our methods have the potential to provide a firmer and more nuanced basis for addressing questions about the effects of development, education, culture, and clinical disorder on brain organization.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1926653","NCS-FO: Collaborative Research: The evolutionary origins of leadership in chimpanzees: from individual minds to collective action","BCS","ECR-EHR Core Research, IntgStrat Undst Neurl&Cogn Sys","08/15/2019","08/29/2019","Alexandra Rosati","MI","Regents of the University of Michigan - Ann Arbor","Standard Grant","Betty Tuller","07/31/2022","$410,041.00","","rosati@umich.edu","3003 South State St. Room 1062","Ann Arbor","MI","481091274","7347636438","SBE","7980, 8624","8089, 8091, 8551, 8817","$0.00","Leadership is crucial for effective cooperation, especially in large and complex groups. Yet there is an empirical and theoretical gap in our understanding of the individual-level processes underpinning leadership and the group-level consequences of leadership. How does the cognition of individual leaders translate into coordinated group action in the real world?  This project proposes using chimpanzees as a new model of human-like leadership to better understand the evolutionary origins of our own leadership patterns. We will bridge the gap between individual- and group-level phenomena by conducting matched research with semi-free ranging chimpanzees living in a sanctuary where we can do detailed assessments of cognition, and with chimpanzees living in the wild where we can look at complex group behavior in a natural setting. By matching datasets across these two contexts, we will be able to see how individual cognitive process translate into group action. While humans are thought to be uniquely able to establish leadership through prestige and collaboration instead of just pure physical domination, chimpanzees are our closest living relative, also show variation in how individuals obtain and maintain status in their groups. This project will therefore illuminate the evolutionary origins of human leadership, and also set a new agenda in evolutionary cognitive science for studying cognition in the wild. Training, education, and outreach from elementary school through to graduate school will be integrated throughout the project both domestically and abroad. As part of this proposal, we will develop a leadership module for children, using animal models to demonstrate different forms of leadership. We will implement this module through outreach at local schools and museums in the US and in 16 primary schools in Uganda. Undergraduates and high school students in the US will gain hand-on research experience through internships and in coursework. Two postdoctoral researchers and a graduate student will further gain international research experiences in the course of the project. This integrated approach to research and education will train a new generation of evolutionary cognitive scientists and disseminate primate research to the public.<br/><br/>This project has three specific aims. The first aim is to identify individual leaders (those with outsized influence) in natural social groups across multiple contexts of behavior including dominance rank, initiation of group movements, resource acquisition, within-group mediation and inter-group aggression. The second aim is to create leadership profiles by characterizing individual variation in the cognitive, behavioral, and physiological mechanisms of leaders across these contexts. At the sanctuary, 100+ chimpanzees across 5 social groups will be assayed for cognition (including social cognition, cooperation, and executive function); temperament; behavior (aggression and affiliation), and physiology (hormones and body size) to predict leadership. At the field site, similar assessments will be made of temperament, behavior, and physiology, drawing on a longitudinal database with 30 years of data on 150 wild chimpanzees. These data will be used to test the hypothesis that there are distinct pathways to leadership in chimpanzees, with intimidation-based and cooperative strategies being the most important, but knowledge and motivation anchoring some forms of leadership. The final aim is to understand how variation in leadership styles shapes the outcomes of collective action by examining several short-and long-term metrics of leadership success, including group cohesion, rewards received, and biological outcomes like reproductive success that can only be studied in the wild. This project will bridge individual-level and group-level perspectives on cognition, behavior, and physiology by leveraging the strengths of two natural populations of chimpanzees. The project will match experimental and observational techniques across sites on a scale never previously done, and will develop chimpanzees as a new model for human leadership.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1909864","CHS: Small: Collaborative Research: APERTURE: Augmented Reality based Perception-Sensitive Robotic Gesture","IIS","HCC-Human-Centered Computing, IntgStrat Undst Neurl&Cogn Sys","09/01/2019","05/05/2020","Thomas Williams","CO","Colorado School of Mines","Standard Grant","Balakrishnan Prabhakaran","08/31/2022","$273,349.00","","twilliams@mines.edu","1500 Illinois","Golden","CO","804011887","3032733000","CSE","7367, 8624","7367, 7923, 8089, 8091, 9251","$0.00","How can a robot choose the ""best"" modality for drawing the attention of a human and communicating the needed information? This is the central theme of the project with the assumption that the human team mates of the robots use augmented reality (AR) based visualization. Specifically, this project plans the following three major research activities for enabling robots to communicate with human teammates in a way that is tailored to their teammates' current mental states: exploring how augmented reality technologies (such as the Microsoft Hololens) can be used to provide robots with new ways to communicate about objects, locations, and people in their environments, especially when used together with communication through spoken language; examining how technologies can non-invasively measure different aspects of teammates' mental states, including how much mental workload, perceptual workload, stress, and frustration they are experiencing; and determining how robots can choose the best way to communicate with their human teammates when the two technologies are combined, (for example, through language alone, AR visualizations alone, or both used together), based on those teammates' individual mental states. This system will then be used to test how it might improve the safety and productivity of underground workers, by allowing robots to communicate in a way that is more effective and less cognitively demanding. While the researchers will be investigating the effectiveness of these integrated technologies specifically within underground work environments, the research will also be applicable to a wide variety of areas, including eldercare, urban search-and-rescue, and space robotics, and will have broad scientific impact across both computer science and cognitive science.<br/><br/>The above goals will be achieved through APERTURE, a novel framework integrating head-mounted augmented reality displays, a multimodal suite of noninvasive, lightweight, and field-ready physiological sensors (such as  functional near-infrared spectroscopy (fNIRS), Electroencaphalography (EEG), Electrodermal Activity, Electrocardiogram (ECG), and Respiration sensors), and unmanned ground robots, within a cognitive robotic architecture. APERTURE will be built by integrating the Distributed Integrated Affect Reflection Cognition (DIARC) architecture with these robotic, augmented reality, and physiological hardware elements.  The project will design and evaluate physiological sensing models, augmented reality gestural cues, and machine learning models for selecting between AR gestural cues based on neurophysiological data. The designed machine learning models will classify users' cognitive and affective states from this sensor data, and help the robots understand when and how to communicate based on users' cognitive and affective states. The novel AR approach to deictic gesture will help robots pick out the objects they are referring to through the use of visualizations displayed in their teammates' augmented reality headsets.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1660996","Exploring Links between STEM Success and Spatial Skills: Undergraduate GIS Courses and a Spatial Turn of Mind","DRL","ECR-EHR Core Research","07/01/2017","06/04/2019","Nora Newcombe","PA","Temple University","Continuing Grant","Gregg Solomon","06/30/2022","$1,681,032.00","Jeffrey Hamerlinck, Paddington Hodza, Meredith Minear","newcombe@temple.edu","1801 N. Broad Street","Philadelphia","PA","191226003","2157077547","EHR","7980","8089, 8091, 8551, 8816, 8817","$0.00","People with strong spatial skills are more likely to show interest and success in science, technology, engineering and mathematics (STEM). Fortunately, spatial skills are malleable, and improvements in them are durable and generalizable. Increasing spatial skills during educational training may be one route towards increasing the STEM workforce. However, there are two gaps in current knowledge. First, existing research concentrates almost exclusively on small-scale spatial skills such as mentally rotating objects. The relation between large-scale spatial skills such as navigation and STEM has not been investigated. Scientific disciplines, especially the ""geo"" disciplines, and any disciplines using map-like distributions, may benefit from training in large-scale spatial skills. This project tests this hypothesis. Second, there is a need for a long-term spatial training plan that can be integrated into K-12 and university classrooms. One such strategy may be teaching Geographic Information Systems (GIS) skills. For example, GIS skills facilitate faster access to data, data modeling, and data visualization. GIS tools are used by professionals in many STEM fields including healthcare, geography and urban planning, environmental studies, and finance. Effective use of GIS depends on understanding the technology, its benefits and shortcomings, and its relation to specific spatial skills. This project will evaluate the efficacy of GIS training and identify its active components. Findings can be used to inform GIS instruction and GIS interface customization. The project is funded by the EHR Core Research (ECR) program which funds basic research that seeks to understand, build theory to explain, and suggest interventions (and innovations) to address persistent challenges in STEM interest, education, learning, and participation.<br/><br/>This project evaluates the importance of large-scale spatial skills in the geography, geoscience, and other scientific disciplines that reply on spatial distributions of information (e.g., epidemiology). Spatial skills relevant to navigation may be predictors of success in these disciplines, and conversely, participation in these disciplines may benefit large-scale spatial skills. This project concentrates on GIS as a predictor of enrollment and success in fundamental and advanced GIS courses at Temple University and University of Wyoming. Simultaneously, it examines GIS technologies as a potential intervention to improve large-scale spatial skills and to create what has been called 'as a spatial turn of mind.'The effective use of GIS depends on our understanding of human spatial representations and its limits. Students enrolled in fundamental and advanced GIS courses will be compared to students enrolled in non-GIS low-spatial courses. Groups are compared in terms of their navigation proficiency and associated cognitive mechanisms (e.g., perspective-taking) at baseline and in terms of their growth over the semester. A virtual environment navigation paradigm will be used to objectively assess large-scale navigation skills. Successful learning in GIS courses will be assessed in multiple ways including hands-on GIS lab exercises, quizzes, exams and individual/group projects. GIS presents an opportunity to integrate spatial training early in formal education and thus increase low- and high- spatial students' interest in spatial concepts through creative and hands-on activities. Findings can inform spatial interventions designed to motivate more students to pursue careers in STEM fields involving spatial distributions. Findings can also be used to direct attention to spatial skill-dependent usability features in geovisualization tools and the importance of customization to learners' level of competence."
"1912270","Collaborative Proposal: CRCNS US-German Data Sharing Proposal: DataLad - a decentralized system for integrated discovery, management, and publication of digital objects of science","IIS","Cognitive Neuroscience","12/01/2019","09/13/2019","Franco Pestilli","IN","Indiana University","Standard Grant","Jonathan Fritz","11/30/2022","$152,802.00","","pestilli@utexas.edu","509 E 3RD ST","Bloomington","IN","474013654","3172783473","CSE","1699","7327, 8089, 8091","$0.00","Scientists collect terabytes of critical data every year. Recently a strong open science movement has generated traction for the beneficial practice of sharing data across laboratories, universities and research institutions. Yet, sharing data is not enough. Data must be shared using standardized formats and accompanied by curated metadata to allow for tracking, search, and organization. Metadata are essential for scientific discovery, as they are routinely used to complete all data analyses. However, to date, most brain projects focus on collecting or analyzing data, not on metadata management. Typical metadata records consist of heterogeneous study descriptions, developed at study release stage, without consistency across records or standard mechanisms to track changes. <br/>This project will increase access to brain data and improve metadata handling by combining two NSF-funded projects. It will develop a first-of-its-kind metadata management system able to track data and metadata distributed across heterogeneous geographical locations, storage systems and data formats. This portion of the project will expand the functionality of a previously funded NSF project DataLad. DataLad will also be enhanced to interoperate with major data repositories such as OSF and Figshare. Furthermore, the project will use the NSF-funded cloud computing platform brainlife.io to create a data and metadata marketplace by gathering data from multiple currently separated repositories into a single ecosystem . The goal is to improve interoperability across open science projects and make data and metadata easily searchable and available for computing on national cyberinfrastructure systems, ultimately advancing scientific discovery by increasing data discoverability, utilization, and publication. <br/><br/>This project will generate various technological advances. The core target will be an extensible system capable of automated gathering of metadata from various domains. It will be comprised of two major components: 1) a set of metadata parser algorithms that extract metadata from datasets and individual files using a flexible JSON-LD based data structure (with the ability to encode controlled vocabularies where available) and 2) an aggregation procedure that merges the aggregated metadata across parsers and stores them into compressed files that are optimized for bandwidth-efficient exchange and can be queried directly, or used as input into SQL or graph databases for data discovery applications. Extracted metadata will be included within the same datasets under Git and git-annex version control for unambiguous referencing and versatile data logistics. In parallel development we will improve interoperability of DataLad with existing data publishing portals (such as Figshare and OSF) by taking advantage of extracted metadata (e.g., Author, Description) to prefill required fields, and also by bundling the entire Git object store within the publication to make such published datasets installable back by DataLad without any loss of information. To make such published datasets discoverable, we will establish a crowd-sourced registry (with a RESTful API) which will get announcements on the availability of new datasets upon publication and aggregate their metadata to enable querying across datasets and data hosting providers. The final development will be the integration of DataLad within the brainlife.io data marketplace. This will make it possible to search and install datasets on brainlife.io as well as to process the data utilizing the brainlife.io analyses Apps on various NSF-funded national cyberinfrastructure high-throughput computer systems.<br/><br/>A companion project is being funded by the Federal Ministry of Education and Research, Germany (BMBF).<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1850102","CRII: SCH: A Computational Toolbox for Analysis of Big Brain Data","IIS","Smart and Connected Health, IntgStrat Undst Neurl&Cogn Sys","06/01/2019","03/24/2020","Maria Holland","IN","University of Notre Dame","Standard Grant","Sylvia Spengler","05/31/2022","$180,870.00","","maria-holland@nd.edu","940 Grace Hall","NOTRE DAME","IN","465565708","5746317432","CSE","8018, 8624","8018, 8089, 8091, 8228, 8551, 8624, 9102, 9251","$0.00","The brain is our most complex and least understood organ. Due to the recent proliferation of large public neuroimaging data repositories, researchers have access to an unprecedented amount of data, but in many ways the amount of data has surpassed our abilities to analyze it. With pressing health questions attracting the interest of scientists, clinicians, and engineers, we have an urgent need for computational tools that integrate the methods and expertise of different fields. This project seeks to advance the analysis of big brain data by developing, using, and sharing novel open-source computational tools for the modeling and analysis of cortical thickness, an indicator of healthy brain development. Through the analysis of two large data sets containing over 500 individual scans, a baseline for cortical thickness variation throughout healthy development will be generated. Numerical simulations will also shed light on the effect of the mechanical forces that give rise to the brain?s unique shape. The computational tools developed will be made available for use by other researchers to further leverage existing open access databases of MRI scans. Beyond that, this project has the potential to produce new insights with clinical applications in the analysis of neurological disorders such as Autism Spectrum Disorder, Alzheimer's Disease, and Parkinson's Disease. Alongside this trans-disciplinary project, the team will also develop a student-written blog, intended for the general public, on interesting investigations in the field of biomechanics.<br/><br/>Gyrification, or the process by which the brain develops its characteristic wrinkles and folds, is the result of both biological processes and mechanical forces. These elements, tightly coupled and affecting each other, affect both the form and function of the brain. This project will increase the biological fidelity of the finite element simulations used to model gyrification by representing cerebrospinal fluid pressure, neuronal apoptosis, and synaptic pruning through the development of new material models that describe heterogeneous, anisotropic, growing and remodeling tissue. These computational simulations will generate a deeper understanding of the role of mechanical forces in the evolution of cortical thickness, which varies regionally both within and between individuals. By introducing a new metric of interest that allows for the characterization of thickness variations on arbitrarily small regions, this project will develop new computational tools for the analysis of within-subject and between-subject variations of cortical thickness and the characterization of these patterns in healthy development. The successful completion of this research will result in novel computational tools for neurological imaging analysis of big brain data in the many public neuroimaging databases, generating additional value out of existing resources.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1546296","BIGDATA: Collaborative Research: IA: Hardware and Software for Spike Detection and Sorting in Massively Parallel Electrophysiological Recording Systems for the Brain","IIS","Big Data Science &Engineering, IntgStrat Undst Neurl&Cogn Sys","10/01/2015","06/09/2021","Kenneth Shepard","NY","Columbia University","Standard Grant","Sylvia Spengler","09/30/2022","$898,000.00","Liam Paninski, Luca Carloni","shepard@ee.columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","CSE","8083, 8624","7433, 8083, 8089, 8091, 9251","$0.00","Understanding how the brain works is arguably one of the most significant scientific challenges of our time and the focus of the BRAIN initiative. It is widely believed that neural circuit function is emergent, the result of complex interactions between constituents with individual neurons forming synaptic connections with thousands of other neurons. Mapping of these complex circuits has been virtually impossible because of the reliance on electrophysiological recordings which sample these networks extremely sparsely. These tools for extracellular spike recordings are only able to simultaneously record from several tens to a few hundred neurons. Raw signals from these recording electrodes are first filtered to remove out-of-band signals. Putative spike events are then detected and extracted. Finally, these snippets of time-series event are sorted, typically on the basis of waveform shapes, into clusters. Even at the very modest bandwidths for these systems, computing systems struggle to save the data and process the resulting data sets. Scalability of these measurement techniques by many orders of magnitude in recording density and channels will be essential to future progress in understanding neuron circuits.<br/><br/>This project is exploiting emerging electrophysiological recording systems in which the electrode (and channel) count is increased by almost three orders of magnitude over conventional systems with data bandwidths exceeding 1GB/sec. To handle these data bandwidths and resulting data volumes and deliver scalability, this project will develop dedicated hardware and associated algorithms for spike detection and sorting that allow these tasks to be performed in real-time in close proximity to the recording system. Compression by more than three orders of magnitude is possible by these means by taking advantage of the special spatiotemporal local structure in these data sets; by exploiting strong prior information about the spiking signal and reducing the dimensionality of the problem accordingly; and by adapting and extending modern scalable nonparametric Bayesian inference methods. In addition to providing important new tools for neuroscience, the tools developed here for scalable real-time event detection and annotation have broad applicability to other spatiotemporal data sets (or more generally, any data set comprising multiple streams of data, in which the streams could involve different data modalities) in which objects of interest are spatially and temporally localized with fixed spatial footprints. Examples abound in cell and molecular biology, particle and solid-state physics, financial monitoring,  monitoring of power networks, and sensor networks."
"1822478","CRCNS Research Proposal:  Collaborative Research: Wiring synaptic chain networks for precise timing during development","EF","CRCNS-Computation Neuroscience","09/01/2018","10/15/2020","Michael Long","NY","New York University Medical Center","Continuing Grant","Edda Thiels","08/31/2022","$400,394.00","","mlong@med.nyu.edu","One Park Avenue, 6th FL","New York","NY","100165800","2122638822","BIO","7327","7327, 8089, 8091, 9178, 9179","$0.00","Skilled behaviors such as singing and playing the piano require precise timing. The primary goal of this project is to use theoretical and experimental approaches to understand the network properties of neurons that can produce the extremely precise activity necessary to enable these actions. Such networks are likely to be wired during the development of the brain, but the precise mechanisms involved remain a mystery. Previous computational models and experimental observations suggest that the wiring process is gradual. The investigators of this project will study how individual neurons are incorporated into the network. Of particular interest are postnatally born neurons, which have more immature properties compared with other neurons within the circuit, including a higher degree of spontaneous activity, which potentially facilitates their recruitment into the network. These ideas will be tested by experimentally tagging and manipulating immature neurons, as well as by constructing computational models and simulating the network growth process. The findings may shed light on how functional neuronal networks develop.  The research may also help to formulate strategies of repairing dysfunctional or injured brain networks through manipulation of neuron maturity. This research will involve a wide range of innovative experimental and computational techniques and provide opportunities for students to gain expertise in electrophysiology, neural data analysis, and modern methods of computational neuroscience. The principal investigators will train postdoctoral researchers as well as graduate students, undergraduates, and summer high school interns. <br/><br/>The model system used in this project is the motor control circuitry of the zebra finch, a songbird whose adult courtship song consists of a highly repeatable sequence of vocal elements (or motif) sung with millisecond precision. The timing of song is controlled by a premotor forebrain region called HVC (proper name). Each premotor HVC neuron fires once per motif with sub-millisecond timing jitter across renditions. As a population, these neurons drive downstream song production circuits to produce specific acoustic patterns. During development, precise timing within HVC gradually emerges while the bird is learning to perform his song. Previous experimental observations suggest that neurons are gradually incorporated into the network generating song-relevant neural sequences, potentially from the newly born neurons that are robustly added to HVC during this period. This project aims to investigate the cellular and synaptic mechanisms underlying the development of the sequence generating network in HVC. The central hypothesis of this work is that these spontaneously active, newly born neurons are preferentially added to the leading edge of the growing timing network. This hypothesis will be tested with a combined experimental and computational modeling approach: (1) directly imaging the dynamics of network integration of newly born neurons in vivo through a targeted retroviral method; (2) constructing a computational model of HVC that is constrained by these observations and using the model to investigate the mechanisms of the network growth; and (3) measuring the cellular and synaptic properties of newly born neurons and their spontaneous activity as they mature.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1509178","AF: Medium: Algorithmic Complexity in Computation and Biology","CCF","Algorithmic Foundations, IntgStrat Undst Neurl&Cogn Sys","07/01/2015","06/08/2021","Leslie Valiant","MA","Harvard University","Standard Grant","Tracy Kimbrel","06/30/2022","$1,079,975.00","","valiant@seas.harvard.edu","1033 MASSACHUSETTS AVE","Cambridge","MA","021385369","6174955501","CSE","7796, 8624","7924, 7927, 8089, 8091, 8551","$0.00","Computational complexity is the field that studies how much resources are needed for performing computational tasks. Its primary focus has been to understand how many steps and how much storage space is required for performing various important tasks on conventional computers. Biological processes, can also be viewed as computations to the extent that they consist of step-by-step processes that follow certain rules, and can then be also studied from the perspective of the theory of computational complexity. This proposal is concerned with studying both of these aspects. Its goal is that of proving, by mathematical means, upper or lower bounds on the resources needed for both general purpose and evolutionary computations.<br/><br/>While much is understood about the complexity of computations on general purpose computers, this understanding is pivoted around a small number of critical open questions, such as the P=?NP question, the answer to which would resolve the resource requirements of numerous important tasks. The first focus of this study will be algebraic approaches to these questions, in which the limitations on computations imposed by algebraic axioms is analyzed. Holographic algorithms have over the last decade yielded novel algorithms for a variety of problems, as well as new lower bound arguments, and also new techniques for proving computational equivalence among apparently dissimilar problems. The goal of the research is to understand the inherent limits of holographic algorithms and to use this understanding to develop efficient algorithms. Darwinian evolution can be also viewed as a computational process that uses quantifiable resources, here measured in terms of numbers of generations, size of populations, and the number of experiences of individuals. Recently it was shown that the Darwinian mechanism can be viewed as a form of machine learning, the field of computer science that studies systems in which most of the information is acquired from experience and not from a programmer. The goal of the research is to understand what classes of functions, such as those occurring in protein expression networks, can so evolve using practicable resources.  Graduate students will be involved in these projects."
"1922439","NCS-FO:  The Neural Basis of Human Spatial Navigation in Large-Scale Virtual Spaces with Vestibular Input","BCS","ECR-EHR Core Research, IntgStrat Undst Neurl&Cogn Sys","07/30/2018","02/06/2019","Arne Ekstrom","AZ","University of Arizona","Standard Grant","Kenneth Whang","08/31/2021","$504,390.00","","adekstrom@email.arizona.edu","888 N Euclid Ave","Tucson","AZ","857194824","5206266000","SBE","7980, 8624","8089, 8091, 8551, 9179","$0.00","How do people learn large-scale spaces, like new towns and cities that they visit, as they navigate? Addressing this question poses surprising obstacles, such as the difficulty in optimizing large-scale spaces for experimental testing and controlling for pre-existing knowledge. Desktop virtual reality offers one possible way to address this question, although such testing offers an incomplete rendition of the full-body, immersive experience that is real-world navigation. Researchers will develop a 2-D treadmill coupled with a head-mounted display to allow free ambulation of large-scale virtual spaces. Successful development of this device has important societal applications. For example, pre-training with enriched body-based cues has the potential to increase knowledge transfer to real world environments, which could be helpful for training individuals such as first-responders and navigation in wilderness environments. Also, the device and proposed experiments will provide a completely novel understanding of the neural basis of human spatial navigation with body-based cues, fundamental to accurately modeling spatial cognition and understanding why we often get lost when we visit new cities.<br/><br/>Almost all theories of the neural basis of spatial navigation, largely developed in freely navigating rodents, assume the critical importance of importance of body-based cues to this code. Yet the vast majority of studies in humans involve navigation in desktop virtual reality. The novel device that will be developed will permit 2-D locomotion-based VR navigation, allowing a full range of body/head rotations and ambulation. The experiments will determine 1) the contributions of body-based input to human spatial navigation and how navigation in VR with body-based can enhance subsequent knowledge of real world environments 2) how the brain codes spatial distance by employing simultaneous EEG recordings 3) how the brain codes the relative directions of landmarks in the environment by modeling the underlying multidimensional brain networks using high-resolution functional magnetic imaging (fMRI). The outcomes from these experiments will be important to testing models of spatial navigation and advancing our understanding of the extent to which we employ visual vs. body-based cues to represent spatial environments, currently an issue of significant debate in the field."
"1750931","CAREER: Mathematical Modeling and Computational Tools for in vivo Astrocyte Activity","IIS","Robust Intelligence","06/01/2018","06/16/2020","Guoqiang Yu","VA","Virginia Polytechnic Institute and State University","Continuing Grant","Kenneth Whang","05/31/2023","$529,249.00","","yug@vt.edu","Sponsored Programs 0170","BLACKSBURG","VA","240610001","5402315281","CSE","7495","1045, 7495, 8089, 8091","$0.00","This project aims to develop new computational tools to interpret and analyze the activity of astrocytes. Astrocytes, one type of glial cells and the most populous cells in brain, have recently been found to have much more active functionality than previously thought. Astrocytes closely listen to and proactively regulate the nervous system, yet their exact roles in normal and pathological brains remain elusive. Recent technological progress makes it possible to monitor astrocyte activity with unprecedented spatial and temporal resolution, but considering the complexity and scale of astrocyte activity data, rigorous computational modeling is critically needed. This project will establish a solid foundation for quantitative analysis of astrocyte activity, enabling in vivo analysis, greater reproducibility, and  benefits for understanding brain disorders. The computationally challenging problems formulated in this project are expected to be valuable for other areas of computer science, serving as examples to build new statistical models and develop powerful generic machine-learning theory and algorithms. <br/><br/>The proposed research will develop a comprehensive data-driven framework to model astrocyte activity, with the specific goals of automatically detecting calcium events, identifying functional independent units and characterizing their individual and systems manifestation. Three research objectives include: (1) developing computational approaches to detect calcium events (2) systems modeling and quantification of astrocyte activity, and (3) application to in vivo astrocytes of mouse and other model animals to  showcase the usefulness of the proposed methodology by addressing several different current biological questions. The educational objective is to help maintain the competitive vitality of the U.S. computational neuroscience workforce, and to deepen the understanding of core computational concepts, by incorporating cutting-edge computational neuroscience problems into the engineering curriculum, by improving the recruitment and retention of women and minority students, by reaching out to K-12 students to inspire their interest in this interdisciplinary field, and by interacting with undergraduate students to offer opportunities and encourage them to choose computational neuroscience as a career.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2024462","NCS-FO: Dynamic computational phenotyping of human cognition and brain function","DRL","ECR-EHR Core Research, IntgStrat Undst Neurl&Cogn Sys","09/01/2020","07/28/2020","Samuel Gershman","MA","Harvard University","Standard Grant","Gregg Solomon","08/31/2022","$916,029.00","Randy Buckner","gershman@fas.harvard.edu","1033 MASSACHUSETTS AVE","Cambridge","MA","021385369","6174955501","EHR","7980, 8624","8089, 8091, 8551","$0.00","A long-term goal of cognitive neuroscience is to understand which aspects of cognition are shared across individuals and which are unique to an individual. Studies of the latter are typically concerned with traits that are relatively stable over time, constituting what is referred to as a static phenotype. Phenotyping has proven to be a powerful approach for predicting behavior across time and tasks. For example, individual differences in the ability to delay gratification at age 4 years predict academic, verbal, and socioemotional competence in adolescence. But a major limitation to the predictability of such static approaches to phenotyping is that they do not capture within-individual variation. Static phenotypes are derived from performances on tasks measured at a specific time and context, whereas we know that cognitive performances (and brain measures of it) vary within individuals in relatively short time frames depending on such factors as sleep, stress, mood, alertness, and motivation. To predict an individual's cognitive performance across time, one needs to understand how the individual's cognitive state changes and what drives those changes. This research project, conducted by investigators at Harvard University, will fill this gap by collecting individual data repeatedly over time. By fitting computational models to the data, the researchers will extract a dynamic ""computational phenotype? of each individual. They hypothesize that changes will be captured computationally by a relatively small set of dynamical parameters and that a small set of brain networks will be found to map onto those parameters. If this hypothesis is correct, then the project will have the potential to open the door to targeted, precise, and individual-specific training interventions to improve cognitive performance. This project is funded by Integrative Strategies for Understanding Neural and Cognitive Systems (NCS), a multidisciplinary program jointly supported by the Directorates for Computer and Information Science and Engineering (CISE), Education and Human Resources (EHR), Engineering (ENG), and Social, Behavioral, and Economic Sciences (SBE).<br/><br/>Computational phenotyping has recently emerged as a powerful technique for characterizing variation between individuals. By fitting computational cognitive models to behavioral data, investigators can use the resulting parameter estimates as a cognitive ?fingerprint? for an individual. Computational phenotypes have the advantage over other kinds of phenotypes (e.g., those based on surveys) of being more closely linked to underlying cognitive and neural mechanisms. Research has shown the utility of computational phenotyping in predicting individual-level outcomes, designing interventions, and providing an alternative to traditional diagnostic criteria. A critical limitation of this approach is that it has typically conceptualized the phenotype as a trait?a static descriptor of an individual. In the first aim, the investigators will formalize and experimentally validate a dynamic conceptualization of the computational phenotype. To accomplish this aim, the investigators will have participants complete a battery of behavioral tasks? weekly over three months ? for which established computational models exist. Data from this longitudinal study will be used to estimate how each participant?s computational phenotype uniquely changes over time, and the investigators will employ statistical methods to extract low-dimensional structure in the phenotype. In the second aim, the investigators will use longitudinal neuroimaging in conjunction with the behavioral battery to identify networks in the brain that track the low-dimensional phenotype structure, allowing them to pinpoint the neural locus of intra-individual variation.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1734938","NCS-FO: Neuroimaging to Advance Computer Vision, NLP, and AI","IIS","GVF - Global Venture Fund, ECR-EHR Core Research, IntgStrat Undst Neurl&Cogn Sys","08/15/2017","07/12/2019","Jeffrey Siskind","IN","Purdue University","Standard Grant","Kenneth Whang","07/31/2022","$1,000,000.00","Ronnie Wilbur, Evguenia Malaia","qobi@purdue.edu","Young Hall","West Lafayette","IN","479072114","7654941055","CSE","054Y, 7980, 8624","5946, 5980, 6869, 8089, 8091, 8551, 8817","$0.00","It is often said that a picture is worth a thousand words. Frequently, to search for what is needed, whether images or objects in those images, words are needed instead. Getting accurate labels for efficient searches is a longstanding goal of computer vision, but progress has been slow. This project employs new methods to significantly change how picture-word labeling is accomplished by taking advantage of the best picture recognizer available, the human brain. Through functional magnetic resonance imaging and electroencephalography, brain activity of humans looking at pictures/videos is recorded and then used to improve performance on artificial intelligence (AI) tasks involving computer vision and natural language processing. Current systems use machine learning to train computers to recognize objects (nouns) and activities (verbs) in images/video, which are then used to describe events. Reasoning tasks (e.g., solving math problems) can then be done. These systems are trained on specially prepared datasets with samples of nouns for objects, verbs for activities, sentences describing events, and exam questions and answers. A novel paradigm using humans to perform the same tasks while their brains are scanned allows determination of neural patterns associated with those tasks. The brain activity patterns, in turn, are used to train better computer systems.<br/><br/>The central hypothesis is that understanding human processing of grounded language involving predication and its use during reasoning will materially improve engineered computer vision, natural language processing, and AI systems that perform image/video captioning, visual question answering, and problem solving.  Scientific and engineering goals include developing models of human language grounding and reasoning consistent with neuroimaging, to improve engineered systems integrating language and vision that support automated reasoning.  The main scientific question is to understand mechanisms by which predicates and arguments are identified, linked, and used for reasoning by the human brain.  The hypothesis, that predicate-argument linking in visual and linguistic representations are accomplished similarly, and that this then supports reasoning and problem solving, will be tested using multiple neuroimaging modalities, and machine learning algorithms to decode ""who did what to whom"" from brain scans of subjects processing linguistic and visual stimuli.  The iterative approach will involve understanding information integration at the neural level, to improve machine learning performance on AI tasks by training computers to perform increasingly complex tasks with neuroimaging data from stimuli derived from large-scale natural tasks.  Using identical datasets for human and machine performance will support translation of scientific advances to engineering practice involving integration of computer vision and natural language processing.<br/><br/>This award is cofunded by the Office of International Science and Engineering."
"2024414","Collaborative Research: NCS-FO: Intelligent Closed-Loop Neural Interface System for Studying Mechanisms of Somatosensory Feedback in Control of Functional and Stable Locomotion","ECCS","IntgStrat Undst Neurl&Cogn Sys","09/01/2020","07/27/2020","Boris Prilutsky","GA","Georgia Tech Research Corporation","Standard Grant","John Zhang","08/31/2023","$305,999.00","","boris.prilutsky@ap.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","ENG","8624","8089, 8091, 8551","$0.00","Sensory feedback from moving legs is critical for functional and dynamically stable locomotion. Although it is clear that motion-related sensory feedback influences inter-leg coordination and selection of gaits (walking, trotting, galloping, etc.), it is not known which sensory modalities (e.g., muscle length- or force-related signals) and sources of feedback (e.g., hip or knee muscles) mediate these locomotor changes. Therefore, this project aims to understand how sensory neurons providing information about the length of hip muscles regulate interlimb coordination and gait selection. This goal will be accomplished by selectively and reversibly stimulating these sensory neurons in an intelligent, closed-loop, and well-controlled manner. This project will lead to the development of new neural implant tools and associated computational algorithms for an in-vivo manipulation of motion-related sensory signals in a large animal model, the cat. The new findings of this project and the developed methods will substantially enhance our understanding of the mechanisms of sensory locomotor control and contribute to developing novel therapeutic interventions. The proposed multidisciplinary research approaches will also significantly expand the utility and capabilities of the rapidly growing field of optogenetics, enabling transformative research and providing unprecedented new experimental tools for neuroscience. The most noticeable long-term benefits of this work to society will be an improvement in the quality of life for a sizable population of people affected by a wide range of movement deficits, from limb loss to sensory neuropathy. These individuals will benefit from the development of neural interfaces between the nervous and engineering systems controlled by machine learning algorithms. Throughout this project, efforts will be made to recruit and train graduate and undergraduate students from underrepresented groups. Outreach activities will also be organized to share resources, tools, and knowledge with teachers, students, and underrepresented groups. The results of the proposed research and educational activities will be shared with students, scientific communities, and the public through science fairs, publications, workshops, conferences, and the Internet.<br/><br/>The overall goal of this proposal is to characterize the mechanisms of somatosensory control of interlimb coordination and gait selection by spindle afferents of hip muscles in the cat model by developing and utilizing in-vivo an intelligent and closed-loop optoelectronic neural interface system. In particular, in this proposal high-density, efficient, and wirelessly-powered implantable opto-electro (WIOE) neural interface devices will be developed. Each WIOE heterogeneously incorporates an optoelectronic array of 64 transparent microelectrodes and 16 microscale light-emitting-diodes (LEDs), a system-on-a-chip (SoC), and a power receiver (Rx) coil in an mm3-size package, capable of optogenetic stimulation and electrical recording of neural activities. Wireless telemetry links will be implemented for efficient transcutaneous power and wideband data transmission between an external data-acquisition/control unit and the distributed array of WIOE implants. Multiple WIOE devices will be implanted in selected dorsal root ganglia (DRG) of the cat. Neural activities of DRG neurons, EMG activities of selected muscles of the four limbs, and full-body locomotor kinematics will be recorded, and spindle afferent activities will be manipulated via optogenetic stimulation in selected DRGs during unconstrained cat locomotion. Machine learning (ML) models leveraging the spatiotemporal structures in the signals and mapping afferent  activities in DRGs to limb kinematics will be applied for achieving closed-loop control of the optogenetic  neuromodulation. The proposed research activities will be conducted by a team of collaborators with complementary research expertise in the areas of bioMEMS, wireless microelectronics, machine learning, artificial intelligence, and behavioral neuroscience. The successful development of the proposed intelligent and closed-loop optoelectronic neural interface will yield a robust building block for a comprehensive set of minimally invasive neural interfaces to study somatosensory control of movement, as well as monitor or treat somatosensory pathological conditions.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1835239","NCS-FO: How real-world interaction networks shape and are shaped by neural information processing","SMA","ECR-EHR Core Research, IntgStrat Undst Neurl&Cogn Sys","04/01/2019","08/10/2018","Carolyn Parkinson","CA","University of California-Los Angeles","Standard Grant","Jonathan Fritz","03/31/2023","$976,747.00","Mason Porter","cparkinson@ucla.edu","10889 Wilshire Boulevard","LOS ANGELES","CA","900951406","3107940102","SBE","7980, 8624","8089, 8091, 8551, 8817","$0.00","Human thought and behavior is embedded in social contexts. However, research on social networks and neural information processing are almost always conducted in isolation. Cognitive neuroscientists typically study mental processing without considering how individuals are influenced by their social networks, and the structure and dynamics of social networks are usually studied without considering the workings of the minds that comprise them. This research effort integrates theory and methods from cognitive neuroscience and network science to test how the brain shapes and is shaped by its social context. It will synthesize and extend recent developments in social cognitive neuroscience and network science to test how individual differences in unconstrained processing of naturalistic stimuli shape and are shaped by individuals' positions in a real-world social network. <br/><br/>This project will characterize the multirelational social network of a bounded community based on all members' reported relationships and interactions with each other. A subset of the members will complete a series of functional magnetic resonance imaging (fMRI) studies involving free-viewing of audiovisual stimuli. This project is grounded in prior work that suggests that inter-subject similarities of fMRI response time series predict distances between people in their social network, but extends that work in four novel directions. First, by capitalizing on developments in multilayer network analysis, which will also be advanced further, the research will relate neural response similarities to distances between individuals within and across layers of their shared social network. This will yield insight into the extent to which associations between social network proximity and inter-individual similarities in neural responding are specific to friendship or extend more generally to homophily. Second, integrating multilayer network analysis and longitudinal fMRI will elucidate the extent to which neural response similarities cause or result from proximity between individuals in the multirelational social network of their community. Third, pairing multilayer network methods and longitudinal fMRI will shed light on how a person's importance across interaction types in a social network may relate to his/her influence on how other network members process the world around them. Fourth, the project will relate social network position to inter-individual neural variability not only in terms of fMRI response time series, but also in terms of multi-voxel response patterns corresponding to high-level event representations and how such representations are stored in memory. This work will also develop and advance approaches for analyzing multirelational networks; this will be useful to the broad range of scholars who study network phenomena, particularly in social and brain networks.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1815971","CIF: Small: Learning on Graphs","CCF","Special Projects - CCF","06/15/2018","06/11/2018","Francois Meyer","CO","University of Colorado at Boulder","Standard Grant","Phillip Regalia","05/31/2022","$426,527.00","","fmeyer@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","CSE","2878","075Z, 7923, 7935, 8089, 8091","$0.00","Not unlike road networks, significant disruptions in the pattern of connections between brain regions have profound effect on brain function. International projects, such as the Human Connectome Project and the Autism Brain Imaging Data Exchange initiative, provide open access to massive datasets that can be used to learn the association between brain connectivity and psychiatric or neurological diseases. This award responds to the current lack of analytical and computational methods to quantify changes in the organization of brain functional networks. This project proposes to design novel machine learning algorithms that will lead the way toward precision medicine in psychiatry and neurology. The award will train several graduate students to work on big-data challenges in precision medicine. The source code that will implement the algorithms will be made publicly available in the form of open source toolboxes.<br/><br/>The availability of large datasets composed of graphs creates an unprecedented need to invent tools in statistical learning to study ""graph-valued random variables"". The first goal of this project is to develop theory and algorithms to estimate the mean and variance of a set of graphs. This basic problem is at the core of several statistical inference problems about population of graph ensembles. The second aim is to develop statistical methods that can detect significant structural changes (e.g., alteration of the topology and connectivity, etc.) in a time series of graphs. The third aim is concerned with the question of learning functions defined on a graph ensemble. The proposed approach relies on the ability to equip a graph ensemble with a metric, effectively turning the learning problem into the question of extending functions defined on a metric space.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1760950","Spokes: MEDIUM: WEST: Breaking down barriers for reproducible neuroimaging data analyses","OAC","BD Spokes -Big Data Regional I, Cognitive Neuroscience, Robust Intelligence","09/15/2018","06/23/2020","Russell Poldrack","CA","Stanford University","Standard Grant","Kenneth Whang","08/31/2022","$599,904.00","Krzysztof Gorgolewski","poldrack@stanford.edu","450 Jane Stanford Way","Stanford","CA","943052004","6507232300","CSE","024Y, 1699, 7495","028Z, 040Z, 8083, 8089, 8091","$0.00","This project will enable the reproducible analysis and sharing of large human brain imaging datasets.  Imaging the brain using magnetic resonance imaging (MRI) is an essential tool for the study of the human brain, but the processing of large neuroimaging datasets is often a difficult and time-consuming process. This project will improve the ability of researchers to analyze these data more effectively and share the results.  This work will build upon the OpenNeuro project, which provides researchers with the ability to easily upload and share neuroimaging data. The first aim of this project is to develop the ability to process these datasets using national supercomputing resources. Because these resources are both much more powerful and more cost-effective than commercial cloud computing resources, this extension will allow researchers to process larger datasets using more sophisticated analysis procedures.  The second aim is to extend the reach of data storage and processing beyond standard neuroimaging datasets to include heterogeneous datasets with clinical and psychological data in addition to brain imaging data. A large study of human brain development will be used as a test case for this extension. The third aim of this project is to engage researchers and software developers in order to develop a broad community that will further extend the reach and capabilities of the proposed technical developments and promote the sustainability of the resources beyond the grant period.<br/><br/>The first aim will implement the ability to execute computational workflows using national supercomputing resources through a Science-As-A-Service model, via technologies such as the Agave API and the Singularity container system.  This will provide the ability for researchers to execute complex containerized workflows using large datasets, providing a long-term sustainable computational platform for analysis of open data. The second aim will involve the extension of the current OpenNeuro platform to represent data from a large longitudinal neurodevelopmental study, in order to allow the joint analysis of imaging, clinical, psychological, and genetic data.  The third aim will engage the relevant user and developer communities through workshops and code sprints.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1835309","NCS-FO: Leveraging Deep Probabilistic Models to Understand the Neural Bases of Subjective Experience","DGE","ECR-EHR Core Research, IntgStrat Undst Neurl&Cogn Sys","08/15/2018","04/10/2019","Jan-Willem van de Meent","MA","Northeastern University","Standard Grant","Gregg Solomon","07/31/2022","$999,375.00","Jennifer Dy, Ajay Satpute, Sarah Ostadabbas, John Hutchinson","j.vandemeent@northeastern.edu","360 HUNTINGTON AVE","BOSTON","MA","021155005","6173733004","EHR","7980, 8624","8089, 8091, 8551, 8817","$0.00","An interdisciplinary team of researchers at Northeastern University, including experts in deep learning and probabilistic programming, the cognitive neuroscience of emotion, computational methods in neuroimaging, probabilistic modeling, and computer vision, will engage in an integrated computational and neuroscientific research effort to understand the neural bases of subjective experience. Different individuals experience the same events in vastly different ways, owing to their unique histories and psychological dispositions. For someone with social anxieties, the mere thought of leaving the home can induce a feeling of panic. Conversely, an experienced mountaineer may feel quite comfortable balancing on the edge of a cliff. This variation of perspectives is captured by the term subjective experience. Despite its centrality and ubiquity in human cognition, it remains unclear how to model the neural bases of subjective experience. The proposed work will develop new techniques for statistical modeling of individual variation and apply these techniques to a neuroimaging study of the subjective experience of fear. Together, these two lines of research will yield fundamental insights into the neural bases of fear experience. More generally, the developed computational framework will provide a means of comparing different mathematical hypotheses about the relationship between neural activity and individual differences. This will enable investigation of a broad range of phenomena in psychology and cognitive neuroscience. The work has further implications for other fields in which there are individual differences in subject experience, such behavioral medicine and the study of stress in the workplace or STEM education and the study of math or test anxiety. This project is funded by Integrative Strategies for Understanding Neural and Cognitive Systems (NSF-NCS), a multidisciplinary program jointly supported by the Directorates for Computer and Information Science and Engineering (CISE), Education and Human Resources (EHR), Engineering (ENG), and Social, Behavioral, and Economic Sciences (SBE). <br/><br/>The project will develop a new computational framework for modeling individual variation in neuroimaging data and use this framework to investigate the neural bases of one powerful and societally meaningful subjective experience, namely, of fear. Fear is a particularly useful assay because it involves variation across situational contexts (spiders, heights, and social situations), and dispositions (arachnophobia, acrophobia, and agoraphobia) that combine to create subjective experience. In the proposed neuroimaging study, participants will be scanned while watching videos that induce varying levels of arousal. To characterize individual variation in this neuroimaging data, the investigators will leverage advances in deep probabilistic programming to develop probabilistic variants of factor analysis models. These models infer a low-dimensional feature vector, also known as an embedding, for each participant and stimulus. A simple neural network models the relationship between embeddings and the neural response. This network can be trained in a data-driven manner and can be parameterized in a variety of ways, depending on the experimental design, or the neurocognitive hypotheses that are to be incorporated into the model. This provides the necessary infrastructure to test different neural models of fear. Concretely, the investigators will compare a model in which fear has its own unique circuit (i.e., neural signature or biomarker) to subject- or situation-specific neural architectures. More generally, the developed framework can be adapted to model individual variation in neuroimaging studies in other experimental settings.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1651396","CAREER: Statistical Tools for Tracking Synaptic Plasticity in Neural Spiking Data","IIS","Robust Intelligence, Modulation","06/01/2017","05/22/2018","Ian Stevenson","CT","University of Connecticut","Continuing Grant","Kenneth Whang","05/31/2022","$452,340.00","","ian.stevenson@uconn.edu","438 Whitney Road Ext.","Storrs","CT","062691133","8604863622","CSE","7495, 7714","1045, 7495, 8089, 8091","$0.00","This project aims to develop new statistical tools for understanding how synapses between neurons change over time. Synaptic changes are the basis for flexible information processing, learning, memory, and recovery from injury in the brain, but, since neural activity is highly variable, studying synaptic changes in behaving animals is a major challenge. The research described in this proposal will address this challenge by developing novel statistical methods that infer changes in synaptic strength based on neural spiking activity. In parallel with the research plan, this project will also implement a set of tutorials and workshops to improve the training of undergraduate and graduate students in neural data analysis. These resources aim to improve the reliability and reproducibility of neuroscience research and better prepare experimental neuroscientists to contribute to and benefit from large-scale data and code sharing.<br/><br/>The proposed research will develop a statistical model-based framework that allows time-varying synaptic weights to be inferred from spiking data alone and apply these methods to characterize plasticity on multiple timescales in vivo. Through close collaboration with experimentalists, the models will first be validated and refined on isolated, well studied neural systems with known connectivity. The models will then be extended to address the additional sources of variability in larger populations of neurons with unknown connectivity. This framework will be applied to determine 1) how synaptic plasticity interacts with brain state and 2) how short- and long-term plasticity interact in vivo. By using multi-electrode spike recordings, the statistical tools developed here will allow synaptic plasticity to be quantified on a larger scale than previously possible and will allow new comparisons of plasticity across cell types, brain areas, and behaviors. By shedding light on how synapses change over time, this work may ultimately lead to a better understanding of disease and injury and advance the development of neurally-inspired technologies.<br/>"
"1605646","Probing Neural Connectivity at Multiple Temporal Scales","CBET","Engineering of Biomed Systems, IntgStrat Undst Neurl&Cogn Sys","09/01/2016","05/21/2021","Laleh Najafizadeh","NJ","Rutgers University New Brunswick","Standard Grant","Stephanie George","08/31/2022","$435,917.00","David Margolis","laleh.najafizadeh@rutgers.edu","33 Knightsbridge Road","Piscataway","NJ","088543925","8489320150","ENG","5345, 8624","8089, 8091, 9102","$0.00","1605646 - Najafizadeh<br/><br/>The brain is a highly complex dynamic system in which neural functional connections are continuously changing at multiple time scales. These changes can occur at very short scales, for example due to learning a simple task, or at relatively longer scales, due to wide range of reasons, such as learning complex concepts, brain-related diseases (e.g. Alzheimer's and depression), and going through rehabilitation. Currently, our understanding of how the neural functional interactions form and change with time has been very limited because of lack of 1) quantitative measures that can reliably characterize these changes at different time scales, and 2) the ability to continuously monitor and record brain activities at different time scales, from millisecond to days and weeks. This project aims to address these limitations by taking a combined theoretical-experimental approach to establish a data-driven computational framework with new quantitative measures that can characterize the temporal evolution of dynamics of brain functional networks, across short-and long time scales. To further broaden the capabilities of the framework, this project will take a step further to consider scenarios where the brain network structure has been manipulated, and will computationally and experimentally investigate how brain networks reorganize and change with time in response to transient, localized manipulations of the network structure. The outcome of this project will have a transformative impact in the field of neuroscience by introducing a powerful computational framework for quantifying the dynamics of brain networks that have been evaluated experimentally under various conditions. The project will also provide a unique opportunity for the graduate and undergraduate students to obtain multidisciplinary expertise at the intersection of signal processing, statistics, neurobiology and imaging, thus providing an ideal platform for the training of the next generation engineers and neuroscientists.<br/><br/><br/>One of the fundamental problems in the field of neuroscience and brain mapping is the lack of a generalized computational framework with reliable quantitative measures for characterizing the changes that occur in the functional interactions among brain networks at multiple temporal scales. The focus of this three-year project is to establish a comprehensive data-driven quantitative framework, which will enable studying and quantitatively characterizing the dynamic properties of brain functional networks at multiple temporal scales. With a focus on somatosensory learning, this research will use the proposed framework along with chronic imaging in GCaMP6f reporter mice, to quantitatively examine 1) how the interactions among functional brain networks are modified by task performance (short term changes), 2) how such interactions differ over days when mice finally becomes expert in performing the task (long term changes), and 3) how manipulating different nodes in the network, will change dynamics of brain functional interactions. This project, via combined theoretical-experimental studies, will introduce innovative approaches at three frontends. First, a systematic data-driven approach for quantitatively analyzing the temporal evolution of dynamics of brain functional networks at different temporal scales will be established. The aim is to represent the functionality of the brain networks with a multi-layer network, in which layers are labeled by time. Second, using state-of-the-art chronic imaging in GCaMP6f reporter mice, the project will monitor network activities at several temporal scales, from fast millisecond to those that occur on a slower time scale of days to weeks. The joining of quantitative analysis with in vivo imaging brings a powerful approach to the understanding of behavior-related dynamic changes in the cortical network. Third, to strengthen the capabilities of the framework, quantitatively and experimentally (using simulations as well as inactivation methods during imaging), the project investigates how the functional network is altered by transient, localized manipulations of network structure.  The outcomes will be particularly important for advancing understanding of the dynamics of functional reorganization of the brain networks after stroke or injuries. The success of this project, by including the temporal dimension into the analysis, will have a transformative impact in the field of neuroscience. The new comprehensive framework will enable quantitative assessment of studying short-term and long-term network changes to advance our understanding of the dynamics of functional reorganization of the brain. The unique rich data set that will be generated through the state-of-art imaging system in this project along with the framework will provide important information on how cortical network activity changes across fast and slow time scales as related to learning. The outcomes of this research will have a significant impact in the clinical domain, helping the development of the next generation of personalized rehabilitation technology.  In addition, the proposed research work is multidisciplinary as it covers topics from signal processing, statistics and engineering to neurobiology, imaging and neuroscience, thus providing a unique opportunity for the graduate and undergraduate students involved in the project to gain new learning experiences."
"1715858","CHS: Small: Collaborative Research:  EEG-Guided Electrical Stimulation for Immersive Virtual Reality","IIS","HCC-Human-Centered Computing, IntgStrat Undst Neurl&Cogn Sys","10/01/2017","08/24/2017","Deniz Erdogmus","MA","Northeastern University","Standard Grant","Ephraim Glinert","09/30/2021","$142,000.00","","erdogmus@ece.neu.edu","360 HUNTINGTON AVE","BOSTON","MA","021155005","6173733004","CSE","7367, 8624","7367, 7923, 8089, 8091","$0.00","Spatial presence, in Virtual Reality (VR) terminology, refers to the perception (or illusion) of being physically present in a simulated environment.  VR strives to create interactive environments that provide experiences of spatial presence through accurate delivery and perception of multimodal sensory stimuli.  Research in VR spans fields ranging from neuroscience and medicine to gaming.   While the computing and gaming industries have generated tremendous advances in hardware and software for graphics processing and 3D display technologies, VR systems still lack capabilities for providing users with haptic feedback (a sense of touch), which is crucial for generating truly immersive, real-world experiences.   It is known that an increase in the feeling of spatial presence manifests itself in the form of increased brain activity.   This research aims to achieve the control of haptic sensory stimulation adaptively, based on the changes in brain activity associated with perceptual responses elicited by sensory stimulation in VR environments.  Project outcomes will include novel scientific discoveries and engineering enhancements that will make significant contributions to other areas of interest, such as prosthetic limbs, augmented reality, and telepresence applications.  The project will help train a new generation of engineers skilled in addressing multidisciplinary challenges, while through outreach activities STEM careers will be promoted at the K-12 level.<br/><br/>The research objective is to identify and analyze brain activity associated with the increased feeling of haptic spatial presence elicited by electro-tactile stimulation and measured through EEG, and to investigate closed-loop techniques to control electro-tactile stimulation for enhanced haptic presence in VR environments.  Specifically, the project will: (1) develop an electrical haptic stimulation framework; (2) design analysis techniques to identify markers of haptic inputs in EEG; (3) establish control policies for adaptive electrical stimulation; and (4) evaluate and refine EEG-guided adaptive stimuli control framework in VR environments.  In particular, the proposition to actuate haptic feedback through electrical stimulation is novel, while formulating design principles for model-based optimal EEG-guided closed-loop haptic feedback for immersive spatial presence is transformative.  Additional innovative propositions to advance adaptive control under uncertainty and psychophysical investigations are unique; these present a potentially game-changing opportunity for VR system development and perhaps for general human-computer interaction."
"1923129","Studying the Neural Basis of Numeracy Using the Lesion Method","BCS","Cognitive Neuroscience, IntgStrat Undst Neurl&Cogn Sys","09/01/2019","08/28/2019","Julie Fiez","PA","University of Pittsburgh","Standard Grant","Jonathan Fritz","08/31/2022","$668,330.00","","fiez+@pitt.edu","300 Murdoch Building","Pittsburgh","PA","152133203","4126247400","SBE","1699, 8624","1699, 8089, 8091","$0.00","The ability to engage in mathematical thought is central to an individual's ability to thrive modern society. This project will investigate the neural basis of this ability by studying individuals with brain injury due to stroke. The goal is to understand how and where localized brain injury leads to impairments in math skills, thereby revealing the parts of the brain that are crucial for normal function. The work will examine the ability to make judgments about magnitude, a fundamental skill thought to rest upon an innate approximate number system, as well the abilities that rest upon cultural transmission of symbol systems for number (e.g., through classroom instruction). The relationship between these different types of skills, and their neural substrates, remains a point of significant debate. To make progress, stroke survivors will participate in the study. All participants will complete a magnetic resonance imaging (MRI) session to acquire images of their brain, and a set of behavioral tasks probing sensory, motor, language, general cognitive, and mathematical abilities. A series of statistical analyses will combine the brain and behavioral data, in order to identify sites of brain injury that are associated with: (1) specific impairments in approximate number representation and estimation, (2) specific impairments in precise number representation and calculation, and (3) impairments in math ability that are secondary to impairments in language or more general cognitive functions. The work should help to adjudicate between theories of math ability and inform future studies examining math learning and intervention strategies for struggling learners. Importantly, the project will be deeply intertwined with undergraduate education and research mentorship. This will occur by embedding the data collection into an advanced undergraduate laboratory course and summer research internship programs, with graduate students contributing to the instruction. The result will be a multilayered, interdisciplinary, and diverse learning context for experiential science learning that will be of broad educational impact. Additionally, at the conclusion of the project the data (without identifying information) will be placed into an open repository for neuroscience research. No other dataset like this currently exists, and so this will give researchers access to unique and highly valuable dataset that will be suitable for addressing many research questions.<br/><br/>The lesion method involves studying patterns of preserved and impaired abilities in participants with brain damage. By combining information about patterns of behavioral performance and corresponding locations of neural damage, causal inferences can be drawn about the functions supported by particular brain regions and their white matter connections. This project will use the lesion method to investigate the relationship between different aspects of numeracy. The participants in the study will be ~ 160 individuals with left-hemisphere focal brain lesions, and an exploratory group of ~ 40 individuals with right-hemisphere lesions. All participants will complete a neuroimaging session to acquire structural and functional brain volumes, and a battery of behavioral tasks probing sensory, motor, general cognitive, linguistic, and mathematical abilities. Participants with evidence of impaired numeracy, or aphasia without intact numeracy, will be invited to return for a second behavioral-only session. This secondary assessment will involve a battery of tasks that will probe numeracy skills in greater depth, as well as general cognitive abilities relevant for skilled math performance. For the primary analyses, voxelwise lesion symptom mapping (VLSM) analyses will be used to test predictions derived from theoretical models of numeracy. These include the predictions that impairments in number comparison will be associated with damage to the inferior parietal sulcus, impairments in verbal fact retrieval will be associated with damage to the angular gyrus, and impairments in ordinality will be associated with damage to premotor cortex. Secondary analyses will permit more detailed examination of associations and dissociations across our numeracy, language, and cognitive tasks. This will include the use of principal components analysis and other data-driven techniques to discover patterns of impairments across our battery of tasks and test for associated loci of neural damage. Finally, exploratory analyses will probe for hemispheric differences in the representation of number.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2100138","Collaborative Research: Learning Preferences and Domain Differences in Design Fixation","DRL","ECR-EHR Core Research","09/01/2021","05/21/2021","John Gero","NC","University of North Carolina at Charlotte","Continuing Grant","Gregg Solomon","08/31/2024","$364,261.00","","jgero1@uncc.edu","9201 University City Boulevard","CHARLOTTE","NC","282230001","7046871888","EHR","7980","8089, 8091, 8817","$0.00","Learning to design in formal engineering and design education often involves the study of existing designs as examples. Research has shown that the use of pictorial examples during the presentation of design problems can support the learning of engineering principles and design constraints. But it can also bias designers and engineering design students toward replicating the examples they were shown, even in the presence of explicit instructions not to do so, rather than seeking innovative alternative solutions. This phenomenon is known as design fixation?the tendency to adhere to elements of prior ideas or solutions to a problem. Design fixation is a significant barrier to the generation of new design ideas and creative problem solving. Intriguingly, preliminary research on engineering education has suggested there is a disciplinary difference in the tendency to show design fixation to pictorial examples, such that industrial designers are markedly less likely to fixate than are mechanical engineers. The goal of this project, a collaboration between cognitive neuroscience researchers at Drexel University and design scientists at the University of North Carolina, is to focus on this difference as a means of understanding the cognitive and neural processes underlying design fixation. The driving hypothesis is that, as a result of their training, mechanical engineering students are more likely to fixate because they are less apt to draw on abstract principles. The studies will involve a combination of behavioral and brain imaging studies of first year and fourth year undergraduate students in different design disciplines. The results of this project will have the potential to generalize across much of STEM education by informing the development of curricula to ward off design fixation. This award is made by the EHR Core Research (ECR) program, which supports work that advances the fundamental research literature on STEM learning.<br/><br/>Drawing on the research literature in cognitive science, cognitive neuroscience, engineering education, and design science, this project will examine the premise that there are differences between undergraduate industrial design and mechanical engineering students in their tendencies to show design fixation and that these differences are arise from instruction that emphasizes the of abstraction (rule-based) learning in the former discipline and exemplar-based learning in the latter. The project will examine whether differences between students during concept building, captured by both behavioral and neural measures, can predict design fixation patterns. The researchers will collect multimodal data from first year and senior industrial design and mechanical engineering students on a design fixation task and a control design task. They will quantify design fixation behaviorally through (a) the coding of sketches according to an established design categorization scheme, and (b) the coding of verbal protocols with the established Function-Behavior-Structure (FBS) ontology for design. The FBS ontology segmentation and coding of verbal protocols will then be used in a novel attempt to analyze neural responses during the design fixation and control tasks. The behavioral and neural differences in learning tendencies ? rule-based and exemplar based ? between students in the two disciplines will then be used to predict behavioral and neural differences in design fixation. Ultimately, the investigators aim to put forth a mechanistic account of design fixation, grounded in cognitive neuroscience and design theory and practice, that will inform the development of instructional interventions.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1724297","CRCNS US-French Research Proposal: Architectural Principles and Predictive Modeling of the Mammalian Connectome","IIS","Cognitive Neuroscience, Cross-BIO Activities, CRCNS-Computation Neuroscience, IIS Special Projects, IntgStrat Undst Neurl&Cogn Sys","10/01/2017","09/22/2017","Zoltan Toroczkai","IN","University of Notre Dame","Continuing Grant","Kenneth Whang","09/30/2021","$534,193.00","","toro@nd.edu","940 Grace Hall","NOTRE DAME","IN","465565708","5746317432","CSE","1699, 7275, 7327, 7484, 8624","7327, 8089, 8091","$0.00","This US-France collaborative project is aimed at discovering the fundamental properties of the structural/anatomical organization of cortical connections capable of supporting massive amounts of computations in the brain, despite the 100,000-fold variation in mass from the smallest mammals to the largest. Several independent empirical observations (such as sensory substitution experiments) suggest the existence of common network architectural principles in the mammalian cortex, critical for efficient and hierarchically modular information processing. Through capturing these fundamental structural and dynamical features in large-scale neuronal networks across several species, this project will help with our understanding of information processing in the human brain. It will also inform the emerging field of neuromorphic engineering, which focuses on bio-inspired computational devices. The outcomes of this project may also be relevant to neuro-degenerative diseases, given the growing evidence suggesting that disease progression often occurs via the breakdown of high-centrality, long-range connections between cortical areas, which will be characterized within this project.<br/><br/>By extending empirical, consistent tract-tracing databases for the physical network of interareal cortical connections in the macaque and mouse (supplemented by dMRI tractography data) and exploiting recent discoveries related to the Exponential Distance Rule (EDR) (which has been empirically demonstrated in several mammals), this project aims to capture the network architectural invariants of the cortex. These invariants are graph theoretical properties of the connectome that are preserved across mammalian brains and across scales. Based on recent empirical evidence, the project puts forward the hypothesis that the EDR also plays a critical role in generating sparse encoding of highly correlated information streams in a scale-invariant manner, a hypothesis that will be tested within a predictive modeling approach.  The work will also generate novel imputation algorithms suitable for dense networks and novel, efficient algorithms for comparing species connectomes, exploiting the spatial embeddedness of these networks.<br/><br/>A companion project is being funded by the French National Research Agency (ANR)."
"1734944","Collaborative Research: NCS-FO: Connecting Spikes to Cognitive Algorithms","IIS","IntgStrat Undst Neurl&Cogn Sys","01/01/2018","08/07/2017","Alexander Huk","TX","University of Texas at Austin","Standard Grant","Kenneth Whang","12/31/2021","$234,752.00","","huk@mail.utexas.edu","3925 W Braker Lane, Ste 3.340","Austin","TX","787595316","5124716424","CSE","8624","8089, 8091, 8551","$0.00","Experimental neuroscientists can record the signals communicated among the neurons that are collectively involved in producing meaningful behaviors, but making sense of these patterns of activity in terms of specific mental functions is challenging. This research project aims to discover the unseen mental processes that underlie such meaningful behavior from those recordings. The technology developed in this endeavor will uncover new ways of understanding mental processes hidden deep in the noisy signals collected from multiple neurons and will be used to derive new theoretical models (cognitive algorithms) to explain how populations of neurons work together. Such models will contribute to the development of diagnostic tools and neural prosthetics for cognitive dysfunctions in perception, working memory, and decision making, and can also inspire advances in machine learning and artificial intelligence.<br/> <br/>The technical goal of this project is to develop a data-driven framework amenable to visualization and interpretation of neural activity underlying cognition. The core of the project is the identification and recovery of an interpretable low-dimensional nonlinear continuous dynamical system that underlies observed neural time series, and its validation through experimental perturbations. This will answer two key scientific questions: (1) How are task and cognitive variables represented in low-dimensional neural trajectories; and (2) What are the laws that govern the time evolution of the neural states. Answering these questions will help us understand how subjects implement and switch between different cognitive strategies, and more importantly, will provide a means for testing previously proposed theoretical models of the neural computations underlying cognition. This project will develop a number of statistical methods that can (i) extract private and shared noise from single-trial electrophysiological observations, (ii) combine recordings from multiple sessions to infer a common cognitive neural dynamics model, and (iii) design control stimulation to perturb the current neural state. Specifically, these tools will be applied to recordings from cortical areas involved in visuomotor decision-making to discover (1) how the co-variability in a population of sensory neurons encodes decision variables, (2) how the cognitive strategy changes when sensory evidence statistics change, and (3) the underlying dynamics that sustain spatial working memory. The success of this project could transform how the field analyzes population activity with low-dimensional structure in the context of cognitive tasks and beyond."
"2055420","The neurobiological mechanisms underlying gesture?s role in mathematical learning","DRL","ECR-EHR Core Research","07/01/2021","05/21/2021","Susan Goldin-Meadow","IL","University of Chicago","Continuing Grant","Eric Knuth","06/30/2026","$888,123.00","Marc Berman","sgm@uchicago.edu","6054 South Drexel Avenue","Chicago","IL","606372612","7737028669","EHR","7980","8089, 8091, 8817","$0.00","All speakers gesture when they talk. Gestures are a type of action??an action done in the air that does not directly affect objects. Both gestures and actions-on-objects can promote learning, but having gesture as part of a math lesson makes it easier to remember and extend that lesson than having action as part of the lesson. This program of research uses neural data to figure out why. Two hypotheses, both of which might be correct, are possible: (1) Gesture promotes learning by helping children abstract beyond particular exemplars used in instruction. (2) Action impedes learning by tying children to the particulars of the exemplars used in instruction. It is difficult to disentangle these two mechanisms at the behavioral level because both hypotheses lead to the same outcome??better learning following gesture than action. The research uses neuroimaging to measure activity during a math lesson and determine whether different areas of the brain are activated during gesture- vs. action-based instruction. Understanding the neural processes that underlie learning through gesture vs. action can help distinguish between these two hypotheses, and lead to more finely tuned recommendations to teachers for using these tools in the classroom. <br/><br/>The research program aims to distinguish between the two hypotheses in a math lesson under two conditions: when children observe an instructor produce gestures or actions (Study 1); when children themselves produce gestures or actions (Study 2). Study 1 uses fMRI (functional magnetic resonance imaging) and Study 2 uses fNIRS (functional near infrared spectroscopy) to measure neural activity while 8- to 10-year-old children in 3rd and 4th grade receive gesture- or action-based instruction in the pre-algebra concept of math equivalence (the notion that two sides of an equation must be equal). Neural activity in abstraction areas is expected to occur during gesture instruction; neural activity in object areas is expected to occur during action instruction). Differences in neural processes during instruction will be used to predict children?s learning outcomes after instruction. fNIRS is a new technology that has been underused in educational neuroscience, but has the potential to be used in the classroom to measure neural activity during learning from multiple students simultaneously. This work is an early step in testing that possibility.<br/><br/>This project is funded by the EHR Core Research (ECR) program, which supports work that advances fundamental research on STEM learning and learning environments, broadening participation in STEM, and STEM workforce development.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1912280","CRCNS US-France Research Proposal: Oscillatory processes for visual reasoning in deep neural networks","IIS","Perception, Action & Cognition, CRCNS-Computation Neuroscience, IntgStrat Undst Neurl&Cogn Sys","12/01/2019","08/30/2019","Thomas Serre","RI","Brown University","Standard Grant","Kenneth Whang","11/30/2022","$548,809.00","","Thomas_Serre@brown.edu","BOX 1929","Providence","RI","029129002","4018632777","CSE","7252, 7327, 8624","7327, 8089, 8091, 9150","$0.00","The development of deep convolutional networks (DCNs) has recently led to great successes in machine vision. Despite these successes, to date, the most impressive results have been obtained for image categorization tasks such as indicating whether an image contains a particular object. However, DCNs ability to solve more complex visual reasoning problems such as understanding the visual relations between objects remains limited. Interestingly, much work in computer vision is currently being devoted to extending DCNs, but these models are still outmatched by the power and versatility of the brain, perhaps in part due to the richer neuronal computations available to cortical circuits. The challenge is to identify which neuronal mechanisms are relevant and to find suitable abstractions to model them. One promising set of candidates is the neural oscillations that are found throughout the brain.  This project seeks to identify the key oscillatory components and characterize the neural computations underlying humans ability to solve visual reasoning tasks, and to use similar strategies in modern deep learning architectures.<br/><br/>This project will use existing computational models to develop tasks and stimuli to be used in EEG studies to identify the key oscillatory components underlying human visual reasoning ability. The analysis of these EEG data will be guided by the development of a biophysically-realistic computational neuroscience model. This will inform the development of hypotheses on the circuit mechanisms underlying the oscillatory clusters and relate these mechanisms to neural computations. Finally, the project will develop novel machine learning idealizations of these neural computations, which are trainable with current deep learning methods but still interpretable at the neural circuit level.  In particular, the project will further develop initial machine learning formulation of oscillations based on complex-valued neuronal units, thus extending the approach and demonstrating its ability to qualitatively capture key oscillatory processes underlying visual reasoning. <br/><br/>A companion project is being funded by the French National Research Agency (ANR).<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1652617","CAREER: Understanding Vision and Natural Motion Statistics Through the Lens of Prediction","IIS","Robust Intelligence","03/01/2017","01/28/2019","Stephanie Palmer","IL","University of Chicago","Continuing Grant","Kenneth Whang","02/28/2022","$549,880.00","","sepalmer@uchicago.edu","6054 South Drexel Avenue","Chicago","IL","606372612","7737028669","CSE","7495","1045, 7495, 8089, 8091","$0.00","The visual input to the brain is transformed even before signals leave the eye, and these computations produce an efficient representation of the structure of the natural visual world. Previous work by the PI has shown that this processing can include repackaging of information for optimal prediction. This suggests a new approach to neural encoding. While many previous studies have sought to characterize what stimuli in the past gave rise to a subsequent response, this work asks what future stimuli those responses predict. The proposed project will derive the best possible predictor given the way objects move in the outside world and quantify how close the brain gets to this optimum. Viewing the brain through the lens of prediction develops a principle of neural coding and computation that can bridge brain regions, from the retina to higher visual areas. A component of this plan involves measuring and quantifying the predictive components of natural motion. In doing so, a public database of natural motion will be created that will be a lasting tool for the neuroscience and computer vision communities. An associated educational program will bring over 100 local middle school children to campus each year for hands-on neuroscience experiments, and will instill in a large group of graduate students the rewards and responsibilities of science teaching.<br/><br/>The research proposed here explores prediction in the visual system in a variety of ways: by computing efficiency bounds on the predictive encoding of complex motion, by developing quantitative methods to test these bounds in neural datasets, by measuring the statistics of motion in natural scenes, and by describing how, mechanistically, the brain achieves this performance. Hypotheses about how the brain performs optimal predictive computations may be constrained by the structure of predictable events in the natural visual world. To measure these statistics, a new natural movie database will be constructed by making high-speed, high-pixel-depth recordings of natural scenes. By quantifying motion in these data, this project will yield statistical and generative models of natural motion that will inform our understanding of the natural world and provide a compact way to recapitulate natural motion in silico. These stimuli will be used to test whether neural systems optimally encode information relevant for prediction. The work will also test what adaptive and otherwise non-linear processing steps underlie optimal prediction in the brain.<br/>"
"1654089","CAREER: Neural investigations of magnitude processing as a pathway to understanding mathematical thinking","BCS","Cognitive Neuroscience, ECR-EHR Core Research","03/01/2017","05/20/2021","Joonkoo Park","MA","University of Massachusetts Amherst","Continuing Grant","Jonathan Fritz","02/28/2022","$676,574.00","","joonkoo@umass.edu","Research Administration Building","Hadley","MA","010359450","4135450698","SBE","1699, 7980","1045, 1699, 8089, 8091","$0.00","Similar to the development of language, the creation and use of mathematics is a uniquely human ability. Nevertheless, despite our success in using mathematics, little is understood of the unique cognitive and neural processes that support this ability. A full explanation of mathematical ability is critical not only for furthering basic science, but also because this understanding may give rise to more effective math education. There is increasing evidence that our sense of magnitude (allowing us to judge which is more and which is less without counting or using numerical symbols) provides a rudimentary foundation for mathematical thinking. Investigations into the neural basis of magnitude processing have focused on a particular region of the brain, the intraparietal sulcus. However, simply labeling a brain region as the source of magnitude processing does not explain how magnitudes are actually processed or how magnitude processing supports more complex mathematical thinking. This project seeks to investigate the anatomy and function of the neural pathways involved in magnitude processing, thereby identifying the neural mechanisms that support this core aspect of mathematical thinking. Furthermore, by relating these results to individual differences in more complex mathematical ability, this research seeks to provide novel insights into the factors that underlie successful math education practices. <br/><br/>The overarching goal will be achieved in a series of electroencephalography  and functional magnetic resonance imaging studies, with three objectives. First, this project will determine the functional characteristics of non-symbolic magnitude representations in the visual processing pathway with the hypothesis that there exists a temporal evolution of visual representation, from a very rapid and purely sensory representation to a slower conceptual representation of numerical magnitude in the visual stream. Second, this project will identify the neuroanatomical substrates of numerical magnitude, and test the hypothesis that the brain uses different processing pathways to represent magnitudes with different numerical values. Third, using a novel methodological approach that provides a reliable neural measure at the individual level, this project will test the hypothesis that each individual's neural sensitivity to magnitude predicts that individual's math skill level. With regard to theory construction, the project will provide insights into understanding the neurocognitive basis of an important foundation for mathematical thinking. With regard to influencing practice, this project may help us understand the relationship between non-symbolic magnitude processing and learned, symbolic mathematical competence, thereby providing opportunities to improve math education. Furthermore, this project itself offers educational opportunities for training undergraduates, high school students, and underrepresented students as well as for engaging children and their families with diverse background in scientific research."
"1909038","RI: Small: Collaborative Research: Topology-Aware Image Understanding using Deep Variational Objectives","IIS","Robust Intelligence, IntgStrat Undst Neurl&Cogn Sys","08/15/2019","08/14/2019","Chao Chen","NY","SUNY at Stony Brook","Standard Grant","Jie Yang","07/31/2022","$244,999.00","","chao.chen.1@stonybrook.edu","WEST 5510 FRK MEL LIB","Stony Brook","NY","117940001","6316329949","CSE","7495, 8624","7495, 7923, 8089, 8091","$0.00","Image segmentation, which extracts objects of interest from given images, is a fundamental computer vision task. This project develops novel image segmentation methodology combining classic mathematical foundations and modern deep neural networks. In particular, the developed methodology will achieve high quality in segmenting fine-scale object instances, as well as their topology. Correct segmentation of fine-details and topology such as connectivity between parts is critical for downstream analysis such as reasoning about affordance of objects - what actions can be made on them - and biomedical image analysis. This project not only bridges the gap between principled mathematical theory and the practical deep image segmentation framework, but also trains the next generation of researchers and educators. Through a carefully designed integrated educational and outreach plan, the principal investigators will engage undergraduate students, high school students, women, and other underrepresented students in the research activities.<br/><br/>This project studies deep variational relaxations of segmentation problems, namely, consider the segmentation task as a continuous valued prediction problem and employ variational functionals as training loss functions for deep neural networks. The introduction of deep learning allows highly nonlinear functions to be estimated and greatly improves the capability of variational approaches such as the Mumford-Shah functional and the persistent homology, in segmenting instances with sharp boundaries and with correct topology. Applications on robotic affordance and influence prediction and medical imaging will improve state-of-the-arts in those areas. The resulting techniques and software will be validated on image segmentation, affordance and medical imaging datasets, in order to provide quantitative assessments of the proposed approaches.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1920730","Impact of Sleep Loss on Creativity and STEM Learning for First-Year College Students","DRL","ECR-EHR Core Research","06/15/2019","05/17/2021","Michael Scullin","TX","Baylor University","Continuing Grant","Gregg Solomon","05/31/2022","$1,499,721.00","A Beaujean, Steven Nelson","Michael_Scullin@baylor.edu","One Bear Place #97360","Waco","TX","767987360","2547103817","EHR","7980","8089, 8091, 8817","$0.00","More than half of all college students are habitually sleep deprived. Sleep deprivation is known to have powerful, detrimental effects generally on brain functioning, yet the extent of its specific effects on mental activity is unknown. This project, led by researchers at Baylor University, will bring together a collaborative team of sleep scientists, educators, cognitive neuroscientists, and statisticians to address theoretical and applied issues at the nexus of sleep, creativity, and STEM learning, especially those concerning whether such prolific sleep loss in students thwarts efforts to foster creativity and STEM learning. Existing theoretical frameworks posit that creative ability is not firmly set, but instead can fluctuate dynamically across hours, days, and weeks. Investigating the brain processes underlying these fluctuations in creativity, in relation to sleeping patterns and success and retention in STEM, will not only provide crucial information from a theoretical perspective, but can also provide a foundation for the development of future educational interventions. Therefore, the study findings will be disseminated broadly, in scientific as well as in formal and informal educational settings. The Project will include a collaboration with a local museum in hosting pop-up exhibits each year to disseminate the findings directly to students, parents, and teachers. The project is funded by the EHR Core Research (ECR) program, which supports work that advances the fundamental research literature on STEM learning and broadening participation in STEM fields. <br/><br/>This project will empirically investigate the interplay of sleep, creativity, and learning outcomes. A large sample of college students in a STEM major will complete a battery of tests assessing creativity, fluid intelligence, sleep habits, and science-concept learning. Structural equation modeling will assess the degree to which sleep habits and creativity have a causal influence on science-concept learning, independent of fluid intelligence. A subset of this larger sample will complete a two-phase polysomnography-monitored, cross-over experiment in which they will sleep normally and undergo multi-night sleep restriction (order counterbalanced). At the end of each phase, participants will undergo neuroimaging while performing tests of creativity, attention, and encoding. The psychometric, polysomnographic, and neuroimaging data will then be utilized to investigate longitudinal relations with STEM achievement and retention.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1912474","NCS-FO: Integrating Non-Invasive Neuroimaging and Educational Data Mining to Improve Understanding of Robust Learning Processes","DGE","ECR-EHR Core Research","09/01/2018","07/30/2019","Erin Walker","PA","University of Pittsburgh","Standard Grant","Gregg Solomon","08/31/2022","$351,509.00","","eawalker@pitt.edu","300 Murdoch Building","Pittsburgh","PA","152133203","4126247400","EHR","7980","8089, 8091, 8212, 8244, 8551, 8817","$0.00","From elementary school math games to workplace training, computer-based learning applications are becoming more widespread. With these programs, it becomes increasingly possible to use the data generated, such as correct and incorrect problem-solving responses, to develop ways to test for student knowledge and to personalize instruction to student needs. The logs of student responses can capture answers, but they fail to capture critical information about what is happening during pauses between student interactions with the software. This project, led by a team of researchers at Arizona State University and Worcester Polytechnic Institute, will explore the use of measurements of brain activity from lightweight brain sensors alongside student log data to understand important mental activities during learning. The study will examine developmental math learning in college and community college students using the ASSISTments intelligent tutoring system. Using brain imaging, the project team will examine whether students are thinking deeply about the problem or mind-wandering during pauses in the learning tasks and use the combined log and brain data to make predictions about learning outcomes. This work will build a foundation for new methods of combining neuroimaging, machine learning, and personalized learning environments. With a better understanding of when and how learning occurs during pauses in tutoring system use, learning technology researchers and developers will be able to create adaptive interventions within tutoring systems that are better personalized to the needs of the individual. This project is funded by Integrative Strategies for Understanding Neural and Cognitive Systems (NSF-NCS), a multidisciplinary program jointly supported by the Directorates for Computer and Information Science and Engineering (CISE), Education and Human Resources (EHR), Engineering (ENG), and Social, Behavioral, and Economic Sciences (SBE).<br/><br/>This project has of three goals: 1) Integrating multiple data streams for the creation of an interdisciplinary corpus; 2) Detecting real-time changes in cognitive states during pauses in log data; and 3) Predicting learning outcomes from brain-based and log-based inferences of cognitive states. In addressing these goals, the team will collect brain data, using functional near-infrared spectroscopy neuroimaging, and behavioral data from controlled, well-understood tasks related to rule learning and mind wandering and from authentic learning tasks. Cognitive neuroscience research involving recordings of brain activity traditionally requires paradigms with highly constrained stimuli, timing, and task requirements, whereas research in complex real-world environments such as tutoring systems rarely align with these paradigms. Features of the brain activity during the cognitive tasks will be used to make inferences about student cognition during authentic learning tasks. In addition, brain features will be combined with log data features to create machine learning models that make accurate predictions of student robust learning outcomes, to be assessed using a posttest given after students use the interactive learning environment. Contributions of this project to STEM learning will include improved understanding of how students build knowledge in response to instructional events within digital learning environments, the construction of better predictive models of when students learn from the use of personalized learning environments, and a mapping between learning processes and the length and context of pauses. This project will also contribute to understandings of how to combine analyses of neuroimaging data and log data.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1734735","NCS-FO: Neurobehavioral integration of visual and semantic number knowledge and its role for individual variation in the math ability of children and adults","DUE","ECR-EHR Core Research, IntgStrat Undst Neurl&Cogn Sys","09/01/2017","11/21/2017","Melissa Libertus","PA","University of Pittsburgh","Standard Grant","Gregg Solomon","11/30/2021","$982,661.00","Julie Fiez, Marc Coutanche","libertus@pitt.edu","300 Murdoch Building","Pittsburgh","PA","152133203","4126247400","EHR","7980, 8624","8089, 8091, 8551, 8817, CL10","$0.00","This project, conducted by a team of researchers at the University of Pittsburgh, will address the need to improve math abilities in American children and adults. According to the 2015 National Assessment of Educational Progress, only 40% of 4th graders, and 33% of 8th graders score at, or above, proficiency level in math, and only about 30% of US adults can complete basic mathematical processes in real-world scenarios such as looking at a thermometer and figuring out the temperature. Such poor math achievement outcomes impose significant burdens, such as in securing employment, on individuals who enter adulthood without achieving basic proficiency, and challenges the capacity of the US to remain competitive in a global economy that is strongly driven by the intellectual capital of its citizens. This project will investigate a foundational skill that underlies math achievement: the ability to recognize visual number symbols by connecting them with the quantities they represent. Using functional magnetic resonance imaging (fMRI) and behavioral measures, the project team will characterize the neural constituents of number knowledge and will test for pathways within this number network that contribute to this ""symbolic integration"" and math ability. Finally, by studying adults and 8-year-old children, they will test whether the neural substrates of symbolic integration change with age, and if so, whether these changes correspond to shifts in the behavioral profile of symbolic integration and individual difference in math ability. Overall, by focusing on the widely used, but poorly understood, construct of symbolic integration, the proposed work will have broad impact on theories of math ability that make assumptions about these underlying processes and will inform future studies examining math learning trajectories and remediation strategies for struggling math learners. This project is funded by Integrative Strategies for Understanding Neural and Cognitive Systems (NSF-NCS), a multidisciplinary program jointly supported by the Directorates for Computer and Information Science and Engineering (CISE), Education and Human Resources (EHR), Engineering (ENG), and Social, Behavioral, and Economic Sciences (SBE).<br/><br/><br/>The overarching objective of the project is to investigate whether symbolic integration is foundational to math ability in adults and children. The project leverages the larger and more established literature on word recognition to develop and test a symbolic integration hypothesis of number processing. This model posits that formal math ability rests in part upon the integration of visual symbols (i.e., Arabic numerals) with the magnitudes they represent, via both direct (visual-semantic) and indirect (visual-verbal, visual-manual) pathways. An innovative combination of neurobehavioral measures will be used to test the model, through an individual differences study involving 100 adults and 125 8-year-old children. The project team will develop a novel neuroimaging protocol and will use cutting-edge multivariate methods to efficiently and broadly identify and characterize the neural constituents of a number processing network. A likely set of regions includes those involved in visual (fusiform gyrus), verbal (angular gyrus), manual (precental gyrus), and semantic (inferior parietal cortex) coding of number. In addition, resting state data will be acquired from each participant, and used to extract a metric of connectivity between identified visual, verbal, manual, and semantic constituents of number knowledge. A pair of behavioral tasks will measure the associative strength between visual and semantic codes for number (i.e., symbolic integration) in each participant. Using general linear models (GLM), the investigators will then test the prediction that both direct (visual-semantic) and mediated (visual-verbal-semantic; visual-manual-semantic) pathways significantly contribute to symbolic integration skill. Finally, standardized measures of math ability will be obtained from each participant. A GLM will be used to test for a predicted positive relation between individual differences in symbolic integration and math ability. Overall, the work will have a broad impact on theories of math ability and will inform future studies of math learning and intervention."
"1943323","CAREER: Translating Innovations from the Sleep Laboratory to Enhance Classroom Education and Informal Science Learning","DRL","ECR-EHR Core Research","03/15/2020","05/19/2021","Michael Scullin","TX","Baylor University","Continuing Grant","Gregg Solomon","02/28/2025","$165,708.00","","Michael_Scullin@baylor.edu","One Bear Place #97360","Waco","TX","767987360","2547103817","EHR","7980","1045, 1544, 8089, 8091, 8212, 8817","$0.00","The Faculty Early Career Development (CAREER) program is a National Science Foundation-wide activity that offers awards in support of junior faculty who exemplify the role of teacher-scholars through outstanding research, excellent education, and the integration of education and research within the context of the mission of their organizations. This award to a scientist at Baylor University has the goal of improving STEM education at the undergraduate level by bridging the gap between laboratory-based and home-based studies in sleep science. Ten million American college students regularly suffer from short or poor-quality sleep, a national problem that has immediate and long-term health, social, economic, and educational consequences. Recent work indicates that sleep problems are particularly prevalent in women and minority groups who historically have also been underrepresented in STEM fields, thereby signaling a novel opportunity to mitigate a longstanding educational challenge known as the achievement gap. To address these national and longstanding concerns, this project will: a) experimentally test how variable sleep and mild sleep loss affect one?s ability to learn challenging STEM content; b) investigate whether sleep interventions that are implemented in STEM classroom settings can improve academic outcomes and reduce achievement gaps; c) broadly disseminate the optimal means to improve sleep via a diversity of student-led community outreach activities and the development of a permanent sleep exhibit at the local museum. Collectively, the project will help to achieve desired societal outcomes including augmenting educational practices, strengthening science literacy and public communication, and improving the well-being of students, parents, and teachers. The project is funded by the EHR Core Research (ECR) program, which supports work that advances the fundamental research literature on STEM learning and broadening participation in STEM fields.<br/><br/>This project will combine experimental and correlational methods to inform how sleep restriction and sleep variability impact learning and stress in the context of gateway STEM courses. In a polysomnography-monitored laboratory setting, participants will sleep on a consistent, restricted, or variable schedule prior to attempting to learn challenging organic chemistry content. In a naturalistic setting, students enrolled in organic chemistry will wear wristband actigraphy across the semester to determine which sleep patterns are predictive of academic outcomes. In classroom-based intervention studies, students will be randomly assigned to receive sleep education only or sleep education augmented with behavioral change techniques. The goal is to determine whether students can improve their sleep in the midst of demanding STEM courses, and if doing so benefits their academic performance. For all studies, this project will test whether sleep patterns mediate the relationship between academic achievement and race, ethnicity, and gender. The polysomnography, actigraphy, and survey data will be further analyzed to investigate longitudinal associations between sleep patterns and STEM outcomes.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1926780","NCS-FO: Understanding How Prior Knowledge Shapes Visual Perception in the Individual Brain","BCS","ECR-EHR Core Research, IntgStrat Undst Neurl&Cogn Sys","10/01/2019","05/19/2021","Biyu He","NY","New York University Medical Center","Standard Grant","Ellen Carpenter","09/30/2023","$1,027,367.00","Orrin Devinsky","Biyu.He@nyumc.org","One Park Avenue, 6th FL","New York","NY","100165800","2122638822","SBE","7980, 8624","8089, 8091, 8551, 8817, CL10","$0.00","Past experiences powerfully shape our daily perception, so our perception of the world around us not only reflects the stimuli input impinging on our senses but is also strongly shaped by what we already know. Sensory input in the real world is often ambiguous, thus incorporating prior knowledge from past experiences is particularly important for perceptual processing in realistic, complex environments. When this process goes awry, past experiences may overwhelm sensory input and cause hallucinations. Through this project, an interdisciplinary research team with expertise in cognitive neuroscience, clinical neurology, and multi-modal human brain imaging will tackle the question of how prior knowledge from past experiences guides perceptual visual processing in the human brain. The research team will further investigate individual variability in these mechanisms and test whether they have predictive power for personality traits that lie on a continuum with mental illnesses. <br/><br/>This project employs a robust, dramatic perceptual paradigm to shed light on how past experiences shape current perceptual processing. Combining psychophysics with cutting-edge human brain imaging technologies, this project will dissect the neural mechanisms underlying the influence of prior experience on human visual perception at the levels of local processing within a brain region, inter-areal information transmission, and large-scale brain dynamics. Further, the extent to which perception relies on prior knowledge varies across healthy individuals and psychiatric patients. This project will capitalize on variations in the general population to determine which neural mechanisms drive individual variability in the reliance of perception on prior knowledge, and further test whether such neural mechanisms can predict an individual?s propensity to psychosis.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1844792","CAREER: Implications of a neurobiological model of memory for education: how novelty exposure transforms poor learning into durable memories","DRL","ECR-EHR Core Research","01/15/2019","05/19/2021","Joseph Dunsmoor","TX","University of Texas at Austin","Continuing Grant","Gregg Solomon","12/31/2023","$928,645.00","","joseph.dunsmoor@austin.utexas.edu","3925 W Braker Lane, Ste 3.340","Austin","TX","787595316","5124716424","EHR","7980","1045, 1187, 8089, 8091, 8817","$0.00","The goal of this project, led by a new investigator at the University of Texas, is to understand the conditions by which poor learning can be transformed into a durable memory, with the ultimate goal of improving educational outcomes. The project leverages groundbreaking behavioral neuroscience research in rodents showing that weak memories can be enhanced through exposure to novelty around the time of learning. It is known that novelty exposure stimulates the molecular and cellular processes involved in long-term memory formation. Remarkably, there is now strong evidence in laboratory animals that novelty exposure can be used as a tool to stabilize other, poorly formed, memories learned around the time of novelty exposure. This idea that novelty exposure retroactively strengthens memory for prior experiences has challenged common assumptions about how animals learn and remember information. It also raises a host of intriguing and important questions on how to harness novelty exposure in humans to improve memory for information that is prone to forgetting. A series of behavioral, psychophysiological, and neuroimaging experiments will attempt to address the parameters by which novelty can be used as a tool to rescue weak learning. The project will culminate in a study of conceptual learning in such fields as biology and geoscience The ultimate goal of this research is to develop innovative and inexpensive tools for promoting learning and memory in real-world settings. Alongside the research project is a plan for public outreach to students and the local community, mentorship, and a plan to develop collaborations with educational researchers to ultimately translate research findings to improve learning performance in authentic educational settings. The project is supported by a CAREER award to the University of Texas by the EHR Core Research (ECR) program, which supports work that advances the fundamental research literature on STEM learning.<br/><br/>This project attempts to translate the concept of 'behavioral tagging,' which was discovered in rodent behavioral neuroscience, to humans. Behavioral tagging is based on a neurobiological model of long-term memory (known as 'synaptic tagging') which details how weak synaptic potentiation creates the conditions for a long-term memory, but only if weak potentiation is accompanied by stronger synaptic potentiation within a critical time window. Behavioral tagging extends this neurobiological model to the realm of behavior by showing that suboptimal learning can be rescued by a separate and more salient experience after learning. Novelty exposure is often utilized as this separate and more salient experience, as it is well-known that novelty induces long-term potentiation in the hippocampus, releases dopamine to the hippocampus via the midbrain, and upregulates plasticity related genes. Thus, novelty exposure may be a valuable tool to stimulate memory formation for other information learned around the same time. Indeed, rodent studies show that poorly formed hippocampal-dependent memories are transformed into durable long-term memories if learning is accompanied by subsequent exposure to a novel open field. This project will test the behavioral tagging hypothesis in humans. It will be discovered whether novelty exposure can improve a host of hippocampal-dependent memories including spatial memory, contextual fear conditioning, pattern separation, memory integration, and learning and transfer of educationally-relevant material. The goal is to gain insight on whether and how novelty enhances poorly formed memories in humans, with the ultimate goal of discovering straightforward, inexpensive, and innovative tools to improve STEM learning.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1954107","Collaborative Research:NCS-FO:Volitional modulation of neural activity in the visual cortex","BCS","ECR-EHR Core Research, IntgStrat Undst Neurl&Cogn Sys","09/01/2019","10/31/2019","Matthew Smith","PA","Carnegie-Mellon University","Standard Grant","Betty Tuller","08/31/2021","$355,938.00","","mattsmith@cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122688746","SBE","7980, 8624","8089, 8091, 8551, 8817","$0.00","This project is funded by Integrative Strategies for Understanding Neural and Cognitive Systems (NSF-NCS), a multidisciplinary program jointly supported by the Directorates for Computer and Information Science and Engineering (CISE), Education and Human Resources (EHR), Engineering (ENG), and Social, Behavioral, and Economic Sciences (SBE). Even basic perception of the world is not as simple as light coming into the eyes or sound coming into the ears.  Rather, perception involves combining the incoming sensory information with cognitive processes such as past experiences, knowledge about the world, and personal tendencies.  In other words, two people observing the same events (i.e., receiving the same sensory information) can arrive at different interpretations of what is happening in the environment.  How the brain combines sensory information with these cognitive processes, and where this occurs in the brain, is incompletely understood.  The key innovation of this project is to use a brain-computer interface (BCI) to tease apart which aspects of the brain's activity are sensory versus cognitive and how the two are combined in the brain to produce perception of the world.  BCIs are widely-known for their ability to help paralyzed patients and amputees by allowing them to move a computer cursor or robotic arm simply by thinking about moving.  Few studies have used BCIs as an experimental tool to understand sensory areas of the brain, as this project seeks to do.  This work is likely to lead to a deeper understanding of how we perceive the world, as well as insights into how BCI can be used to help treat psychiatric disorders and recover function after injury.  Furthermore, the investigators are developing BCI-based lab exercises for undergraduate courses, training researchers to become well-versed in experimental and computational neuroscience, and involving undergraduates, including women and underrepresented minorities, in the research.  <br/><br/>This project focuses on visual area V4, which is known to be a crossroads for sensory and cognitive processes during visual perception.  To dissect what aspects of neural activity are sensory versus cognitive, the investigators train animal subjects to volitionally modulate their V4 activity.  The BCI provides subjects with moment-by-moment auditory feedback of their V4 activity.  This project assesses what aspects of V4 activity can be volitionally (i.e., cognitively) modulated, how volitional modulation of V4 activity affects visual perception, and how malleable is the interaction between V4 and another brain area (prefrontal cortex) during visual perception.  The key advantage of using BCI for this study is that it allows the investigators to challenge the subjects to produce particular patterns of neural activity.  The investigators can specify in the BCI which patterns of activity yield a reward.  This technique allows them to assess what aspects of the neural activity can be volitionally controlled by the animal (i.e., cognitive), and what aspects are hard-wired to the outside world (i.e., sensory). The applications of this BCI paradigm are extremely broad, and can be used to study other sensory, cognitive, and motor systems."
"1717654","CHS: Small: Collaborative Research: EEG-Guided Electrical Stimulation for Immersive Virtual Reality","IIS","HCC-Human-Centered Computing, IntgStrat Undst Neurl&Cogn Sys","10/01/2017","08/24/2017","Murat Akcakaya","PA","University of Pittsburgh","Standard Grant","Ephraim Glinert","09/30/2021","$357,038.00","Douglas Weber","akcakaya@pitt.edu","300 Murdoch Building","Pittsburgh","PA","152133203","4126247400","CSE","7367, 8624","7367, 7923, 8089, 8091","$0.00","Spatial presence, in Virtual Reality (VR) terminology, refers to the perception (or illusion) of being physically present in a simulated environment.  VR strives to create interactive environments that provide experiences of spatial presence through accurate delivery and perception of multimodal sensory stimuli.  Research in VR spans fields ranging from neuroscience and medicine to gaming.   While the computing and gaming industries have generated tremendous advances in hardware and software for graphics processing and 3D display technologies, VR systems still lack capabilities for providing users with haptic feedback (a sense of touch), which is crucial for generating truly immersive, real-world experiences.   It is known that an increase in the feeling of spatial presence manifests itself in the form of increased brain activity.   This research aims to achieve the control of haptic sensory stimulation adaptively, based on the changes in brain activity associated with perceptual responses elicited by sensory stimulation in VR environments.  Project outcomes will include novel scientific discoveries and engineering enhancements that will make significant contributions to other areas of interest, such as prosthetic limbs, augmented reality, and telepresence applications.  The project will help train a new generation of engineers skilled in addressing multidisciplinary challenges, while through outreach activities STEM careers will be promoted at the K-12 level.<br/><br/>The research objective is to identify and analyze brain activity associated with the increased feeling of haptic spatial presence elicited by electro-tactile stimulation and measured through EEG, and to investigate closed-loop techniques to control electro-tactile stimulation for enhanced haptic presence in VR environments.  Specifically, the project will: (1) develop an electrical haptic stimulation framework; (2) design analysis techniques to identify markers of haptic inputs in EEG; (3) establish control policies for adaptive electrical stimulation; and (4) evaluate and refine EEG-guided adaptive stimuli control framework in VR environments.  In particular, the proposition to actuate haptic feedback through electrical stimulation is novel, while formulating design principles for model-based optimal EEG-guided closed-loop haptic feedback for immersive spatial presence is transformative.  Additional innovative propositions to advance adaptive control under uncertainty and psychophysical investigations are unique; these present a potentially game-changing opportunity for VR system development and perhaps for general human-computer interaction."
"1921251","NCS-FO: Collaborative Research: Understanding the neural basis for sensorimotor control loops using whisker-based robotic hardware platforms","BCS","IntgStrat Undst Neurl&Cogn Sys","11/01/2018","02/05/2019","Sarah Bergbreiter","PA","Carnegie-Mellon University","Standard Grant","Betty Tuller","08/31/2021","$274,359.00","","sbergbre@andrew.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122688746","SBE","8624","8089, 8091, 8551, 9251","$0.00","This project will construct robots in order to understand how animals gather information through the sense of touch and how animals use touch information to perform complex behaviors. The results will be important to both neuroscience and engineering. On the neuroscience side, the results will address how the brain combines information about movement and touch, thereby improving our understanding of stroke and brain injury. On the engineering side, the work will develop novel robots and sensors that use touch to sense object location, shape, and texture, to track fluid wakes in water, and to sense the direction of airflow. These capabilities will improve the ability of robots to work in challenging environments; for example, robots could explore dark areas more easily or provide surgeons with a better sense of touch during surgery. To train the next generation of scientists and engineers, both undergraduate and graduate students will help construct the robots and will explore industry- and government-related applications of whisker-based touch sensing. The research team will investigate technology transfer opportunities in robotics and medicine, flow sensing, instrument placement, corrosion detection, three-dimensional tactile profilometry, and compliance sensing. <br/><br/>The fundamental scientific rationale for the work is that understanding how animal nervous systems process complex sensory and motor information necessarily requires quantification of the input. However, it is currently impossible for neuroscientists to record from all primary sensory neurons involved in a particular sensorimotor behavior. The three stages of this project exploit the whisker system of mammals in an endeavor to completely quantify whisker-based input and early neural processing in the rat (Rattus norvegicus) and the harbor seal (Phoca vitulina). The first stage of work will focus on the development of modular, reconfigurable, artificial whiskers that can sense both touch and fluid flow. The materials, manufacturing, and sensor designs necessary for whiskers at multiple length scales will be investigated and signals from the whiskers will be represented based on known coding properties of primary whisker-sensitive neurons in the trigeminal ganglion (TG). The second stage of work will involve the construction of whisker arrays that anatomically match those of the rat and the seal. These arrays will be used to develop combined hardware and software models of the responses of the entire population of TG neurons. Finally, in the third stage of work, the whisker arrays will be mounted on robotic platforms, and the robots will be put through the same head movements as real animals during natural behavior. This process will allow us to simulate the entire TG neuron population response during complex, natural behaviors. Overall, the project will help unlock the basis by which low-level but powerful neural circuits confer animals with flexibility and resourcefulness in sensing and movement.<br/><br/>This project is funded by Integrative Strategies for Understanding Neural and Cognitive Systems (NSF-NCS), a mulitdisciplinary program jointly supported by the Directorates for Computer and Information Science and Engineering (CISE), Education and Human Resources (EHR), Engineering (ENG), and Social, Behavioral, and Economic Sciences (SBE)."
"1804550","Collaborative Proposal: Understanding Motor Cortical Organization through Engineering Innovation to TMS-Based Brain Mapping","CBET","Engineering of Biomed Systems","09/01/2018","08/28/2018","Eugene Tunik","MA","Northeastern University","Standard Grant","Stephanie George","08/31/2021","$300,000.00","Dana Brooks, Deniz Erdogmus","e.tunik@northeastern.edu","360 HUNTINGTON AVE","BOSTON","MA","021155005","6173733004","ENG","5345","8089, 8091","$0.00","This project addresses a question that has vexed scientists for more than a century: how does the motor cortex (the part of the brain where nerve impulses initiate voluntary muscular activity) represent and coordinate multiple muscles in order to produce a vast range of movements? To answer this question, this project will harness the unique strengths of non-invasive, navigated, transcranial magnetic stimulation (TMS) mapping to establish causal links between brain physiology and behavior. TMS is achieved by placing a coil of wires near the scalp, which when activated with an electrical current will create a magnetic field across the scalp and skull to stimulate the brain.  TMS is the only non-invasive method available to stimulate the brain like invasive stimulation. However, to use TMS-based motor mapping to understand multi-muscle physiology and control, innovations in three areas are critically needed: 1) drastically improving the efficiency, efficacy and reliability of the TMS-based motor cortex mapping processes, 2) characterizing and validating TMS-based mapping as a probe for understanding the relationship between multi-muscle activation and voluntary movement, and 3) applying a neural network computational method to improve understanding of motor control and organization. Enhanced understanding of motor cortex physiology through TMS mapping of motor representations has the potential to better map the brain in applications such as surgical removal of tumors, assessing brain injury due to concussions or stroke, and identifying cortical networks needed for successful brain-machine interactions for controlling prostheses. Students involved with this project will be trained to address multidisciplinary challenges at the intersection of neuroscience, non-invasive brain stimulation, software design, control theory, machine-learning, statistical signal processing, data dimensionality reduction and visualization. Partnership with Boston-based leaders in the technology industry will provide state-of-the-art training to undergraduate, graduate, and post-graduate trainees. Through cooperative educational programming at Northeastern University and internships with Mass General Hospital, STEM-based learning opportunities will be provided for middle- and high-school students, inspiring a diverse body of students to pursue STEM careers. To promote STEM careers and demonstrate impact, the team will reach out to local venues that promote public awareness and appreciation of science, such as science fairs and the Boston Museum of Science.<br/><br/>The goal of this collaborative project is to develop a deeper mechanistic understanding of the role of the motor cortex (M1) in controlling single muscles and synergies in producing complex movements. This will be accomplished by developing several innovations in the use of non-invasive transcranial magnetic stimulation (TMS) to map the spatial distribution of synergies and single muscles. Transformative computational advances will be used to extract more accurate information about brain interaction with other physiological systems outside the motor domain and increase the rigor of analysis and data visualization to enhance interpretability, and repeatability. An enhanced understanding of corticomotor organization of complex movement will pave the way to studying motor system development across the lifespan, the basis of human performance enhancement, and the basis and characterization of neuromotor diseases. The research plan is organized under 3 aims. AIM 1 is to accelerate acquisition of TMS-based maps by developing an active learning process based on a Gaussian Process Model (GPM) of Muscle Evoked Potentials (MEPs) as a function of 2D spatial coordinates on the scalp. The developed Active-GMP learning algorithm is expected to speed up the mapping process by diverting time spent on loci with null data to loci where the model needs more samples to improve certainty. The efficacy and the accuracy of the new algorithm will be compared to three existing alternatives. AIM 2 is to test the behavioral relevance of synergies derived from human multi-muscle TMS mapping, i.e., to biologically validate the technical methods developed in Aim 1. Specifically, TMS and Voluntary (VOL) EMG data will be collected from 16 hand-arm muscles in healthy participants while subjects mimic hand postures for static letters and numbers of the American Sign Language alphabet. Non-negative matrix factorization-extracted synergies from VOL data and TMS data will be compared to determine if the TMS-elicited synergies match those utilized during movement production and if the adaptive Active-GMP and user-guided approaches more closely match synergies derived from VOL data compared to other approaches. AIM 3 is to develop generative and inverse topographic imaging models that allow forward modeling of M1 control and reverse mapping of M1 organization, respectively, of muscles and synergies. Hybrid models combining subject-specific FE modeling of TMS-induced cortical electric fields with neural network models trained to predict evoked muscle responses will be used to answer key questions: Q1) Are synergies dominant features of motor control? Q2) Do direct M1 motorneuron projections augment a synergy model of control? and Q3) Are muscles and synergies discretely organized in M1?<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2024046","NCS-FO: Collaborative Research - Human decision-making in complex environments","SMA","ECR-EHR Core Research, IntgStrat Undst Neurl&Cogn Sys","09/01/2019","10/13/2020","Jorge Gonzalez-Martinez","PA","University of Pittsburgh","Standard Grant","Jonathan Fritz","08/31/2021","$364,249.00","","jalmartinez@sbcglobal.net","300 Murdoch Building","Pittsburgh","PA","152133203","4126247400","SBE","7980, 8624","8089, 8091, 8551, 8817","$0.00","Decision-making is one of the most central cognitive functions of importance at practically all levels of society. In many real-world decisions, which of the available alternatives is chosen is influenced by many different attributes. Such multi-attribute decisions are complex because they require the integration and comparison of many pieces of information. For instance, selecting the bundle of goods that maximizes value given a budget constraint in a supermarket that only stocks 100 different goods requires checking approximately 10^30 possible combinations. For this reason, humans do not use rational choice theory in all their decisions. In addition to having to combine the influence of all the different attributes, another complexity is that one alternative is often preferable on one set of attributes, but another is preferred on others. Making a choice then requires a trade-off, which further complicates the decision process. However, the cognitive and neural processes that are at the heart of preference formation are still poorly understood.  This complexity is thought to tax limited cognitive resources in humans who therefore can pay attention only to a limited set of information, on which the decision is then based. In addition, task history often systematically changes decision biases. This research program takes advantage of the opportunity to obtain direct recordings from individual's brains while they perform such complex decision. It will study these activity patterns to determine whether they can be explained via mathematical models of decision making. Understanding which attributes are considered during decision making, and how they are weighted could explain decision making in typical and a-typical populations. Furthermore this integrative research program forms an opportunity to expose engineering students to dynamical systems and control theories in an interdisciplinary context.<br/><br/>This project combines behavioral data, neural recordings in humans (patients undergoing epilepsy evaluation) implanted with multiple depth electrodes covering many cortical and subcortical brain areas, and computational approaches to develop a new theory of the neural mechanisms underlying multi-attribute decision-making in complex environments. This is a unique opportunity to study brain circuits simultaneously across multiple brain areas while humans make these decisions.  The overall goal of the present proposal is to understand the neural circuit involved in (1) representing the relevant decision variables, (2) integrating these variables to form subjective values, and (3) selecting one of the options in multi-attribute decisions. Participants, with implanted electrodes, will work in a novel behavioral task that makes it possible to observe their focus of attention while they evaluate the offers and select one of them.  Data will constrain cutting edge computational models of multi-attribute decision making that will combine: (i) a procedural model of the decision in each trial, and (ii) a latent variable model of biasing influence on decision-making resulting from past trial history. The computational models will make it possible to identify neuronal activity that represents task-relevant variables and the dynamic flow of information across the different elements of the identified neural circuit.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1926756","NCS-FO:Collab:Multimodal sampling of neural ensembles: A high-density opto-electro-chemical neural interface for simultaneous electrical recording and optical imaging of cell-types","ECCS","IntgStrat Undst Neurl&Cogn Sys","09/15/2019","08/22/2019","Xinyan Tracy Cui","PA","University of Pittsburgh","Standard Grant","John Zhang","08/31/2022","$293,138.00","William Stauffer","xic11@pitt.edu","300 Murdoch Building","Pittsburgh","PA","152133203","4126247400","ENG","8624","8089, 8091, 8551","$0.00","This project develops novel devices and methods to record the electrical activity of large numbers of neurons while simultaneously identifying their specific cell types. Specific cell types have precise computational roles in neural information processing systems, but in most cases cell types are not identifiable from electrical activity alone. In cortical regions responsible for decision making, the difficulties posed by intermingled cell types are further complicated by layers, recurrent connections, and the multitude of interneuron types. In order to understand how neural information processing systems mediate decision making, it is necessary to (1) record simultaneously from many neurons to quantify high-dimensional activity, (2) identify and ascertain the precise computational roles of the cell types within those ensembles, and (3) chemically perturb neural ensembles to determine causal functionality. This project will for the first time enable all 3 of these capabilities simultaneously. The proposed neural interface will incorporate recording electrodes, neurochemical stimulators, and flat optical imager waveguides all in the slim form factor of an implantable micro-needle. This device will be used to study the detailed circuit-level functionality of specific cell types involved in the population activity of neurons. The collaboration between a team of engineers and biologists provides a unique interdisciplinary environment for training graduate and undergraduate students working on this project. The PIs will also design a new course on neurotechnology to teach students about the needs in neuroscience research and opportunities in engineering to design next generation neural interfaces.<br/> <br/>This project incorporates an integrative approach based on innovations in technology (nanotechnology, photonics, and neurotechnology) as well as advancements in fundamental neurobiology and transcriptional profiling of cells based on optical tagging to shed light on the role of specific cell types on collective actions of neurons during behavior. Building on a recently developed polymer-based optical waveguide platform with embedded micromirror ports, the investigators will design a novel flat imager that can be monolithically integrated with micro-electrodes to optically image the cell identities, while simultaneously recording their electrophysiology activity. The proposed neural interface (i) is compact and flexible, (ii) combines high-density electrical recording with chemical stimulation, (iii) contains electrically actuated nanocomposite polymers, and (iv) enables on-shank fluorescent imaging using a novel micro-imager array based on parylene polymer photonic waveguides. The utility of this technology platform will be demonstrated for studying cell types involved in encoding sensory sensations in rats during whisker stimulation. The developed multimodal probes will also be disseminated to different neurobiology labs to be used in other experimental contexts to amplify the impact of the proposed project. The outcome of this cross-field research will be (i) a new technology platform that can be used to test various neuroscience hypotheses on the role of specific cell types in encoding and transforming information in brain and (ii) a valuable dataset that can enhance existing mathematical models of neuronal population activity by adding new dimensions to the existing large-scale data based solely on electrophysiology, and will enable an entirely new class of neurobiology experiments.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2045095","CAREER: Leveraging neuroscience to predict and improve science learning in early elementary school","DRL","ECR-EHR Core Research","08/01/2021","05/20/2021","Allyson Mackey","PA","University of Pennsylvania","Continuing Grant","Robert Ochsendorf","07/31/2026","$448,526.00","","mackeya@upenn.edu","Research Services","Philadelphia","PA","191046205","2158987293","EHR","7980","8089, 8091, 8817","$0.00","It is critically important that all U.S. children, regardless of socioeconomic background, are prepared to join the scientific workforce of the future. Prior research shows that having a strong early start in science and math is crucial to later academic success. This study combines innovative approaches in neuroscience, psychology, and education to predict and improve science learning in early elementary school, when foundational scientific knowledge and skills are beginning to be built. This research focuses on understanding how early experiences shape the brain, and how brain development supports learning, which can be leveraged to individualize educational interventions and generate new strategies for broadening participation in STEM. The project is supported by a CAREER award through the EHR Core Research (ECR) program, which supports fundamental research on STEM learning.<br/><br/>The project involves three studies that will investigate early science learning by studying cognitive and behavioral predictors of early science learning and will use structural and functional magnetic resonance imaging (MRI) to study neural networks. In the first study, 144 children between the ages of five- and seven-years-old will be recruited from schools and after-school programs in low-income neighborhoods. Children will participate in MRI and cognitive assessments, as well as eight science lessons designed to align with Next Generation Science Standards. Parents will complete questionnaires about children?s early experiences. The study will test whether exposures to stress and cognitive enrichment are associated with the development of learning, memory, and motivation systems, and whether connectivity in these neural systems predicts science learning. In a separate longitudinal study, 200 two-year-old children from low-income families will be randomly assigned to an intervention that includes weekly home visiting by an early learning specialist or to a control condition that includes information about physical health. In the first year of this study, parents will complete questionnaires about their children?s experiences and development. In the subsequent years of the study, children will complete cognitive measures and MRI and participate in science lessons. This longitudinal design will allow the researchers to assess whether early cognitive enrichment causally influences learning, memory, and motivation systems in the brain, as well as children?s ability to learn science in Kindergarten. A final experimental study will investigate the efficacy of specific pedagogical approaches for enhancing children?s learning. The study will examine whether encouraging children to ask questions improves their learning and other behavioral aspects of curiosity. Together, these studies will provide insights into how to best support children?s early science learning, which will be shared with parents and educators through partnerships with community organizations.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1661074","Collaborative research: Neural and cognitive strengthening of conceptual knowledge and reasoning in classroom-based spatial education","DRL","ECR-EHR Core Research","04/15/2017","04/05/2019","Robert Kolvoord","VA","James Madison University","Continuing Grant","Gregg Solomon","03/31/2022","$151,567.00","","kolvoora@jmu.edu","MSC 5728","HARRISONBURG","VA","228077000","5405686872","EHR","7980","1544, 8089, 8091, 8212, 8817","$0.00","Spatial thinking is a powerful driver of success in the STEM classroom and spatial thinking is a major predictor of future STEM success in the workforce. The brain systems that support spatial thinking have been well mapped by neuroscience to allow clear interpretation of new brain-imaging data. Recent advances in tools used to analyze brain activity allow detection of changes in the brains of students that signify accurate learning of STEM concepts. This advance may open a window onto biomarkers of precisely the type of learning that is the goal of educators. Using these new brain analysis methods, this project, a collaboration involving researchers from James Madison University, Georgetown University, Northwestern University, and Dartmouth College, will investigate how changes in the spatial thinking network support learning of specific STEM concepts, and how changes in the classroom can facilitate changes in the brain related to spatial thinking. This cross-disciplinary project brings together experts in geoscience classroom education, spatial cognition, and the neural bases of learning and reasoning. This team is committed to bridging the conspicuous gap between the laboratory and the high school classroom. A confluence of advances in neuroimaging, and the research team's partnership with Virginia school systems make this effort timely and tractable. Identifying possible effects of sex and STEM-related anxieties on conceptual learning in the brain, and testing the effectiveness of spatial education for reducing disparities, this research will point to critical targets for intervention. The project is funded by the EHR Core Research (ECR) program, which supports work that advances the fundamental research literature on STEM learning.<br/><br/>This project seeks to understand the neural mechanisms of spatial learning, to advance of spatial education, and to identify factors that affect disparities in STEM learning and participation. The research team will collect functional magnetic resonance imaging (fMRI) and behavioral data from students before and after learning in a high school geoscience course that uses a novel spatially-based curriculum to teach STEM concepts and spatial reasoning. Pilot data on this spatial curriculum have begun to characterize the underlying cognitive and neural mechanisms at work, and show promising effects of transfer to STEM problem solving and core measures of spatial ability. Consistent with methods that have demonstrated success in the lab (but not yet the classroom), the research team will use multivariate neural representations of a group of highly experienced and specially trained teachers as an expert standard to determine neural markers of students? conceptual knowledge and spatial reasoning. Leveraging recent multivariate pattern analysis (MVPA) and machine-learning advances in brain imaging, the team will compare the neural patterns of students before and after learning to test for a trajectory that moves students closer to expert representations. This project will also test, for the first time, whether it is possible to compare different curricula based on how much they strengthen the representation of a concept in the brain. Similarly, this work will test whether spatial education leads students to engage spatial brain resources for STEM-related reasoning, and seek to compare curricula on this basis. The project will test whether neural data add predictive value to traditional testing (e.g. conventional unit tests) for subsequent retention of conceptual knowledge and spatial reasoning. Assessments of STEM-related anxieties (e.g., math and spatial anxiety) and analyses of sex-related effects on cognitive and neural outcomes will newly characterize factors that influence disparities in STEM learning and participation."
"1734913","NCS-FO: Collaborative Research: Relationship of Cortical Field Anatomy to Network Vulnerability and Behavior","BCS","IntgStrat Undst Neurl&Cogn Sys","09/01/2017","08/07/2017","Wanpracha Chaovalitwongse","AR","University of Arkansas","Standard Grant","Jonathan Fritz","08/31/2021","$150,000.00","","artchao@uark.edu","1125 W. Maple Street","Fayetteville","AR","727023124","4795753845","SBE","8624","8089, 8091, 8551, 9150","$0.00","Cognitive abilities such as memory and attention are supported by specialized brain networks made up of specific patches of the cerebral cortex called cortical fields. Cortical fields are thought to be anatomically distinct, with neurons connecting between them. Until recently, cortical fields could only be identified after death, by microscopic examination of autopsy brain tissue. Their number, function, and location in individual brains have been unknown.  Now however, Magnetic resonance imaging (MRI) can detect neural activity in the cerebral cortex with relatively high resolution, and diffusion MRI (dMRI) can detect white-matter fibers that connect brain regions. Networks made up of cortical fields become active when individuals accomplish a task, and also spontaneously, when the mind is ""at rest.""  We will use all this information to delineate the specific cortical fields in individual brains as well as patterns of connectivity between them. Cortical fields vary in size up to threefold from person to person, and we intend to study whether this variability is reflected in individual abilities or susceptibilities. The overarching goal is to test the idea that the size of cortical fields matters to the strength and vulnerability of brain networks. We use the MRI approaches outlined above to measure network strength, and we temporarily disrupt networks with transcranial magnetic stimulation (TMS) to assess network vulnerability. The work is important because it will allow us to better understand the reasons people have variable mental abilities. <br/><br/>The project focuses on two established brain networks: the default mode network (DMN) and the lateral frontoparietal network (LFPN), which have components in the inferior parietal lobes.  Connectivity-based parcellation distinguishes two angular gyrus fields, PgA and PgP, which are nodes within the LFPN and DMN networks, respectively. We will use dMRI to parcellate the cortex using a probabilistic parcel atlas of the Human Connectome Project data as prior information. Using functional connectivity, we will evaluate if PgP belongs to DMN, and PgA to LFPN. We will also analyze the strength of functional connectivity across network nodes in resting state fMRI using the dual-regression approach and ascertain the degree to which cortical field size variability across subjects is correlated with network-size variability. We will evaluate whether connectivity-defined cortical parcels maximize fMRI task contrast and show higher levels of EEG gamma and theta activities. Finally we relate the variability of cortical parcel size to task vulnerability by applying transcranial magnetic stimulations (TMS) to PgP and PgA. We hypothesize that low-frequency repetitive TMS (rTMS) over PgA will impair task performance on a working memory task and on a flanker task, and more so for individuals with smaller surface area of PgA. Furthermore, because endogenous reduction of DMN activity is associated with successful deployment of attentional resources, we also hypothesize that rTMS over DMN nodes will positively affect performance on the same tasks, and more so for individuals with smaller surface areas of these nodes.  This project is funded by Integrative Strategies for Understanding Neural and Cognitive Systems (NSF-NCS), a multidisciplinary program jointly supported by the Directorates for Computer and Information Science and Engineering (CISE), Education and Human Resources (EHR), Engineering (ENG), and Social, Behavioral, and Economic Sciences (SBE)."
"1652159","CAREER: Scalable Neuromorphic Learning Machines","CCF","Special Projects - CCF, Software & Hardware Foundation, IntgStrat Undst Neurl&Cogn Sys","02/15/2017","04/01/2021","Emre Neftci","CA","University of California-Irvine","Continuing Grant","Sankar Basu","01/31/2022","$699,696.00","","eneftci@uci.edu","160 Aldrich Hall","Irvine","CA","926977600","9498247295","CSE","2878, 7798, 8624","1045, 7798, 7945, 8089, 8091","$0.00","Machine learning algorithms based on artificial neural networks significantly advanced our ability to solve human-centric cognitive tasks at or above human proficiency. Neuromorphic hardware that emulate the biological processes of the brain on a physical, electronic substrate are emerging as ultra low-power alternatives for performing such tasks where adaptability and autonomy are critical. However, neuromorphic hardware lacks general and efficient inference and learning models of the type that empower artificial neural networks, while being compatible with the spatial and temporal constraints of the brain. This research will bridge isolated fields of machine learning and neuromorphic engineering, and address the energetic and performance merits of computing under physical constraints on communication, precision, retention and failures. The solutions sought to meet these challenges will outline the principles for designing continuously learning hardware, resistant to soft errors and failures of future and emerging computing and memory technologies.This interdisciplinary effort will bring a multifaceted skill set to students and researchers alike, and impact many domains of embedded computing, such as brain implants for detecting and alleviating neurological conditions, implantable prosthetics, assistive robots capable of learning and performing human-level cognitive tasks, as well as defense and surveillance related workloads. To encourage young generations to this approach, the PI will 1) organize hands-on workshops, 2) initiate a student-driven project for developing educational tools targeted for teaching K-12 students the building blocks of spike-based deep learning, and 3) offer public video and lab-based courses on neuromorphic intelligence, including hands-on experiments with cutting edge neuromorphic hardware for students.<br/><br/>The proposed approach will study the stochastic nature of biological neurons and synapses to provide a blueprint for inference and learning machines compatible with the digital and mixed-signal neuromorphic hardware. The goals of this vertically-integrated project will be achieved by devising: 1) Spike-based algorithms guided by statistical machine learning theory that operate on information that is locally available to the underlying physical and neural processes that achieve or surpass the performance of equivalent learning algorithms in deep artificial neural networks; 2) Dedicated scalable neuromorphic hardware architectures for ultra low-power, continuously learning, which are key to adaptive behavior in embedded real-time behaving systems; 3) Rules governing the organization of attention and working memory in the brain using insights obtained from neural networks models equipped with dynamic feedback loops. In tandem with the breakthroughs in deep recurrent neural networks, this project aims to create unprecedented transfer of knowledge, sparking the foundations for novel computers that proactively interpret and learn from real-world data, solve novel problems using what they learned, and operate with the efficiency and proficiency of the human brain."
"1607835","US-French Research Proposal: Hippocampal Layers: Advanced Ccomputational Anatomy Using Very High Resolution MRI at 7 Tesla in Humans","IIS","CRCNS-Computation Neuroscience, Robust Intelligence, IntgStrat Undst Neurl&Cogn Sys","01/01/2017","08/26/2016","Pierre-Francoi Van de Moortele","MN","University of Minnesota-Twin Cities","Standard Grant","Kenneth Whang","07/31/2021","$573,342.00","Thomas Henry","vande094@umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","7327, 7495, 8624","7327, 8089, 8091","$0.00","Magnetic resonance imaging (MRI) plays a pivotal role in the evaluation of brain disorders by allowing clinicians to visualize brain alterations in vivo. For instance in focal epilepsies, it allows to detect lesions that cause seizures, which can subsequently be treated surgically in patients who present drug-resistant epilepsy. This ability to unveil lesions is crucial to achieve favorable surgical outcome and may allow limiting or avoiding invasive explorations with intracerebral electrodes. However, standard MRI techniques have a limited spatial resolution, which results in limited sensitivity to detect subtle structural alterations. This is particularly true in the case of the hippocampus, a relatively small cerebral structure frequently involved in adult and adolescent temporal epilepsy, as well as in other brain disorders. Indeed, the hippocampus is composed of a complex set of internal structures whose typical size is below the resolution of conventional MRI. This project aims to develop new techniques to image the hippocampus, by combining cutting edge MRI acquisition techniques, taking advantage of higher signal to noise ratio at a ultra high magnetic field of 7 Tesla, with advanced mathematical modeling techniques. This new approach will be evaluated in patients with temporal lobe epilepsy. It is expected that exploiting to their full extent very high-resolution structural MR images will allow unveiling cerebral lesions currently undetected in conventional radiological evaluation. Furthermore, by providing unprecedented insight into hippocampal structures, this research will help developing new patient classification and new rationale to guide therapeutic choices in temporal lobe epilepsy. The proposed approach is also expected to provide critical information to advance our understanding of other brain disorders, including Alzheimer's disease and depression, which are major public health concerns. Ultimately, this will pave the way to new biomarkers for diagnosis and prognosis, and help developing new treatments.<br/><br/>The overall goal of this project is to develop a coherent mathematical framework for computational anatomy of the internal structures of the hippocampus based on cutting edge MRI acquisition techniques at 7 Tesla. The project introduces a new approach to move computational anatomy beyond morphometry by integrating both volumetric MRI data and shape into a single framework. To achieve this goal, the researchers will first develop MRI acquisition techniques at 7 Tesla to perform high-resolution and multi-contrast imaging, including new technical developments that will facilitate the use of these advanced methods in clinical settings, for adults and teenagers patients. The second part of the project will be devoted to the development of advanced computational techniques to model multi-contrast 7 Tesla MRI. Such techniques will be based on recent mathematical advances allowing to model multi-scale geometric deformations and to combine shape and intensity information in a coherent framework. Finally, the developed approaches will be applied to 7T MRI acquisition of patients with temporal lobe epilepsy. To that purpose, adult (in the US) and teenagers (in France) patients will be studied with 7 Tesla MRI. This should enable to demonstrate the utility of the developed techniques to unveil lesions that are undetectable by conventional means. This should result in important benefits for patients with focal epilepsy. Beyond the present project, the results should have an important impact on the diagnosis and treatment of brain conditions in which the hippocampus plays a key role, including Alzheimer's disease, depression and schizophrenia. A companion project is being funded by the French National Research Agency (ANR)."
"1947663","Somatosensory Feature Encoding and Attentional Modulation in Human Neocortex","BCS","Cognitive Neuroscience","04/01/2020","03/13/2020","Jeffrey Yau","TX","Baylor College of Medicine","Standard Grant","Jonathan Fritz","03/31/2023","$626,656.00","","jeffrey.yau@bcm.edu","ONE BAYLOR PLAZA","HOUSTON","TX","770303411","7137981297","SBE","1699","1699, 8089, 8091","$0.00","As people search through their pockets to find items, they are able to seamlessly toggle attention from their left hand to their right hand and back to their left hand. Spatial attention enables the brain to effortlessly and selectively perceive and understand what is in the left or right hand at any given moment. Despite the obvious importance of attentional processing for bimanual perception and the coordination of hand movements, how spatial attention deployment to the hands modulates the encoding of touch information remains poorly understood. This research investigates the effects of spatial attention on touch. This project is expected to impact society by advancing understanding of the brain mechanisms supporting touch and attentional selection on the hands, which could enhance diagnosis and monitoring of sensorimotor dysfunctions, and inform the design of advanced neuroprosthetics. The project will promote the participation and education of community college students in neuroscience and related STEM fields.  <br/><br/>Using computational neuroimaging methods and non-invasive brain stimulation, this research will elucidate the effects of spatial attention on information encoding and signal transmission in the human somatosensory cortex. A major research objective is to characterize spatial attention effects on somatosensory stimulus encoding. This objective will be achieved using novel fMRI encoding models that describe population-level tuning for vibration frequency information. These models will be used to establish where and how spatial attention signals ? and their potential interaction with limb position manipulations ? modulate the encoded vibration representations in the human brain. A second major research objective is to characterize spatial attention effects on signal transmission in the somatosensory cortical system. This objective will be achieved by combining causal manipulations of brain activity, using transcranial magnetic stimulation, with behavioral experiments and functional neuroimaging. These multimodal approaches will be used to establish state-dependent processing principles in the somatosensory system. Collectively, the research program will yield novel insights into how spatial attention to the hands flexibly shapes somatosensory feature encoding and network communication in human neocortex.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2011274","CRCNS Research Proposal: Coupled Learning for Anatomically and Developmentally Consistent Analysis of Macaque-Human Fetal Brain Growth","DMS","MATHEMATICAL BIOLOGY, IntgStrat Undst Neurl&Cogn Sys","08/15/2020","10/19/2020","Christopher Kroenke","OR","Oregon Health & Science University","Standard Grant","Zhilan Feng","07/31/2023","$348,832.00","","kroenkec@ohsu.edu","3181 S W Sam Jackson Park Rd","Portland","OR","972393098","5034947784","MPS","7334, 8624","7327, 8089, 8091","$0.00","Neurodevelopmental disorders such as autism spectrum disorder, attention deficit/hyperactivity disorder, fetal alcohol spectrum disorders, and complications associated with premature birth, impact the quality of life of affected individuals over the entire lifespan. Neuroanatomical anatomical differences between people affected by these conditions and ?typically developing? individuals have been identified with magnetic resonance imaging (MRI), but the biological mechanisms leading to such differences, and their link to the disease processes, are incompletely understood. It is safe to perform MRI on pregnant women, and recent developments in the ability to account for fetal motion during image acquisition, have enabled high-resolution 3D imaging of the fetal brain. In order to better understand the developmental mechanisms that underlie the trajectory of anatomical changes observed by MRI in humans, longitudinal measurements are also collected in nonhuman primates. Human and nonhuman primates share many similarities in both brain structure and function that allow findings in one to be translated to the other. Advantages of nonhuman primate studies are that many factors that may vary between human pregnancies can be experimentally controlled, and much more detailed longitudinal imaging is possible. This research will develop computational approaches to more precisely link fetal growth between human and nonhuman brains. The work leverages unique human and nonhuman primate imaging datasets with new methods for systematically labeling the brain into corresponding sub-regions and establish closer links between developmental events. This increased precision will enhance knowledge gained from ongoing human observational studies and enable new clinical approaches to address neurodevelopmental diseases. <br/><br/>The ability to non-invasively monitor fetal brain growth in both human and nonhuman primates using magnetic resonance imaging (MRI) provides a new opportunity to characterize brain development with longitudinal experimental designs. However, given the increased frequency with which data can be acquired, and quality of high-resolution images, an important new limitation is the inability to translate developmental time points between species at the level of precision of the acquired data. Conventional approaches for studying postnatal brain images utilize processing steps such as spatial normalization to a common anatomical coordinate frame, segmentation into tissue classes, and parcellation into known neuroanatomical regions. Adaptation of these techniques to study the developing fetal brain requires age and species-specific definitions for quantities such as transient developmental zones, or emergence of cortical gyri and sulci. This project makes use of increasingly powerful machine learning techniques and leverages the increasingly rich fetal imaging data now being collected, to extract consistent cross-species measures of brain development. An additional objective is to develop fine scale anatomically and temporally consistent definitions across species. These neuroanatomically localized definitions will then be used to quantify regional morphometric growth during fetal brain development in both species. This work contributes to the computational science and the neuroscience that supports neuroimaging studies of fetal brain development. These developments will provide a new translational resource to link anatomically and temporally specific information about brain development, both in normal growth and in clinical and animal model experiments focused on neurodevelopmental disorders.<br/><br/>This award is being co-funded by the CISE Information and Intelligent Systems (IIS) through the CRCNA and BRAIN Programs, and the MPS Division of Mathematical Sciences (DMS) through the Mathematical Biology Program.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1607189","US-Israel Collaboration: Collaborative Research: New Tools for Extracting Neuronal Phenotypes from a Volumetric Set of Cerebral Cortex Images","IIS","CRCNS-Computation Neuroscience, Robust Intelligence, IntgStrat Undst Neurl&Cogn Sys","09/01/2016","08/25/2016","Nir Shavit","MA","Massachusetts Institute of Technology","Standard Grant","Sylvia Spengler","08/31/2021","$332,588.00","","shanir@csail.mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","7327, 7495, 8624","5905, 7327, 7495, 8089, 8091","$0.00","A major limitation in connectomics is that there are few tools to transform connectomic images into a minable database. The research aim of this project is to develop a suite of tools that extract essential structural parameters from the brain's physical structure that was imaged at very high (nanometer scale) resolution. The PIs will determine, by using automated methods, the sizes and shapes of neurons, synapses and their connectivity patterns. Using their tools, the PIs will analyze this detailed and varied dataset to find the key patterns within it. It is their belief that such automated methods are a requirement to comprehend the regularities and rules that govern the formation of neural circuits in the cerebral cortex, which to date have only been studied on very small sample spaces. The cerebral cortex remains perhaps the least understood aspect of mammalian biology. No studyof this magnitude of the neuronal phenotype space has ever been conducted: the dataset will contain hundreds of thousands of somata and a billion synapses, allowing the PIs to search  for patterns that could only be guessed at with the tools used in prior research. Knowing what overarching organizational principles exist in a cerebral cortical network is crucial for understanding how brains work normally and how they may go awry in disease. Moreover, connectomic studies are beginning in a large number of different laboratories throughout the world focused on a wide range of species and parts of the brain. These tools should have direct applicability to many of these endeavors.<br/><br/>The PIs are a consortium of four laboratories with complementary areas of expertise in computer science (Shavit), systems biology (Alon), image processing (Pfister) and neurobiology (Lichtman). Together they are building a stacked set of methods that extract important parameters from connectomic images. These methods include neuron geometry extraction, network structure, motif detection, and archetypical pattern analysis. These approaches are based on two software platforms:the MapRecurse platform for generating connectome graphs and the Pareto Inference Engine for mining patterns within such graphs. The PIs will test these techniques on an a volume of mammalian cerebral cortex containing tens of thousands of cells and a billion synapses, with the aim of extracting the properties of neural circuits that would be difficult or impossible to obtain any other way. The work in this proposal will have significant impact on neuroscience. It speaks directly to the central goals of the White House BRAIN Initiative. It will provide neuroscientists with anumber of powerful and novel tools to understand the cells and circuits that underlie brain function. It should also be influential in developing approaches in machine learning and neuromorphic computing.  <br/><br/>A companion project is being funded by the US-Israel Binational Science Foundation (BSF)."
"1704436","RI: Medium: Collaborative Research: A Structure-Math-Function Approach for Designing Robustly Intelligent Synthetic Nervous Systems","IIS","Robust Intelligence, IntgStrat Undst Neurl&Cogn Sys","10/01/2017","05/15/2018","Roger Quinn","OH","Case Western Reserve University","Standard Grant","Kenneth Whang","09/30/2021","$753,043.00","","rdq@po.cwru.edu","Nord Hall, Suite 615","CLEVELAND","OH","441064901","2163684510","CSE","7495, 8624","7495, 7924, 8089, 8091, 9251","$0.00","Robots are becoming integrated into more areas of life, no longer confined to the predictable environment of a factory, performing the same task. Robots that work among humans require greater intelligence and the ability to adapt to changing tasks in an unpredictable environment. This work develops a sophisticated control system for robotics by modeling the control systems in the brain of a remarkably intelligent, capable, and adaptable insect: the praying mantis. This work promises to transform our understanding of intelligence in both robotics and neuroscience. A model of decision-making in the relatively simple brains of insects advances the study of more complex brains. The model will then be used to allow a legged robot to adapt its movement to suit its goals such as assisting humans, or its ""needs"" such as seeking energy or avoiding danger. These advances seek to give robots the autonomy that animals have. Instead of being programmed for every possible situation, a robot could be trained, continue to learn from experience, and improve efficiency even in novel situations. At an after-school robotics program at an inner-city school, students will benefit from hands-on experience creating robots with the unique perspective of bio-inspired design and modeling of nervous systems.  <br/><br/>This work expands the scale and sophistication of a synthetic nervous system (SNS), a continuous time dynamical model of praying mantis nervous system, and applies it to robotic control. Multi-channel neural recording and stimulation techniques are revealing how insects simplify motor control by distributing computation throughout the nervous system. This project leverages these techniques to understand how the capability of the ""higher"" level (the brain, where sensory input is processed) is directly supported by intelligence in the ""lower"" level (ganglia that coordinate the legs). These data will be used to develop and implement an SNS to control the six-legged MantisBot, endowing it with online learning and intelligent autonomy. Neurobiology will inform this work in all three specific aims: 1) Investigate the lower-level intelligence of the mantis nervous system and use the results to increase the intelligence of MantisBot's low-level control networks; 2) Investigate the correlation between descending commands and behavior and use the results to develop a simplified brain (i.e. high-level controller) for MantisBot; and 3) Investigate the effect of conflicting visual inputs (e.g. simultaneous prey and predator) on descending commands, and use these findings to endow MantisBot with robust intelligence distributed throughout its SNS."
"1734910","NCS-FO: Connecting Spikes to Cognitive Algorithms","IIS","IntgStrat Undst Neurl&Cogn Sys","01/01/2018","08/07/2017","Il Memming Park","NY","SUNY at Stony Brook","Standard Grant","Kenneth Whang","12/31/2021","$715,232.00","","memming.park@stonybrook.edu","WEST 5510 FRK MEL LIB","Stony Brook","NY","117940001","6316329949","CSE","8624","8089, 8091, 8551","$0.00","Experimental neuroscientists can record the signals communicated among the neurons that are collectively involved in producing meaningful behaviors, but making sense of these patterns of activity in terms of specific mental functions is challenging. This research project aims to discover the unseen mental processes that underlie such meaningful behavior from those recordings. The technology developed in this endeavor will uncover new ways of understanding mental processes hidden deep in the noisy signals collected from multiple neurons and will be used to derive new theoretical models (cognitive algorithms) to explain how populations of neurons work together. Such models will contribute to the development of diagnostic tools and neural prosthetics for cognitive dysfunctions in perception, working memory, and decision making, and can also inspire advances in machine learning and artificial intelligence.<br/> <br/>The technical goal of this project is to develop a data-driven framework amenable to visualization and interpretation of neural activity underlying cognition. The core of the project is the identification and recovery of an interpretable low-dimensional nonlinear continuous dynamical system that underlies observed neural time series, and its validation through experimental perturbations. This will answer two key scientific questions: (1) How are task and cognitive variables represented in low-dimensional neural trajectories; and (2) What are the laws that govern the time evolution of the neural states. Answering these questions will help us understand how subjects implement and switch between different cognitive strategies, and more importantly, will provide a means for testing previously proposed theoretical models of the neural computations underlying cognition. This project will develop a number of statistical methods that can (i) extract private and shared noise from single-trial electrophysiological observations, (ii) combine recordings from multiple sessions to infer a common cognitive neural dynamics model, and (iii) design control stimulation to perturb the current neural state. Specifically, these tools will be applied to recordings from cortical areas involved in visuomotor decision-making to discover (1) how the co-variability in a population of sensory neurons encodes decision variables, (2) how the cognitive strategy changes when sensory evidence statistics change, and (3) the underlying dynamics that sustain spatial working memory. The success of this project could transform how the field analyzes population activity with low-dimensional structure in the context of cognitive tasks and beyond."
"1926800","NCS-FO: State Representations in Multi-purpose and Multi-region Neural Network Models of Cognition","IIS","IntgStrat Undst Neurl&Cogn Sys","09/01/2019","08/30/2019","Kanaka Rajan","NY","Icahn School of Medicine at Mount Sinai","Standard Grant","Kenneth Whang","08/31/2022","$1,000,000.00","Erin Rich, Peter Rudebeck","kanaka.rajan@mssm.edu","1 GUSTAVE L LEVY PL","New York","NY","100296504","2128248300","CSE","8624","8089, 8091, 8551","$0.00","Our understanding of the human brain has rapidly progressed with recent technological advances in both experimental neuroscience and artificial intelligence. Despite this, neither approach in isolation is able to explain how distinct cognitive functions such as learning, remembering, reasoning, and intuition emerge from processes inside the brain. In particular, we lack an understanding of how a relatively small and finite number of brain areas are used to accomplish this large and varied repertoire of cognitive functions. Bridging the fields of neuroscience and artificial intelligence, we seek to discover how the brain tracks the cognitive function that is currently engaged and switches between functions during ongoing behavior. We will apply new computational models, called ""multi-purpose recurrent neural networks,"" to neural activity captured from the brains of different animal models to identify common mechanisms that allow animals to track and switch among cognitive functions. By bridging across experimental species, our findings will reveal fundamental features of brain processing. Further, our integrated approach, which uses a multi-disciplinary team of investigators and industry-academia partnerships, will promote cross-fertilization of knowledge and methods between artificial intelligence and neuroscience. We will also achieve broader societal benefits through collaboration with a graphic artist to develop graphic novel abstracts for widely comprehensible, visually appealing representations of the science for publication. <br/><br/>A relatively small number of neural circuits in the brain are used to accomplish a large and varied repertoire of cognitive functions. Achieving this multi-purpose functionality requires neural circuits to both track the engaged function(s) and switch between them. How such tracking and switching is accomplished remains unclear. Computational models based on neural and behavioral data offer an opportunity to identify these key components of the brain's multipurpose functionality. However, existing models that simulate one task at a time lack the flexibility that underlies the brain's capacity to support many tasks. On the other hand, models that simulate multiple cognitive functions lack biologically realistic tracking and switching mechanisms. Here, we propose a new approach to this problem. We will develop a new class of data-inspired multi-purpose recurrent neural network (RNN) models that incorporate biologically plausible mechanisms to track the task being performed and the transitions between tasks. We will also analyze three distinct experimental datasets using machine learning to identify principles underlying multi-purpose functionality, particularly those that are conserved across species. Specifically, we will characterize multi-purpose functionality at the level of dynamic states. We define dynamic states as time-varying patterns of population activity that allow neural circuits to perform multiple tasks, engage them sequentially, and switch between them as task conditions or contexts change. We hypothesize that multi-purpose RNNs can incorporate dynamic states and simulate the brain's ability to track and switch between tasks, in a manner consistent with experimental data. First, we will develop and characterize data-inspired multi-purpose RNNs with internal state representations that track the engaged cognitive function/task performed. Second, we will incorporate functional and structural modularity into RNNs and analyze them in parallel with multi-region neural recordings. The resulting computational framework will enable us to identify key features of state representations and mechanisms underlying multi-purpose functionality in experimental data. What we discover will lay the foundation for understanding and testing core principles of how neural networks throughout the brain support diverse cognitive functions, enabling key advances in the study of cognition. Further, these robust, scalable multi-purpose RNN models containing internally represented states will better leverage existing large-scale neural data and galvanize new experiments designed to test model predictions. For instance, we expect to identify spatio-temporal markers from ongoing neural dynamics that predict upcoming behavioral transitions. In summary, we will build on recent advances in computer science, specifically, deep learning and other AI/ML-based techniques for neural networks, and bring them to bear on a key problem in neuroscience. Our integrative strategy maximally leverages the rapid pace of advances in computer science toward serving neuroscience and neuroengineering to catalyze new investigations beyond the confines of a lab.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2011716","CRCNS US-Japan Research Proposal: A computational neuroscience approach to skill acquisition and transfer from visuo-haptic VR to the real-world","BCS","CRCNS-Computation Neuroscience","09/15/2020","10/19/2020","John Iversen","CA","University of California-San Diego","Standard Grant","Betty Tuller","08/31/2023","$766,105.00","Scott Makeig","jiversen@ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930934","8585344896","SBE","7327","7327, 8089, 8091","$0.00","The ability to learn motor skills allows people to perform critical activities of daily life (walking, dressing, cooking, etc.). It also enables people to engage in social and artistic endeavors and for some to attain virtuoso levels of performance. Understanding the changes that occur in the brain as we learn a motor skill and how we might develop training programs to accelerate such learning, would have impact for many areas, including skill acquisition in robotic training and human-robot interaction, motor skill re-learning in limb amputees, and rehabilitation of motor disorders such as dystonia and gait disorders.<br/><br/>Studies of motor learning are often restricted to highly simplified tasks; few studies have tried to study complex skill learning. The current research project aims to develop a neurobehavioral model of complex skill learning by integrating information from both brain activity and body movement in real time as participants learn real-world activities. The second aim studies ways to enhance learning of complex motor skills. The investigators have developed new visuo-haptic virtual reality (VR) systems that allow detailed interaction with virtual objects, complete with force feedback, to provide a convincing simulation of the real-world but with finer experimental control. This creative VR environment also can simulate changes in the gravitational field which allows using the neurobehavioral model to predict and test human behavior in non-standard environments, such as in space or in underwater applications. Such research is expected to be highly accessible and engaging for the broader public, and the researchers have proposed a range of outreach plans to enhance participation in STEM among groups typically under-represented in these sciences. <br/><br/><br/>A companion project is being funded by the National Institute of Information and Communications Technology, Japan (NICT).<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2024776","NCS-FO: Investigation of cortical-hippocampal interaction during memory formation using multimodal recordings","ECCS","IntgStrat Undst Neurl&Cogn Sys","09/01/2020","07/27/2020","Duygu Kuzum","CA","University of California-San Diego","Standard Grant","John Zhang","08/31/2024","$1,000,000.00","Stefan Leutgeb, Takaki Komiyama","dkuzum@eng.ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930934","8585344896","ENG","8624","8089, 8091, 8551","$0.00","Learning and memory are cognitive functions that are central to human behavior. It has been widely hypothesized that multiple brain regions are coordinated with hippocampus, a subcortical structure, to form the basis for learning and long-term memory. Understanding how different brain regions interact during learning can lead to better understanding of long-term memory storage in the brain. This high-risk, high-payoff project will investigate how cortex and hippocampus communicate and coordinate information transfer during learning and memory consolidation by multimodal imaging and recording experiments. However, such experiments are not currently feasible due to technical limitations. This proposal follows a transformative approach to investigate hippocampus-cortex coordination during learning and memory by combining (i) technological breakthroughs in development of novel implantable probes, (ii) carefully designed multi-modal sensing experiments, and (iii) advanced data analysis techniques. Such a capability could lead to discoveries on information processing in the brain and can help to better understand circuit dysfunctions causing memory impairment for various neurological disorders affecting a large population worldwide. Findings from this research can help with bridging critical gaps between artificial intelligence-driven models for learning and real biological learning in brain. Understanding the latter has the potential to reshape current practices in machine learning. This project will also provide opportunities for students to become engaged in cutting-edge multidisciplinary research in microfabrication, neuroscience and data analysis. The project will also provide research internship opportunities and mentoring initiatives for underrepresented minorities in engineering.<br/><br/>The objective of this project is to investigate how cortex and hippocampus communicate and coordinate information transfer during learning and memory consolidation by multimodal imaging and recording experiments. Wide-field calcium imaging will be used to monitor cortex-wide neural activation across large areas in awake mice. Simultaneous electrophysiological recordings from hippocampus will detect high frequency oscillations such as sharp-wave ripples and spikes from single neurons. Integration of multiple imaging and recording modalities requires development of new implantable probe technologies enabling recording from hippocampus during imaging and advanced data analysis techniques. Complementary expertise of the investigators will be leveraged to pursue; Task 1: Development of new flexible penetrating microprobes compatible with optical imaging, Task 2: Multi-modal, multi-scale experiments in awake mice generating brand new data sets synergistically combining information from calcium fluorescence, local field potentials, single units and behavior, and Task 3: Development of a novel data-driven task-aware algorithm to perform single-event analyses with multimodal calcium imaging from cortex and electrophysiological recordings from hippocampus.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1926576","NCS FR - Elucidating the relationship between motor cortex neural firing rates and dextrous finger movement EMG for use in brain computer interfaces","BCS","IntgStrat Undst Neurl&Cogn Sys","09/01/2019","09/03/2019","Cynthia Chestek","MI","Regents of the University of Michigan - Ann Arbor","Standard Grant","Betty Tuller","08/31/2023","$2,276,395.00","Parag Patil","cchestek@umich.edu","3003 South State St. Room 1062","Ann Arbor","MI","481091274","7347636438","SBE","8624","8089, 8091, 8551","$0.00","Prosthetic hands controlled directly by the nervous system have been the subject of science fiction for decades, and could lead to dramatic quality of life improvements for people with upper limb amputations or paralysis. The brain is the only known controller capable of moving a 5-fingered robot with high precision to use a wide variety of tools and objects. While we know a lot about the control signals in the brain and movement of the fingers, we do not have a good idea of how one gives rise to the other. Here, we will generate an enormous dataset, which will be publicly distributed to students and other scientists everywhere. It will include many channels of brain activity simultaneously with muscle activity to help work out the transformation between the two, and attempt to replicate this control system using artificial neural networks. A strong demonstration of brain controlled prostheses could lead to human studies, and a clinical system that could impact the quality of life for hundreds of thousands of people with amputations or paralysis, as well generating insights for smarter robotic systems. Beyond the direct output of the research, brain machine interfaces have the capability to inspire a large number of students, including those from underrepresented groups, into careers in science and technology, by showing clearly to a young audience how this kind of education can help people.<br/><br/>This project proposes to record data simultaneously from the brain, muscles, and kinematics of the primate hand during complex finger movements, in order to replicate this control system. Specifically, the objective of this particular application is to establish the first such dataset in a nonhuman primate, recording 200 channels from motor cortex, 12 channels of EMG from the muscles, and precise kinematics during the acquisition of finger targets from 4 different degrees of freedom.  Our central hypothesis is that firing rates can be transformed to EMG using a single layer neural nonlinearity followed by a regularized linear regression, and then transformed into finger kinematics through non-linear but well-characterized anatomy.  This differs from upper limb signals, which can appear to be linearly modulated by endpoint velocity regardless of posture. We will complete this project with three objectives. In Objective 1, we will establish a world-class surgical team to create a nonhuman primate animal model with simultaneous chronic brain recording and EMG recording. In Objective 2, we will develop an algorithmic approach to map motor cortex firing rates to EMG as well as kinematics, with both offline and online testing. In Objective 3, we will explore low power circuitry to extract this information in real time, at a power consumption that would be appropriate for an implantable medical device. The overall scientific philosophy of this project is that the brain provides an example of a low power neural network, which is relatively shallow between motor cortex and EMG, for controlling a complex soft robotic system. Uncovering this relationship will enable us to use this approach for brain machine interfaces for paralysis as well as guiding future human made robotic approaches.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1835307","NCS-FO: Integrating Non-Invasive Neuroimaging and Educational Data Mining to Improve Understanding of Robust Learning Processes","DGE","ECR-EHR Core Research, IntgStrat Undst Neurl&Cogn Sys","09/01/2018","07/25/2019","Erin Solovey","MA","Worcester Polytechnic Institute","Standard Grant","Gregg Solomon","08/31/2022","$680,167.00","","esolovey@wpi.edu","100 INSTITUTE RD","WORCESTER","MA","016092247","5088315000","EHR","7980, 8624","8089, 8091, 8212, 8244, 8551, 8817","$0.00","From elementary school math games to workplace training, computer-based learning applications are becoming more widespread. With these programs, it becomes increasingly possible to use the data generated, such as correct and incorrect problem-solving responses, to develop ways to test for student knowledge and to personalize instruction to student needs. The logs of student responses can capture answers, but they fail to capture critical information about what is happening during pauses between student interactions with the software. This project, led by a team of researchers at Arizona State University and Worcester Polytechnic Institute, will explore the use of measurements of brain activity from lightweight brain sensors alongside student log data to understand important mental activities during learning. The study will examine developmental math learning in college and community college students using the ASSISTments intelligent tutoring system. Using brain imaging, the project team will examine whether students are thinking deeply about the problem or mind-wandering during pauses in the learning tasks and use the combined log and brain data to make predictions about learning outcomes. This work will build a foundation for new methods of combining neuroimaging, machine learning, and personalized learning environments. With a better understanding of when and how learning occurs during pauses in tutoring system use, learning technology researchers and developers will be able to create adaptive interventions within tutoring systems that are better personalized to the needs of the individual. This project is funded by Integrative Strategies for Understanding Neural and Cognitive Systems (NSF-NCS), a multidisciplinary program jointly supported by the Directorates for Computer and Information Science and Engineering (CISE), Education and Human Resources (EHR), Engineering (ENG), and Social, Behavioral, and Economic Sciences (SBE).<br/><br/>This project has of three goals: 1) Integrating multiple data streams for the creation of an interdisciplinary corpus; 2) Detecting real-time changes in cognitive states during pauses in log data; and 3) Predicting learning outcomes from brain-based and log-based inferences of cognitive states. In addressing these goals, the team will collect brain data, using functional near-infrared spectroscopy neuroimaging, and behavioral data from controlled, well-understood tasks related to rule learning and mind wandering and from authentic learning tasks. Cognitive neuroscience research involving recordings of brain activity traditionally requires paradigms with highly constrained stimuli, timing, and task requirements, whereas research in complex real-world environments such as tutoring systems rarely align with these paradigms. Features of the brain activity during the cognitive tasks will be used to make inferences about student cognition during authentic learning tasks. In addition, brain features will be combined with log data features to create machine learning models that make accurate predictions of student robust learning outcomes, to be assessed using a posttest given after students use the interactive learning environment. Contributions of this project to STEM learning will include improved understanding of how students build knowledge in response to instructional events within digital learning environments, the construction of better predictive models of when students learn from the use of personalized learning environments, and a mapping between learning processes and the length and context of pauses. This project will also contribute to understandings of how to combine analyses of neuroimaging data and log data.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1734907","NCS-FO:Collaborative Research:Decoding and Reconstructing the Neural Basis of Real World Social Perception","SMA","ECR-EHR Core Research, IntgStrat Undst Neurl&Cogn Sys","08/01/2017","08/07/2017","Avniel Ghuman","PA","University of Pittsburgh","Standard Grant","Jonathan Fritz","07/31/2021","$460,043.00","","ghumana@upmc.edu","300 Murdoch Building","Pittsburgh","PA","152133203","4126247400","SBE","7980, 8624","8089, 8091, 8551","$0.00","Social and affective perception is the critical input that governs how we interact with others during everyday life. Consequently, having a model of the neurobiological basis of social and affective perception is critical for understanding the neural basis of human behavior. The overwhelming majority of our understanding of the neural basis of social and affective perception comes from studies done in artificial lab settings, which cannot capture the richness, complexity, and salience of real-world social interactions. This project aims to fill this gap in knowledge. To accomplish this goal, the researchers will record electrical brain activity from patients undergoing neurosurgical treatment for epilepsy. To determine the region of the brain responsible for their seizures, these patients are implanted with electrodes in various parts of their brain and then they spend 1-2 weeks in the hospital during which they interact with doctors, nurses, friend and family visitors, etc. This award will support research into using the recordings from their brains to understand how these patients perceive and understand the actions, emotions, and communication during these interactions on a moment-to-moment basis. The results of these studies have the potential to transform our understanding of social and affective perception by illuminating the neural basis of these processes during real life, meaningful interactions. The lack of models of the neural basis of natural, real world social and affective perception is a critical impediment to understanding these processes and ultimately a developing treatments for debilitating neurological and psychiatric disorders of social and affective perception, such as autism, post traumatic stress disorder, etc. In addition, through education, mentoring, and teaching, this award will provide an avenue for new researchers to take advantage of the rare and valuable opportunity for basic neuroscientific research provided by direct recordings from the human brain. This research is supported by the EHR Core Research Program, providing funding for fundamental research in STEM learning and learning environments, broadening participation in STEM, and STEM workforce development. <br/><br/>Models of social visual perception developed using unnatural stimuli often assume that neurons have unchanging response sensitivity and are organized into bottom-up hierarchies. While some recent models acknowledge the role of feedback, they remain simplistic with a relatively limited number of core systems and often neglect of the role of social context and dynamic prior knowledge. These models are unlikely to fully generalize to natural social vision where the system can rapidly and actively adapt its response to optimize processing of rich and complex natural visual input. The PI and colleagues will combine intracranial EEG (iEEG) recordings captured during long stretches of natural visual behavior with cutting-edge computer vision, machine learning, and statistical analyses to understand the neural basis of natural, real-world visual perception. The goal of their program of research is to develop the first fully ecologically validated models of social perception. The researchers will use recent advances in iEEG in combination with cutting-edge gaze tracking technology, video analysis tools, and big data statistical and machine learning tools to understand the rapid, complex neural information processing that occurs during real-world social vision. The project will involve decoding the spatiotemporal patterns of neural activity and reconstruct the expressive features of people they see at these different levels on a moment-to-moment basis. The multidisciplinary nature of this project provides an excellent environment for students and postdocs to be trained in computational methods, statistics, and neuroscience. Given the rapid advance of high-level computational and statistical methods in neuroscience, this multidisciplinary training is critical for modern neuroscientists. Enhanced understanding of the mechanisms involved in social cognition has implications for teaching and learning. For example, knowing more about how people form impressions of one another can inform teachers' abilities to recognize and respond to students and other stakeholders in educational settings.<br/><br/>This project is funded by Integrative Strategies for Understanding Neural and Cognitive Systems (NSF-NCS), a multidisciplinary program jointly supported by the Directorates for Computer and Information Science and Engineering (CISE), Education and Human Resources (EHR), Engineering (ENG), and Social, Behavioral, and Economic Sciences (SBE)."
"1724174","Automated Analysis of Movement Disorders from Diffusion and Functional MRI","IIS","OFFICE OF MULTIDISCIPLINARY AC, STATISTICS, CRCNS-Computation Neuroscience, MATHEMATICAL BIOLOGY, IntgStrat Undst Neurl&Cogn Sys","10/01/2017","08/04/2017","Baba Vemuri","FL","University of Florida","Standard Grant","Kenneth Whang","09/30/2022","$1,060,000.00","Hani Doss, Michael Okun, David Vaillancourt","vemuri@cise.ufl.edu","1 UNIVERSITY OF FLORIDA","GAINESVILLE","FL","326112002","3523923516","CSE","1253, 1269, 7327, 7334, 8624","4444, 7327, 8089, 8091, 8251","$0.00","Magnetic resonance imaging (MRI) is the most widely used diagnostic imaging tool for detecting neurodegenerative disorders such as Parkinson's Disease. This project will develop new automated methods for detecting subtle effects that can be revealed by MRI, including changes in water diffusional properties of human brain tissue, and functional brain activity. To assess the deviation from the normal brains, a computationally efficient algorithm will be developed to  construct a population-specific brain structural template from a normal brain population. Further, a new algorithm will be developed to facilitate the detection of Parkinson's using diffusion MRI data. Finally, novel algorithms for establishing the correlation between the information derived from diffusion and functional MRI data will be developed, enabling prediction of functional activity given the anatomical information and vice-versa. Inferring such a correlation will make it possible to predict functional changes due to changes in tissue microstructure caused by neurodegenerative disorders and vice-versa.<br/><br/>In summary, the precise project goals are: (i) To develop a computationally efficient template brain map construction algorithm for features derived from diffusion MRI. In this context, the ensemble average propagator (EAP), which captures both orientation and shape information of the diffusion process at each voxel in the diffusion MRI data, is proposed. Validation of the constructed template will be performed using standard evaluation metrics for template-based segmentation. (ii) To develop novel methods to automatically discriminate between control and Parkinson's groups using the EAP fields as well as Cauchy deformation tensors (that capture the changes in EAP fields). Validation of the classifier will be achieved using the standard leave-k-out strategy. (iii) To develop a novel algorithm for kernel-based nonlinear regression between EAP fields derived from diffusion MRI and scalar-valued fields derived from functional MRI activation maps. The algorithm will be able to predict the level of activation given the EAP fields and vice-versa. These predictions will be validated using a priori labeled data sets. Predicting functional responses from structural information and vice-versa will significantly impact treatment planning of patients with Parkinson's Disease and other neurodegenerative disorders. The multidisciplinary nature of this project will provide the opportunity to collectively train graduate students from diverse backgrounds in the STEM related fields of this project."
"2004088","Targeted Zinc Photocages for Studying Biological Signaling","CHE","Chemistry of Life Processes","09/01/2020","07/23/2020","Shawn Burdette","MA","Worcester Polytechnic Institute","Standard Grant","Robin McCarley","08/31/2023","$451,687.00","Christopher Lambert","scburdette@wpi.edu","100 INSTITUTE RD","WORCESTER","MA","016092247","5088315000","MPS","6883","8089, 8091","$0.00","With this award, the Chemistry of Life Processes Program in the Division of Chemistry is funding Dr. Shawn Burdette at Worcester Polytechnic Institute to develop chelators that undergo light-induced reactions to release zinc in cells. Metal ions play essential roles in numerous processes that sustain life. Among these important roles, metal ions carry the signals that enable learning, memory, and movement. While the function of metal ions such as sodium, potassium and calcium are well established, the role of zinc ions, save for their role in specific zinc metalloenzymes, is less well understood. Dr. Shawn Burdette of Worcester Polytechnic Institute designs and makes tools that trap zinc ions until a light source releases the metal ion at the desired time and location. This project combines elements of synthetic chemistry with spectroscopic and biological methodologies to develop new tools to study zinc in cells. Several educational activities are integrated into a plan that includes involving home-schooled students in research activities through the Worcester Think Tank. Students in the Think Tank program come from the diverse Worcester, Massachusetts community, where over 40% of the residents belong to underrepresented groups. This collaborative effort crosses traditional disciplines of science and utilizes a hands-on research experience to promote teaching chemistry through inquiry.<br/><br/>Vesicular zinc was found in neurons decades ago, but many roles of loosely bound zinc in signal transduction remain ambiguous. Despite the lack of definitive mechanisms, circumstantial evidence suggests zinc can modulate the activity of a variety of ion channels, and zinc interactions with cell surface receptors may lead to a variety of intracellular responses. The central obstacle to studying zinc signaling is a lack of methodologies for mimicking zinc fluctuations in biological systems with spatial and temporal control. Dr. Burdette is approaching this deficiency by applying principles of metal chelator design with the photo-reactivity of xanthone and nitro-phenylacetic acid derivatives. Taking advantage of a light-induced decarboxylation reaction, zinc can be released inside cells with an appropriate light source. This project provides the tools necessary to study zinc signaling as well as establishes the methods necessary to apply those tools in a biological environment. The research objectives are combined with educational objectives that address the lack of access home schooled students have to laboratory facilities, but also exposes those students to innovative research.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1926737","NCS-FO: Collaborative Research: The evolutionary origins of leadership in chimpanzees: from individual minds to collective action","BCS","ECR-EHR Core Research, IntgStrat Undst Neurl&Cogn Sys","08/15/2019","08/29/2019","Zarin Machanda","MA","Tufts University","Standard Grant","Betty Tuller","07/31/2022","$379,193.00","","zarin.machanda@tufts.edu","136 Harrison Ave","Boston","MA","021111817","6176273696","SBE","7980, 8624","8089, 8091, 8551, 8817","$0.00","Leadership is crucial for effective cooperation, especially in large and complex groups. Yet there is an empirical and theoretical gap in our understanding of the individual-level processes underpinning leadership and the group-level consequences of leadership. How does the cognition of individual leaders translate into coordinated group action in the real world?  This project proposes using chimpanzees as a new model of human-like leadership to better understand the evolutionary origins of our own leadership patterns. We will bridge the gap between individual- and group-level phenomena by conducting matched research with semi-free ranging chimpanzees living in a sanctuary where we can do detailed assessments of cognition, and with chimpanzees living in the wild where we can look at complex group behavior in a natural setting. By matching datasets across these two contexts, we will be able to see how individual cognitive process translate into group action. While humans are thought to be uniquely able to establish leadership through prestige and collaboration instead of just pure physical domination, chimpanzees are our closest living relative, also show variation in how individuals obtain and maintain status in their groups. This project will therefore illuminate the evolutionary origins of human leadership, and also set a new agenda in evolutionary cognitive science for studying cognition in the wild. Training, education, and outreach from elementary school through to graduate school will be integrated throughout the project both domestically and abroad. As part of this proposal, we will develop a leadership module for children, using animal models to demonstrate different forms of leadership. We will implement this module through outreach at local schools and museums in the US and in 16 primary schools in Uganda. Undergraduates and high school students in the US will gain hand-on research experience through internships and in coursework. Two postdoctoral researchers and a graduate student will further gain international research experiences in the course of the project. This integrated approach to research and education will train a new generation of evolutionary cognitive scientists and disseminate primate research to the public.<br/><br/>This project has three specific aims. The first aim is to identify individual leaders (those with outsized influence) in natural social groups across multiple contexts of behavior including dominance rank, initiation of group movements, resource acquisition, within-group mediation and inter-group aggression. The second aim is to create leadership profiles by characterizing individual variation in the cognitive, behavioral, and physiological mechanisms of leaders across these contexts. At the sanctuary, 100+ chimpanzees across 5 social groups will be assayed for cognition (including social cognition, cooperation, and executive function); temperament; behavior (aggression and affiliation), and physiology (hormones and body size) to predict leadership. At the field site, similar assessments will be made of temperament, behavior, and physiology, drawing on a longitudinal database with 30 years of data on 150 wild chimpanzees. These data will be used to test the hypothesis that there are distinct pathways to leadership in chimpanzees, with intimidation-based and cooperative strategies being the most important, but knowledge and motivation anchoring some forms of leadership. The final aim is to understand how variation in leadership styles shapes the outcomes of collective action by examining several short-and long-term metrics of leadership success, including group cohesion, rewards received, and biological outcomes like reproductive success that can only be studied in the wild. This project will bridge individual-level and group-level perspectives on cognition, behavior, and physiology by leveraging the strengths of two natural populations of chimpanzees. The project will match experimental and observational techniques across sites on a scale never previously done, and will develop chimpanzees as a new model for human leadership.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1822575","CRCNS Research Proposal: Collaborative Research: Discovering Network Structure in the Space of Group-Level Functional Differences","IIS","CRCNS-Computation Neuroscience, MATHEMATICAL BIOLOGY, IntgStrat Undst Neurl&Cogn Sys","10/01/2018","10/15/2020","Archana Venkataraman","MD","Johns Hopkins University","Continuing Grant","Kenneth Whang","09/30/2022","$874,048.00","Raman Arora","archana.venkataraman@jhu.edu","1101 E 33rd St","Baltimore","MD","212182686","4439971898","CSE","7327, 7334, 8624","7327, 8089, 8091","$0.00","Large-scale study correlated patterns of activity in the brain (functional connectivity) can provide a unique glimpse into the inner workings of neuropsychiatric functions and disorders. However, current methods follow a less than optimal procedure for clinical analyses: they first fit a model to each individual, and then separately identify group differences. In practice, this approach tends to implicate distributed functional changes across the brain, which are difficult to interpret, ignore crucial information about the patient cohort, and fail to replicate across studies. This project takes an entirely new look at this problem by hypothesizing that each neuropsychiatric disorder reflects a set of coordinated disruptions in the brain. As a result, the induced functional differences between patients and neurotypical controls should be interdependent and form their own subnetwork. This strategy reflects a growing perception in the field that complex neuropsychiatric disorders are system-level dysfunctions, rather than collections of isolated effects. Going one step further, the inference procedures developed in this work will strategically leverage patient heterogeneity to guide the subnetwork estimation. In this end, this project will pave the way for robust and targeted biomarker discovery across a wide range of neuropsychiatric disorders.<br/><br/>The technical exploration of this project will unfold in three stages, each of which incorporates an additional level of abstraction. Task 1 is to develop a core model of network-based functional differences via two complementary topologies. Namely, a community architecture suggests that the given deficit arises from a subset of abnormally communicating brain regions, whereas a spreading model assumes that the deficit is linked to a sparse set of region hubs, which abnormally interact with the rest of the brain. Task 2 will broaden the core framework by incorporating structural information from diffusion MRI and by estimating time-varying network differences. Finally, Task 3 will take a purely data-driven approach to the network estimation based on semi-supervised representation learning. In parallel with these technical innovations, Task 4 will address key clinical questions related to three of the most prevalent neurodevelopmental disorders: autism, ADHD, and schizophrenia. The principal investigators will release a flexible computational platform for functional connectomics based on the results of this project.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1724026","CRCNS Research Proposal: Collaborative Research: Studying Competitive Neural Network Dynamics Elicited By Attractive and Aversive Stimuli and their Mixtures","EF","Cross-BIO Activities, CRCNS-Computation Neuroscience","09/01/2017","08/01/2018","Dirk Albrecht","MA","Worcester Polytechnic Institute","Continuing Grant","Edda Thiels","08/31/2021","$280,497.00","","dalbrecht@wpi.edu","100 INSTITUTE RD","WORCESTER","MA","016092247","5088315000","BIO","7275, 7327","1228, 7327, 8089, 8091, 9178, 9179","$0.00","This award supports basic research regarding the question of how networks in the brain allow odors to be detected and perceived.  Such a question is of fundamental interest in neuroscience because responding to odors or scents is one of the most basic ecological abilities exhibited across different animal species.  Further, responses to odors are highly dependent on context.  For example, certain smells may create both attractive and repulsive reactions, depending on small differences in dilution or whether they are encountered alone or as components in a cocktail.  Thus, studying how the brain processes odors can provide important clues regarding how animals and humans sense and perceive in complex environments.  In seeking such understanding, this project uses a unique combination of methods from neuroscience, mathematics, and engineering.  Brain activity from two different animal species are recorded during experiments in which odors are presented in isolation and in mixtures.  Subsequently, data analysis and mathematical modeling is used to identify brain activity patterns that distinguish the reaction of the animals to the odors in question.  Hence, the project uncovers how particular brain networks transform and transmit odor information in a way that is central to the sense of smell.  To broaden the impact of these studies, the project includes the development of a summer internship in sensory neural engineering, intended to allow undergraduate and high school students to learn about and experience how different academic disciplines contribute to future brain science.<br/><br/>The extent to which sensory networks amplify or suppress perceived differences in odor valence remains a fundamental, unanswered question in sensory neuroscience.  The overarching hypothesis of this project is that indeed, there exists a well-defined set of transformations, governed by neuronal dynamics, which map sensory network activity to behavior.  Specifically, the project will determine: (a) How neural networks enable the formation of time-varying neural activation patterns, or, trajectories, in response to sensory stimuli, (b) The mapping from trajectories to behavioral outcome, and (c) The commonality of this mapping across species.  The research goals use an interdisciplinary approach combining sensory systems neuroscience in two species, locusts (Schistocerca americana) and round worms (C. elegans), with computational modeling and dynamical systems theory.  Neural and behavioral responses are recorded from animals receiving nominally attractive and aversive odors, and these data inform computational models of the sensory networks and ensuing behaviors.  The models generate predictions on how behavioral responses might be modulated by a change in selectivity, or background state.  The latter is tested through a paradigm wherein animals are systematically fed or starved, thus shifting their response dynamics on the aversive-attractive spectrum.  Subsequently, model-based sensitivity analyses is used to predict mixture response curves and paradoxical mixtures (e.g., two aversive stimuli that when mixed, elicit an attractive response).  These predictions are tested by delivering component stimuli in systematic ratios.  Thus, the overall methodology combines physiological experiments with new systems-level analysis in an integrated, multidisciplinary modeling-theory loop."
"1926757","NCS-FO: Collaborative Research: Analysis, prediction, and control of synchronized neural activity","IIS","ECR-EHR Core Research, IntgStrat Undst Neurl&Cogn Sys","09/01/2019","08/29/2019","Danielle Bassett","PA","University of Pennsylvania","Standard Grant","John Zhang","08/31/2023","$499,993.00","","dsb@seas.upenn.edu","Research Services","Philadelphia","PA","191046205","2158987293","CSE","7980, 8624","8089, 8091, 8551, 8817","$0.00","Understanding the relations between the anatomical structure of the human brain and its functions in healthy and diseased states can not only lead to the design of novel, targeted, non-invasive, and highly-effective treatments for neurological disorders, but also inform the application of innovative stimulation schemes to enhance cognitive performance and executive capabilities. Leveraging data obtained with state-of-the-art sensing and imaging technologies, this project pursues these objectives by innovatively studying the human brain as a dynamic network system comprising neuronal ensembles and white-matter fibers, and as governed by principles similar to social and technological cyber-physical networks. This project develops and validates new rigorous theories and tools to address an outstanding problem in network neuroscience. Namely, to leverage the brain anatomical structure to characterize, predict, and control patterns of synchronized neural activity, and to validate the methods with realistic brain data. This project will not only contribute to the theories of networks, controls, and neuroscience, but also to their integration, by leveraging different levels of abstraction (brain representations from diffusion imaging data, electrocorticography time series, mathematical models) and distinct disciplinary approaches. In addition to new methods to study synchronized activity in the brain and inform the next generation of diagnostics, this project pursues far-reaching teaching and outreach activities, including (i) a number of university-level initiatives at the graduate and undergraduate levels, (ii) outreach activities that will engage young people from the local communities in Philadelphia and Riverside, and (iii) dissemination activities that will bring together traditionally separated communities and promote multi-disciplinary initiatives to tackle some of the most pressing problems in neuroscience.<br/><br/>The central hypothesis of this project is that the interconnected structure of the brain determines its performance and controls its transitions between healthy and diseased states. Building on this hypothesis, this project addresses the unsolved problems of characterizing, predicting, and controlling patterns of synchronized neural activity in the human brain from sparse and coarse temporal measurements and interventions. Additionally, to support the hypothesis and validate the theories of neural synchronization, the project leverages three unique and extensive multimodal neuroimaging datasets combining high-resolution electrocorticography and diffusion imaging that will allow to assess the relations between synchronization patterns and underlying structural network architecture. Specifically, this project is organized around two main tasks. Task 1, abstracts the problem of controlling patterns of neural activity as the problem of controlling the degree of synchronization among interconnected nonlinear oscillators, where oscillators represent brain regions and their interconnections reflect the anatomy of the human brain as reconstructed by diffusion magnetic resonance imaging. The idea is put forth that altered synchronization patterns are the results of, possibly small, modifications to the oscillators' interconnection structure and weights, and that desirable patterns can be restored by minimal and localized structural interventions. Task 2 uses empirical data to obtain inferences complementing those acquired in the formal theoretical and modeling work in Task 1. Because the focus here is the analysis, prediction, and control of cluster synchronization, the empirical efforts remain constrained to the study of functional neuroimaging data with clear electrographic signatures of synchronization. Specifically, the project uses electrocorticography data, which boasts markedly greater temporal resolution than functional magnetic resonance imaging and does not suffer from the issues of volume conduction that are more common in electroencephalography and magnetoencephalography. The project blends and extends tools from control and network theories, dynamical systems, data analysis, and network neuroscience. While this project focuses on synchronization problems in neural activity, the methods have broad applicability in engineering, for instance to design optimized networks and sparse controllers, network neuroscience, and network science.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1921917","Collaborative Research:  NCS-FO: Flexible Large-Scale Brain Imaging Analysis: Diversity, Individuality and Scalability","SMA","IntgStrat Undst Neurl&Cogn Sys","12/14/2018","10/15/2020","Vince Calhoun","GA","Georgia State University Research Foundation, Inc.","Standard Grant","Jonathan Fritz","12/31/2021","$100,000.00","","vcalhoun@gsu.edu","58 Edgewood Avenue","Atlanta","GA","303032921","4044133570","SBE","8624","8089, 8091, 8551","$0.00","This project is designed to develop important analysis methods for brain imaging data, provide new educational and outreach activities to help promote the workforce, and create a software tool to foster big data analysis of the human brain. Functional magnetic resonance imaging (fMRI) enables noninvasive study of brain function, typically through the estimation of functional networks of connectivity. These networks are relatively stable, but it is also clear that there is a wide degree of differences across individuals. Given that now large-scale multi-subject data have now become available across multiple repositories, there is a pressing need for the development of a flexible analysis framework for large-scale fMRI data that can capture the global traits in brain activity, while not losing the individual aspects of a given brain. Such an accurate estimation of each subject's functional connectivity maps enables the leveraging of large and distributed fMRI repositories. It also promises effective comparisons across different conditions, groups, and time points, thus further increasing the usefulness of fMRI in human brain research. The project provides rich educational experience necessary for student training and workforce development in this fast growing field. The benefits are permeated even further via undergraduate research projects and public outreach programs such as brain awareness weeks, in addition to scholarly dissemination through publications, presentations, and workshop organization. The software toolbox developed as part of the project is freely distributed and enables wider adoption and reuse of the methods by the academia and the practitioners to move forward the brain research collectively. Ultimately, the project outcomes contribute to the NSF's mission of promoting the progress of science and advancing the national health, prosperity and welfare.<br/><br/>Data-driven methods based on latent variable models such as independent component analysis (ICA) have been increasingly adopted in fMRI data analysis. Recently, there have been lively debates as to whether ICA leverages source independence, exploits sparsity, or both, igniting active research in sparse matrix models such as dictionary learning (DL) for fMRI analysis. Indeed, synergistically balancing multiple notions of diversity remains an important challenge. In this context, it is first recognized that jointly leveraging both independence and sparsity enables a powerful and flexible framework for analyzing large-scale fMRI data, by capturing the common traits as well as individual details in a data-driven manner. Therefore, the complementary strengths of the already widely used blind source separation approaches such as ICA, and the more recent, sparse matrix factorization models such as DL are advantageously integrated. Essential practical aspects for large-scale data integration studies, such as decentralized computation and privacy-aware sharing of the datasets across multiple repositories are also addressed by leveraging the complementary expertise of the team."
"2026416","The Origins of Numerical Concepts from Nonverbal Perception","DRL","ECR-EHR Core Research","09/01/2019","01/10/2021","Jessica Cantlon","PA","Carnegie-Mellon University","Continuing Grant","Gregg Solomon","01/31/2022","$366,853.00","","jcantlon@andrew.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122688746","EHR","7980","1544, 8089, 8091, 8212, 8817","$0.00","Modern human mathematical cognition is shaped by evolutionary, developmental, and environmental influences. Researchers seek to understand how those influence affect the development of numerical concepts in human children at the cognitive and neural levels. This research program at the University of Rochester tests the hypothesis that children's early numerical concepts originate from a primitive cognitive and neural system for spatial reasoning.<br/><br/>The proposed research takes an interdisciplinary approach by combining animal cognition, cognitive development, neuroimaging, and mathematics education measures into an integrative analysis of the origins and basic structure of numerical concepts in human children. This interdisciplinary approach is powerful because it allows researchers to test a single hypothesis in a systematic fashion, using a consistent set of methods and across different levels of analysis. The experiments test: 1) the degree to which numerical and spatial perception overlap in the developing brain using functional magnetic resonance imaging (fMRI) with 4- to 6-year-old children; 2) the degree to which numerical and spatial perception become distinct as children receive cultural input from counting education; and 3) the degree to which human children exhibit similar levels of perceptual integration to non-human animals in their representation of numerical and spatial properties. These experiments speak to whether spatial perception gives rise to mathematical cognition in the developing human brain and so reveals the evolutionary and cultural influences on the developmental trajectory of human numerical concepts.<br/><br/>The research program contributes widely to cognitive science, neuroscience, and mathematics education. The cognitive and neuroimaging data from human children advance our knowledge of the developing human brain and provide critical input for early childhood education practices and assumptions about individual differences and gender differences. The comparative data from human children and non-human animals allow researchers to identify fundamental principles that give rise to human mathematical concepts and intrinsic perceptual biases that young children bring to numerical concept learning as they enter school. Together, these data are critical for understanding how humans successfully develop mathematical concepts."
"1926804","NCS-FO:Collab:Multimodal sampling of neural ensembles: A high-density opto-electro-chemical neural interface for simultaneous electrical recording and optical imaging of cell-types","ECCS","IntgStrat Undst Neurl&Cogn Sys","09/15/2019","08/22/2019","Maysamreza Chamanzar","PA","Carnegie-Mellon University","Standard Grant","John Zhang","08/31/2022","$375,773.00","","mchamanz@andrew.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122688746","ENG","8624","8089, 8091, 8551","$0.00","This project develops novel devices and methods to record the electrical activity of large numbers of neurons while simultaneously identifying their specific cell types. Specific cell types have precise computational roles in neural information processing systems, but in most cases cell types are not identifiable from electrical activity alone. In cortical regions responsible for decision making, the difficulties posed by intermingled cell types are further complicated by layers, recurrent connections, and the multitude of interneuron types. In order to understand how neural information processing systems mediate decision making, it is necessary to (1) record simultaneously from many neurons to quantify high-dimensional activity, (2) identify and ascertain the precise computational roles of the cell types within those ensembles, and (3) chemically perturb neural ensembles to determine causal functionality. This project will for the first time enable all 3 of these capabilities simultaneously. The proposed neural interface will incorporate recording electrodes, neurochemical stimulators, and flat optical imager waveguides all in the slim form factor of an implantable micro-needle. This device will be used to study the detailed circuit-level functionality of specific cell types involved in the population activity of neurons. The collaboration between a team of engineers and biologists provides a unique interdisciplinary environment for training graduate and undergraduate students working on this project. The PIs will also design a new course on neurotechnology to teach students about the needs in neuroscience research and opportunities in engineering to design next generation neural interfaces.<br/> <br/>This project incorporates an integrative approach based on innovations in technology (nanotechnology, photonics, and neurotechnology) as well as advancements in fundamental neurobiology and transcriptional profiling of cells based on optical tagging to shed light on the role of specific cell types on collective actions of neurons during behavior. Building on a recently developed polymer-based optical waveguide platform with embedded micromirror ports, the investigators will design a novel flat imager that can be monolithically integrated with micro-electrodes to optically image the cell identities, while simultaneously recording their electrophysiology activity. The proposed neural interface (i) is compact and flexible, (ii) combines high-density electrical recording with chemical stimulation, (iii) contains electrically actuated nanocomposite polymers, and (iv) enables on-shank fluorescent imaging using a novel micro-imager array based on parylene polymer photonic waveguides. The utility of this technology platform will be demonstrated for studying cell types involved in encoding sensory sensations in rats during whisker stimulation. The developed multimodal probes will also be disseminated to different neurobiology labs to be used in other experimental contexts to amplify the impact of the proposed project. The outcome of this cross-field research will be (i) a new technology platform that can be used to test various neuroscience hypotheses on the role of specific cell types in encoding and transforming information in brain and (ii) a valuable dataset that can enhance existing mathematical models of neuronal population activity by adding new dimensions to the existing large-scale data based solely on electrophysiology, and will enable an entirely new class of neurobiology experiments.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1816568","RI: Small: Computational and Physiological Studies of Complex Neural Codes in the Early Visual Cortex","IIS","Robust Intelligence, IntgStrat Undst Neurl&Cogn Sys","10/01/2018","04/18/2019","Tai Sing Lee","PA","Carnegie-Mellon University","Standard Grant","Kenneth Whang","09/30/2021","$513,994.00","","tai@cnbc.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122688746","CSE","7495, 8624","7495, 7923, 8089, 8091, 9251","$0.00","In this interdisciplinary project, machine learning approaches are coupled with neurophysiological studies of primate early visual cortex  to investigate the functional, coding and computational benefits of the observed neural representation and computing architecture.  Neural models, with recurrent connections and the proposed dual-code strategy, will be developed to solve multiple vision problems simultaneously and to fit neurophysiological data.  The representations will be studied from both coding perspectives and computational perspectives, based on scene statistics and their relevance for solving vision problems. The research program will be facilitated by international collaboration and tightly integrated with undergraduate and graduate education in neural computation.   The proposed project wide provide new insights to the computations and functions of the biological visual system, as well as new ideas and inspirations for developing machine learning systems that can learn from limited data and function robustly and flexibly in novel complex situations, potentially with broad societal and technological impact.<br/><br/>Current deep learning neural networks utilize tens or hundreds of layers to learn solutions for specific computer vision problems. The mammalian visual system has much fewer layers, and yet can solve many tasks in a variety of novel and complex situations. The nervous system might achieve this feat by having neuronal circuits with loops and recurrent connections, and with order of magnitude more neurons in each ""layer."" Recent neurophysiological findings suggest that neurons in the primary visual cortex (V1) of primates are not simply oriented edge and bar detectors as described in textbooks, but respond strongly to highly specific complex local patterns, although they also respond to many other patterns with much weaker responses.  The PI proposed that the individual neurons are not amorphous entities, functioning facelessly in a large population, but are distinct and unique individuals that serve as specialists for some specific tasks and as generalists in other tasks. They participate in population encoding of  information with strong sparse codes or weak distributed codes respectively, depending on the functional roles they serve.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1734868","NCS-FO:Collaborative Research:Decoding and Reconstructing the Neural Basis of Real World Social Perception","SMA","ECR-EHR Core Research, IntgStrat Undst Neurl&Cogn Sys","08/01/2017","08/07/2017","Max G'Sell","PA","Carnegie-Mellon University","Standard Grant","Jonathan Fritz","07/31/2021","$490,074.00","Louis-Philippe Morency","mgsell@andrew.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122688746","SBE","7980, 8624","8089, 8091, 8551","$0.00","Social and affective perception is the critical input that governs how we interact with others during everyday life. Consequently, having a model of the neurobiological basis of social and affective perception is critical for understanding the neural basis of human behavior. The overwhelming majority of our understanding of the neural basis of social and affective perception comes from studies done in artificial lab settings, which cannot capture the richness, complexity, and salience of real-world social interactions. This project aims to fill this gap in knowledge. To accomplish this goal, the researchers will record electrical brain activity from patients undergoing neurosurgical treatment for epilepsy. To determine the region of the brain responsible for their seizures, these patients are implanted with electrodes in various parts of their brain and then they spend 1-2 weeks in the hospital during which they interact with doctors, nurses, friend and family visitors, etc. This award will support research into using the recordings from their brains to understand how these patients perceive and understand the actions, emotions, and communication during these interactions on a moment-to-moment basis. The results of these studies have the potential to transform our understanding of social and affective perception by illuminating the neural basis of these processes during real life, meaningful interactions. The lack of models of the neural basis of natural, real world social and affective perception is a critical impediment to understanding these processes and ultimately a developing treatments for debilitating neurological and psychiatric disorders of social and affective perception, such as autism, post traumatic stress disorder, etc. In addition, through education, mentoring, and teaching, this award will provide an avenue for new researchers to take advantage of the rare and valuable opportunity for basic neuroscientific research provided by direct recordings from the human brain. This research is supported by the EHR Core Research Program, providing funding for fundamental research in STEM learning and learning environments, broadening participation in STEM, and STEM workforce development. <br/><br/>Models of social visual perception developed using unnatural stimuli often assume that neurons have unchanging response sensitivity and are organized into bottom-up hierarchies. While some recent models acknowledge the role of feedback, they remain simplistic with a relatively limited number of core systems and often neglect of the role of social context and dynamic prior knowledge. These models are unlikely to fully generalize to natural social vision where the system can rapidly and actively adapt its response to optimize processing of rich and complex natural visual input. The PI and colleagues will combine intracranial EEG (iEEG) recordings captured during long stretches of natural visual behavior with cutting-edge computer vision, machine learning, and statistical analyses to understand the neural basis of natural, real-world visual perception. The goal of their program of research is to develop the first fully ecologically validated models of social perception. The researchers will use recent advances in iEEG in combination with cutting-edge gaze tracking technology, video analysis tools, and big data statistical and machine learning tools to understand the rapid, complex neural information processing that occurs during real-world social vision. The project will involve decoding the spatiotemporal patterns of neural activity and reconstruct the expressive features of people they see at these different levels on a moment-to-moment basis. The multidisciplinary nature of this project provides an excellent environment for students and postdocs to be trained in computational methods, statistics, and neuroscience. Given the rapid advance of high-level computational and statistical methods in neuroscience, this multidisciplinary training is critical for modern neuroscientists. Enhanced understanding of the mechanisms involved in social cognition has implications for teaching and learning. For example, knowing more about how people form impressions of one another can inform teachers' abilities to recognize and respond to students and other stakeholders in educational settings.<br/><br/>This project is funded by Integrative Strategies for Understanding Neural and Cognitive Systems (NSF-NCS), a multidisciplinary program jointly supported by the Directorates for Computer and Information Science and Engineering (CISE), Education and Human Resources (EHR), Engineering (ENG), and Social, Behavioral, and Economic Sciences (SBE)."
"1839291","TRIPODS+X:EDU: Foundational Training in Neuroscience and Geoscience via Hackweeks","DMS","TRIPODS Transdisciplinary Rese, OFFICE OF MULTIDISCIPLINARY AC, IntgStrat Undst Neurl&Cogn Sys","10/01/2018","09/10/2018","Maryam Fazel","WA","University of Washington","Standard Grant","Tracy Kimbrel","09/30/2021","$176,190.00","Anthony Arendt, Aleksandr Aravkin, Ariel Rokem, Zaid Harchaoui","mfazel@uw.edu","4333 Brooklyn Ave NE","Seattle","WA","981950001","2065434043","MPS","041Y, 1253, 8624","047Z, 062Z, 8089, 8091","$0.00","Data-driven science and engineering requires close collaboration and coordination among researchers from different communities, including core sciences, statistics, and optimization. This project will build on and broaden the successful existing ""hackweek"" model to bring together participants from neuroscience and geoscience with experts in machine learning and optimization. The hackweeks will incorporate tutorials on core methods, hands-on sessions, and group activities designed to promote deeper understanding and closer collaboration of both data-driven scientific problems in neuroscience and geoscience, as well as fundamental methodologies and how they apply to these sciences. <br/><br/>In particular, the investigators plan to redesign geo-hackweek and neuro-hackweek, two events that the have been held annually at the University Washington by two of the PIs in recent years. Geo-hackweek will be redesigned to include the discussion of geophysical data interpolation and denoising, geophysical inverse problems, and Gaussian process models, and connecting these to techniques in optimization, including sparse and low-rank models, stochastic optimization, and PDE-constrained optimization. Neuro-hackweek will be augmented to include tutorials on the use of optimal transport models and Wasserstein distances in the analysis of neuroimaging data. This project aims to<br/><br/>(1) Expose participants from domain sciences to foundational topics, so they better understand data science tools, and in particular gain insight into how and when these algorithms work well (or do not work well);<br/>(2) Train participants to consider methods in the context of domain-specific problems, be able to identify domain-specific challenges, and think critically about how to effectively leverage optimization and machine learning tools for specific problem classes;<br/>(3) Expose students with foundations background to application domains, to understand practical challenges in application of machine learning tools;<br/>(4) Generate pedagogical material that can used in similar events;<br/>(5) Encourage collaborations between domain experts and experts on theory and methods.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1912352","CRCNS Research Proposal: Collaborative Research: Mechanisms and dynamics of retronasal olfactory coding","IIS","OFFICE OF MULTIDISCIPLINARY AC, Cross-BIO Activities, Modulation, EPSCoR Co-Funding","10/01/2019","09/05/2019","Woodrow Shew","AR","University of Arkansas","Standard Grant","Edda Thiels","09/30/2022","$482,210.00","","shew@uark.edu","1125 W. Maple Street","Fayetteville","AR","727023124","4795753845","CSE","1253, 7275, 7714, 9150","1228, 7327, 8089, 8091, 9150, 9178, 9179","$0.00","How do our brain, nose, and mouth work together to generate the flavor of food and drink?  When flavor perception goes wrong, can this play a role in diseases like obesity?  The sense of smell is very important for perceiving flavor, largely because of odors that originate in the mouth and are exhaled through the nose via the back of the throat in a a process called retronasal olfaction.  In this study, researchers from the University of Arkansas, the Virginia Commonwealth University, and Southeastern Methodist University are teamed up to gain better understanding of how retronasal olfaction works using rats as an animal model.  The researchers combine direct measurements of the brain in action together with computer simulations of air flow through the nose and neural networks. They are testing the idea that different forces in the nose caused by reversing airflow through the nasal cavity are responsible for how the brain distinguishes exhaled retronasal odors from inhaled odors. In addition, the researchers offer training opportunities at each of the three institutions and are developing an educational video game aimed at introducing users to basic concepts of neurobiology and cognitive neuroscience. <br/><br/>Smells that enter the nose retronasally, i.e., from the back of the nasal cavity, play an essential role in flavor perception, yet many questions about the neuroscience of retronasal olfaction remain unanswered.  How does simply reversing the direction of air flow through the nasal cavity result in different neural input to the olfactory bulb (OB)?  How are retronasal and orthonasal (inhaled) olfactory signals encoded at the level of spiking neurons in the OB?  How do interactions within OB circuits facilitate selective response to retronasal versus orthonasal stimuli?  In this study, researchers from the University of Arkansas, the Virginia Commonwealth University, and Southeastern Methodist University are teamed up to answer these questions, guided by a two-part hypothesis. First, they hypothesize that, at the sensory periphery, retro- and orthonasal stimuli produce distinct spatiotemporal patterns of mechanosensory excitation of olfactory receptor neurons.  Second, they hypothesize that, in the OB, cell-type-specific inhibitory circuit interactions are crucial for dynamic changes in retronasal coding.  To test these hypotheses, the research team is combining high-density multi-electrode recordings in rat OB with fluid dynamics computer simulations based on the three-dimensional shape of the nasal cavity of the same animals. Moreover, the team is performing state-of-the-art realistic computational modeling to identify OB circuit-level principles of retronasal coding.  This work is expected to generate new understanding of the neural basis of retronasal olfaction that includes both peripheral mechanisms in the nose and central mechanisms at the level of M/T cells in the OB. This project is jointly funded by the cross-directorate Collaborative Research in Computational Neuroscience program, the Established Program to Stimulate Competitive Research(EPSCoR), and the MPS Office of Multidisciplinary Activities.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1661088","Collaborative research: Neural and cognitive strengthening of conceptual knowledge and reasoning in classroom-based spatial education","DRL","ECR-EHR Core Research","04/15/2017","03/18/2021","David Kraemer","NH","Dartmouth College","Continuing Grant","Gregg Solomon","03/31/2022","$322,679.00","","David.J.M.Kraemer@Dartmouth.edu","OFFICE OF SPONSORED PROJECTS","HANOVER","NH","037551421","6036463007","EHR","7980","1544, 8089, 8091, 8212, 8817","$0.00","Spatial thinking is a powerful driver of success in the STEM classroom and spatial thinking is a major predictor of future STEM success in the workforce. The brain systems that support spatial thinking have been well mapped by neuroscience to allow clear interpretation of new brain-imaging data. Recent advances in tools used to analyze brain activity allow detection of changes in the brains of students that signify accurate learning of STEM concepts. This advance may open a window onto biomarkers of precisely the type of learning that is the goal of educators. Using these new brain analysis methods, this project, a collaboration involving researchers from James Madison University, Georgetown University, Northwestern University, and Dartmouth College, will investigate how changes in the spatial thinking network support learning of specific STEM concepts, and how changes in the classroom can facilitate changes in the brain related to spatial thinking. This cross-disciplinary project brings together experts in geoscience classroom education, spatial cognition, and the neural bases of learning and reasoning. This team is committed to bridging the conspicuous gap between the laboratory and the high school classroom. A confluence of advances in neuroimaging, and the research team's partnership with Virginia school systems make this effort timely and tractable. Identifying possible effects of sex and STEM-related anxieties on conceptual learning in the brain, and testing the effectiveness of spatial education for reducing disparities, this research will point to critical targets for intervention. The project is funded by the EHR Core Research (ECR) program, which supports work that advances the fundamental research literature on STEM learning.<br/><br/>This project seeks to understand the neural mechanisms of spatial learning, to advance of spatial education, and to identify factors that affect disparities in STEM learning and participation. The research team will collect functional magnetic resonance imaging (fMRI) and behavioral data from students before and after learning in a high school geoscience course that uses a novel spatially-based curriculum to teach STEM concepts and spatial reasoning. Pilot data on this spatial curriculum have begun to characterize the underlying cognitive and neural mechanisms at work, and show promising effects of transfer to STEM problem solving and core measures of spatial ability. Consistent with methods that have demonstrated success in the lab (but not yet the classroom), the research team will use multivariate neural representations of a group of highly experienced and specially trained teachers as an expert standard to determine neural markers of students? conceptual knowledge and spatial reasoning. Leveraging recent multivariate pattern analysis (MVPA) and machine-learning advances in brain imaging, the team will compare the neural patterns of students before and after learning to test for a trajectory that moves students closer to expert representations. This project will also test, for the first time, whether it is possible to compare different curricula based on how much they strengthen the representation of a concept in the brain. Similarly, this work will test whether spatial education leads students to engage spatial brain resources for STEM-related reasoning, and seek to compare curricula on this basis. The project will test whether neural data add predictive value to traditional testing (e.g. conventional unit tests) for subsequent retention of conceptual knowledge and spatial reasoning. Assessments of STEM-related anxieties (e.g., math and spatial anxiety) and analyses of sex-related effects on cognitive and neural outcomes will newly characterize factors that influence disparities in STEM learning and participation."
"1835209","NCS-FO: Modeling Individual Differences in Cognitive Control as Variation in Neural Activation Trajectories","SMA","ECR-EHR Core Research, IntgStrat Undst Neurl&Cogn Sys","10/01/2018","08/10/2018","ShiNung Ching","MO","Washington University","Standard Grant","Jonathan Fritz","09/30/2021","$610,560.00","Todd Braver","shinung@ese.wustl.edu","CAMPUS BOX 1054","Saint Louis","MO","631304862","3147474134","SBE","7980, 8624","8089, 8091, 8551, 8817, 9150","$0.00","NSF 1835209<br/>NCS-FO: Modeling Individual Differences in Cognitive Control as Variation in Neural Activation Trajectories<br/>Abstract:<br/>This award supports fundamental research to examine how activity within brain networks allows humans to adapt their behavior in order to achieve goals and complete mental tasks.  Such processes within the brain, referred to as cognitive control, are thought to differentiate individuals in terms of mental abilities that are critical for successful navigation in activities of daily life, such as planning, problem solving and reasoning.   Current brain imaging methods enable examination of the activity and interactions among brain networks as individuals perform various tasks, thus providing a window into the mechanisms of cognitive control. However, research efforts to date have mostly used imaging data to generate snapshots of brain activity that are averaged across groups of individuals and many different events while performing a task. In this research program, the investigators develop a new form of analysis to characterize the moment-to-moment fluctuations in brain activity, within each individual, as they transition from rest to cognitively demanding task conditions.  In particular, efforts will be directed towards the development of a computational model that can predict how brain networks coordinate activity over seconds-level timescales in response to changing task conditions.  A key aspect of the effort will be to develop unique models for each individual, drawing from a large database of previously obtained neuroimaging data.  In these data, individuals perform a range of tasks requiring different cognitive control strategies, some proactive (sustained) versus others reactive (transient). Thus, application of the model will reveal how the brains of these individuals differentially respond to various types of cognitive demand.  The development of this model also provides a unique opportunity for education and outreach; specific efforts will be directed toward the development of a software platform through which members of the public can work with demonstration models to probe and learn about how different patterns of brain activity relate to cognitive function.<br/><br/>Functional neuroimaging has allowed for detailed spatial and temporal characterizations of brain network activation in an effort to elucidate the neural underpinnings of cognitive control. However, such analyses usually rely on static snapshots of neural activation patterns in individual brain regions and/or correlational indices of inter-regional co-activation (i.e., functional connectivity). Further progress in understanding distinctions between cognitive states and cognitive control strategies requires more precise descriptions of the brain dynamics that govern how patterns of neural activity (trajectories) evolve across time. Leveraging recent advancements in optimization theory that allow for reliable high-dimensional parameter estimation, this award will support the validation and parameterization of single-subject dynamical models using high-resolution, long-duration resting-state fMRI data from the Human Connectome Project, which contains data from over 1000 individuals. Subsequent model analysis will characterize individual differences in terms of brain network dynamics, focusing on quantitative metrics of the ruggedness of the attractor landscape (which indicates the diversity of achievable trajectories) and the consequent energetic costs incurred by shifting between cognitive states and strategies. Hypothesis testing will be conducted with a unique follow-up dataset, consisting of a subset of HCP participants and monozygotic (identical) twins (over 100 in total) tracked in multiple neuroimaging sessions, under conditions that systematically manipulate cognitive control strategies.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1734887","NCS-FO: A Computational Theory to Model the Neurobiological Basis of a Visuo-Cognitive Neuroprosthetic","SMA","IntgStrat Undst Neurl&Cogn Sys","08/01/2017","08/07/2017","Stephen Macknik","NY","SUNY Health Science Center at Brooklyn","Standard Grant","Jonathan Fritz","07/31/2021","$949,928.00","Susana Martinez-Conde","macknik@neuralcorrelate.com","450 Clarkson Avenue","Brooklyn","NY","112032012","7182702680","SBE","8624","8089, 8091, 8551","$0.00","Evoking high quality visual perception in a blind person, via direct microstimulation of the brain, poses great difficulties. One major obstacle has been that electrical stimulation of the brain typically affects neuronal populations that are mutually suppressive, which subverts proper neuronal signaling. The visual system has two antagonistic information channels that encode either the perception of lightness, in ON cells, or darkness, in OFF cells. Inappropriate coactivation of these two channels results in nullification of contrast, and deprived visual perception. It follows that high-quality prosthetic stimulation systems must avoid unwanted coactivation of mutually suppressive neurons, just as the natural visual system does. This is a challenge because the antagonistic neurons typically lie within microns of each other in the brain. The project aims at transformative advances in viral transfection and imaging methodology, computational theory, and cortical prosthetic neuroengineering design for the purpose of restoring vision by genetically modifying neurons in the brain and then stimulating them with light, a method called optogenetics. The expected results and methodology will form the scientific basis to build a breakthrough neuroprosthetic, with transformative potential to further brain research in sensory, motor, and cognitive parts of the cortex and to advance human medicine. To promote the development and availability of derived products to the public, the team will disseminate the discoveries to general audiences through public lectures and publications in popular science magazines. The investigators will supervise trainees from underrepresented groups, including postdoctoral fellows, graduate students, undergraduates, and high school students. The investigators are faculty mentors for The Children's Aid Society (CAS) Workforce Development Department Summer Youth Employment Program (SYEP), which provides summer research opportunities to disadvantaged and minority youth in NYC to inspire them to pursue STEM careers. <br/><br/>Recent research has shown that, for any given retinal position, the ON and OFF cell inputs to the brain's visual cortex are purely excitatory, concentrate in a specific layer, and are laid out in a pattern that can be targeted with light from outside the brain. First, the team will modify these neurons genetically, to turn them into a novel type of photoreceptor, embedded within the brain. The team will then target light stimulation to the identified ON and OFF cells, determining the precise balance of activation to either channel to generate high-quality prosthetic vision based on a video camera's signal. This technology can then be used to bypass the eye to stimulate the brain from the camera. The project aims to develop the computational model to drive an optogenetic brain stimulation system that will optimally activate neural responses in the primary visual cortex. By comparing the neuronal responses of sighted nonhuman primates viewing natural visual stimuli to prosthetic responses in the same neurons, the work will optimize stimulation patterns that evoke naturalistic visual perception. The balanced targeting of appropriate ON and OFF inputs at each position in visual space is expected to achieve maximal contrast perception at the highest attainable acuity, with full stereoscopic binocular vision. The team's computational model of spatiotemporal visual inputs into the cortex will also account for the effects of eye movements on early visual responses, a novel approach to visual prosthetics tested here for the first time.<br/><br/>This project is funded by Integrative Strategies for Understanding Neural and Cognitive Systems (NSF-NCS), a multidisciplinary program jointly supported by the Directorates for Computer and Information Science and Engineering (CISE), Education and Human Resources (EHR), Engineering (ENG), and Social, Behavioral, and Economic Sciences (SBE)."
"1750213","CAREER: Longitudinal Development of Numerical Processing Brain Networks in Developmental Dyscalculia: A Neuroimaging Study from Kindergarten to Second Grade","DRL","ECR-EHR Core Research","03/15/2018","02/26/2021","Gavin Price","TN","Vanderbilt University","Continuing Grant","Gregg Solomon","02/28/2023","$1,854,253.00","","gavin.price@vanderbilt.edu","Sponsored Programs Administratio","Nashville","TN","372350002","6153222631","EHR","7980","1045, 1187, 1545, 8089, 8091, 8817","$0.00","Approximately 6% of Americans suffer from the mathematical learning disability developmental dyscalculia (DD), facing academic difficulties, reduced employment, increased mental and physical illness, and higher rates of arrest and incarceration. Despite the potential consequences, no consensus currently exists regarding the brain and behavioral causes of DD. The project team will attempt to characterize the development of and interaction between brain mechanisms responsible for processing symbolic and nonsymbolic numbers in children from kindergarten through 2nd grade with DD, with the hope that understanding the root causes of the disorder will aid the development of effective diagnostic and remedial tools for educational interventions. They will engage in a combination of neuroscientific and behavioral research in order to disambiguate between competing causal theories that are unlikely to be distinguished on the basis of behavioral evidence alone. The project is supported by a CAREER award to Vanderbilt University by the EHR Core Research (ECR) program, which supports work that advances the fundamental research literature on STEM learning.<br/><br/>Competing theories of the underlying cause of DD suggest that there is a deficit either in the representation of numerical magnitude, or in the connection between those representations and symbolic numbers. The project will attempt to disambiguate between these theories by providing a multimodal characterization of the neural networks involved in basic nonsymbolic and symbolic number processing in DD children using functional magnetic resonance imaging (fMRI), as well as structural metrics of grey and white matter. The project will examine the development of those networks and will examine the extent to which those networks predict typical and atypical mathematical skill development. Investigators will study children with DD, children with dyslexia (DL), and typically developing (TD) children longitudinally from kindergarten to 2nd grade. By contrasting between these three groups, the investigators will be able to identify atypical brain and behavioral phenotypes that are specific to DD, as well as identify any commonalities between DD and DL. In each year, participants will complete a battery of symbolic and nonsymbolic number processing tasks in the fMRI scanner, in addition to a battery of behavioral tests measuring mathematics skills and general cognitive abilities. Measures of brain structure will also be collected in each year, allowing investigators to assess functional brain activation, functional and structural connectivity, and their relation to behavior and to each other. At the conclusion of the research project, the research team will provide evidence supporting a characterization of the core neurofunctional abnormalities in basic number processing underlying DD, identify the relationships between structural brain integrity and functional neural mechanisms underlying numerical magnitude processing in DD, and explore the causal developmental relationships beween aberrant number processing brain mechanisms and math outcomes in DD from kindergarten through 2nd grade.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1632257","SBIR Phase II:  Using Data Mining to Optimally Customize Therapy for Individuals with Autism","IIP","SBIR Phase II","08/01/2016","07/07/2020","John Nosek","PA","Guiding Technologies Corporation","Standard Grant","Alastair Monk","07/31/2021","$1,016,170.00","","johnnosek@verizon.net","1500 JFK Blvd Suite 1825 2 Penn","Philadelphia","PA","191021710","6096059273","ENG","5373","116E, 165E, 169E, 5373, 7744, 8018, 8032, 8042, 8089, 8091, 8240, 9231, 9251","$0.00","The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase II project will revolutionize the treatment of individuals with autism. One of every sixty-eight US children has autism (over 1.1 million). The estimated cost of providing Applied Behavior Analysis (ABA) therapy to those who could benefit is $7.5 billion dollars annually. Societal impacts include: 1) more individuals with autism across the globe will receive treatment regimens that will enable them to live more fulfilled lives and reach their full potential; 2) families whose children are good candidates for treatment and receive it will experience reduced stress and better family life; and 3) the additional lifetime cost of not effectively treating children with autism, which is approximately ten-fold the cost of treatment, will be reduced. Because high-quality, contextually rich ABA performance data will be collected for the first time, efforts to apply data analytics will contribute in two important ways: a) patterns may be discerned across individuals with autism to better understand variations in autism and create therapies to target these differences; b) expansion of the frontiers of data mining to provide guidance in real time will contribute to a number of areas within and beyond ABA therapy.<br/><br/>The proposed project will optimize therapy outcomes for individuals with autism by transforming agent-based guiding technology into an adaptive and intelligent ABA therapy assistant for supervisors and instructors. The project pushes the boundaries in providing cost-effective, adaptable, intelligent, real-time guidance and data-collection support to instructors that integrates naturally into the instructional process and is easy to learn and use. ABA therapy experts, supervisors and instructors will verify the analyses and resulting guidance incorporated into the technology.  Advanced theories of usability engineering, including some developed by the project team, will be used to build interfaces that supervisors and instructors can intuit without the need for learning new concepts and syntax. The project will utilize the collected logs from multiple sessions with multiple therapy recipients and multiple therapy providers to uncover hidden patterns and assist supervisors in selecting appropriate therapy steps personalized for the individual with autism. The project will build on a large body of recent work in visualization, machine learning on temporal predictive modeling and sequential pattern mining, including some of the previous results of the project team. Special attention will be paid to the recent work in educational data mining and intelligent tutoring."
"1912373","CRCNS US-German Research Proposal: Language representations in bilinguals","IIS","CRCNS-Computation Neuroscience, IntgStrat Undst Neurl&Cogn Sys","12/01/2019","09/05/2019","Jack Gallant","CA","University of California-Berkeley","Continuing Grant","Jonathan Fritz","11/30/2024","$775,163.00","Fatma Deniz","gallant@berkeley.edu","Sponsored Projects Office","BERKELEY","CA","947101749","5106433891","CSE","7327, 8624","7327, 8089, 8091","$0.00","The overarching goal of this project is to uncover how language-related information is represented and<br/>processed in the brains of bilinguals. To do this the project will use functional magnetic resonance imaging to<br/>record brain activity in bilingual subjects while they read passages of text in two different languages.<br/>These data will be analyzed and modeled using a cutting-edge approach called voxelwise modeling.<br/>The results of this study will provide crucial insights regarding how syntactic and semantic<br/>information about multiple languages are represented and organized in individual bilingual brains,<br/>and how these representations are flexibly deployed to facilitate multi-language comprehension.<br/>Improving our understanding of language representations in bilinguals will improve diagnosis and<br/>treatment of language disorders, enhance methods for language education, and advance machine<br/>translation technologies.<br/><br/>Over the past 10 years the project team has developed a novel and sensitive voxelwise modeling approach for<br/>analyzing and modeling fMRI data. This approach recovers functional maps in the human cerebral cortex in<br/>unprecedented detail. The project team will use this powerful framework to study language representation in the brains of<br/>bilingual speakers. In Aim 1 the project will compare lexical semantic information represented in cortical maps obtained<br/>during language comprehension in bilinguals in both German and English. In Aim 2 the project will compare syntactic<br/>information represented in cortical maps obtained during language comprehension in the same individuals<br/>examined in Aim 1. In Aim 3 the project will compare cortical semantic and syntactic maps obtained during language<br/>comprehension in bilinguals who know two very different languages, Chinese and English. Together these<br/>experiments will answer several important questions about semantic representation in bilinguals: Are the<br/>functional representations of semantic and syntactic information similar or different across languages? What are<br/>the similarities and differences in semantic representations across languages? How are syntactic features<br/>represented and how do these representations differ across languages?<br/><br/>A companion project is being funded by the Federal Ministry of Education and Research, Germany (BMBF).<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1835389","NCS-FO: How Ecology Induces Cognition: Paleontology, Machine Learning, and Neuroscience","ECCS","IntgStrat Undst Neurl&Cogn Sys","09/15/2018","08/31/2018","Malcolm MacIver","IL","Northwestern University","Standard Grant","John Zhang","08/31/2022","$1,000,000.00","Daniel Dombeck","maciver@northwestern.edu","750 N. Lake Shore Drive","Chicago","IL","606114579","3125037955","ENG","8624","8089, 8091, 8551","$0.00","We think of nervous systems as the means by which an animal organizes its world, but a deep time perspective suggests that it is rather the world of an animal that organizes its brain. Prior to the vertebrate invasion of land 385 million years ago, vision, our most powerful long-range sense, took in a largely blurry world at short range while underwater, with little variability in scene as the eyes move. Once on land, vision takes in a high contrast world at long range, with high variability as the eyes move. A possible reason for the greatly increased size and complexity of terrestrial vertebrate brains over those of fish is that this environment provides selective advantage to long sequences of actions toward distant goals, reaching its most complex form in varieties of prospective cognition in certain mammals and birds. A team of Northwestern researchers will conduct research into the computational, behavioral, and neural basis of planning, rooted in an evolutionary and computational sensory ecology perspective and a commitment to ethologically relevant behaviors. Planning is an immensely important capacity to understand the mechanistic basis of, as it participates in a diverse range of behaviors, and its diminishment favors impulsivity and reliance on the habit system. Up to now, laboratory studies of planning have typically relied on reduced environments and simple behaviors which are either appetitive or (more rarely) aversive, without a sentient target, the dynamics and unpredictability of which is likely key to the adequate analysis of prospective cognition. Methods from neuroengineering and data-intensive neuroscience will be brought to bear on the problem of making a more ethologically relevant, yet tightly controlled approach to investigating planning possible. The computational and behavioral work will be used to guide neurobiological interventions in two of the key brain structures that participate in reactive versus reflective decision making and choice: the striatum and hippocampus. <br/><br/>The team will pursue research with an unusually bold intellectual dynamic range well beyond a typical disciplinary approach, from its motivation rooted in evolutionary biology and computational sensory ecology, to the extension of the latest machine learning methods, through to single-cell resolution imaging of live animal behavior in a virtual reality system. The researchers will knit together parallel synergistic efforts in the simulation of planning, a mechatronically reconfigurable behavior arena with a robot predator, and two-photon single cell resolution imaging in a virtual reality system, resulting in an ethologically relevant context significantly more complex than current practice in laboratory settings. There are few areas of neuroscience that have as much potential to impact society as research on the neural basis of planning. Discussions of self-control, marshmallow tests, grit, and challenges we face in making long term plans such as retirement or adapting to changing climate for future generations fill the media. One of the team's research goals is to understand the manner in which the nervous system participates in constraining the temporal and spatial range of prospective cognition,which is clearly quite limited even in humans, toward a neuroscience of sustainability.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1763350","NCS-FO: Collaborative Research: Fully-passive and wireless multi-channel neural recording for chronic in-vivo studies in animals","ECCS","CCSS-Comms Circuits & Sens Sys, IntgStrat Undst Neurl&Cogn Sys","08/09/2017","03/09/2020","John Volakis","FL","Florida International University","Standard Grant","John Zhang","07/31/2021","$585,087.00","","jvolakis@fiu.edu","11200 SW 8TH ST","Miami","FL","331990001","3053482494","ENG","7564, 8624","090E, 8089, 8091, 8551, 9102, 9251","$0.00","This project focuses on the study of chronic in-vivo brain neuropotentials in free-moving animals acquired by wireless, fully-passive multi-channel recorders. Current clinical brain implants have limitations due to their intracranial wires, batteries, and heat caused by dense electronics. Recent work by the proposers introduced a new class of wireless and fully-passive neural implants. These implants were demonstrated to acquire in-vivo neural signal of 500 microVolts and in-vitro emulated neuropotentials as small as 20 microVolts.  But these implants were limited to single-channel recording, prohibiting realistic in-depth brain studies. Herewith, we propose a bold and creative study to 1) Design and implement multi-channel, wireless and fully-passive brain implants; a passive approach is also proposed for implants, scalable to even 1000s of channels. 2) Enable chronic in-vivo recording and behavioral studies in free-moving animals. The proposed sensor system will provide, for the first time, a unique opportunity to study longitudinal brain dynamics. The impact of this research can be profound at many levels. Specifically, the success of this research may ultimately result in real and accessible multi-channel brain implant recorders to improve human well-being, especially for people suffering from chronic neurological disorders.  Collectively, the recorded data can expose a very broad realm of the human's well-being. The utmost long-term aim is carefree, real-time and closed-loop diagnosis/treatment for several neurological disorders (tremors, Parkinson's, addictions, Alzheimer's, traumatic brain injury, epilepsy, etc.). A number of educational activities will be brought forward, including hands-on experiences to train students in a new area, summer camps, and a variety of outreach activities to attract women and minorities in engineering. This project is funded by Integrative Strategies for Understanding Neural and Cognitive Systems (NSF-NCS), a multidisciplinary program jointly supported by the Directorates for Computer and Information Science and Engineering (CISE), Education and Human Resources (EHR), Engineering (ENG), and Social, Behavioral, and Economic Sciences (SBE).<br/><br/>This project proposes a bold and creative study for a new class of wireless fully-passive multi-channel neural recorders for safe and reliable neurosensing in free-moving animals. The key aspects of the proposed research are: 1) Design and implement multi-channel, wireless and fully-passive brain implants; Two different implants are proposed, with one scalable to 1000s of channels. 2) Enable chronic in-vivo recording and behavioral studies in free-moving animals. Of importance is that the proposed wireless and fully-passive biotelemetry sensor is expected to significantly enhance long-term reliability and safety of brain implants. This is due to 1) None to minimal heat dissipation by the implant, 2) Elimination of infections from intra-cranial wires, and 3) Avoidance of batteries within the skull. This game-changing research can lead to the first wireless and fully-passive chronic recording of brain signals using free-moving animal models (rats). Notably, the proposed neurosensors employ a unique microwave backscattering method to enable wireless battery-less operation. As a result, wires, cables and active electronic components are avoided. Multi-channel recording is implemented by integrating photo-selective and photo-sensitive switches to activated individual channels via a multi-band light source and corresponding filters for channel selection. Overall, the proposed sensor system will provide, a unique opportunity to study longitudinal brain dynamics for studying brain activity in the natural environment of animals. The proposed sensing system will also have significant impact on safety and reliability for long-term operation."
"1734806","NCS-FO: Collaborative Research: Fully-passive and wireless multi-channel neural recording for chronic in-vivo studies in animals","ECCS","CCSS-Comms Circuits & Sens Sys, IntgStrat Undst Neurl&Cogn Sys","08/15/2017","07/28/2020","Junseok Chae","AZ","Arizona State University","Standard Grant","John Zhang","07/31/2021","$296,793.00","","junseok.chae@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","ENG","7564, 8624","8089, 8091, 8551, 9102, 9251","$0.00","This project focuses on the study of chronic in-vivo brain neuropotentials in free-moving animals acquired by wireless, fully-passive multi-channel recorders. Current clinical brain implants have limitations due to their intracranial wires, batteries, and heat caused by dense electronics. Recent work by the proposers introduced a new class of wireless and fully-passive neural implants. These implants were demonstrated to acquire in-vivo neural signal of 500 microVolts and in-vitro emulated neuropotentials as small as 20 microVolts.  But these implants were limited to single-channel recording, prohibiting realistic in-depth brain studies. Herewith, we propose a bold and creative study to 1) Design and implement multi-channel, wireless and fully-passive brain implants; a passive approach is also proposed for implants, scalable to even 1000s of channels. 2) Enable chronic in-vivo recording and behavioral studies in free-moving animals. The proposed sensor system will provide, for the first time, a unique opportunity to study longitudinal brain dynamics. The impact of this research can be profound at many levels. Specifically, the success of this research may ultimately result in real and accessible multi-channel brain implant recorders to improve human well-being, especially for people suffering from chronic neurological disorders.  Collectively, the recorded data can expose a very broad realm of the human's well-being. The utmost long-term aim is carefree, real-time and closed-loop diagnosis/treatment for several neurological disorders (tremors, Parkinson's, addictions, Alzheimer's, traumatic brain injury, epilepsy, etc.). A number of educational activities will be brought forward, including hands-on experiences to train students in a new area, summer camps, and a variety of outreach activities to attract women and minorities in engineering. This project is funded by Integrative Strategies for Understanding Neural and Cognitive Systems (NSF-NCS), a multidisciplinary program jointly supported by the Directorates for Computer and Information Science and Engineering (CISE), Education and Human Resources (EHR), Engineering (ENG), and Social, Behavioral, and Economic Sciences (SBE).<br/><br/>This project proposes a bold and creative study for a new class of wireless fully-passive multi-channel neural recorders for safe and reliable neurosensing in free-moving animals. The key aspects of the proposed research are: 1) Design and implement multi-channel, wireless and fully-passive brain implants; Two different implants are proposed, with one scalable to 1000s of channels. 2) Enable chronic in-vivo recording and behavioral studies in free-moving animals. Of importance is that the proposed wireless and fully-passive biotelemetry sensor is expected to significantly enhance long-term reliability and safety of brain implants. This is due to 1) None to minimal heat dissipation by the implant, 2) Elimination of infections from intra-cranial wires, and 3) Avoidance of batteries within the skull. This game-changing research can lead to the first wireless and fully-passive chronic recording of brain signals using free-moving animal models (rats). Notably, the proposed neurosensors employ a unique microwave backscattering method to enable wireless battery-less operation. As a result, wires, cables and active electronic components are avoided. Multi-channel recording is implemented by integrating photo-selective and photo-sensitive switches to activated individual channels via a multi-band light source and corresponding filters for channel selection. Overall, the proposed sensor system will provide, a unique opportunity to study longitudinal brain dynamics for studying brain activity in the natural environment of animals. The proposed sensing system will also have significant impact on safety and reliability for long-term operation."
"1631838","Collaborative Research: NCS-FO: Flexible Large-Scale Brain Imaging Analysis: Diversity, Individuality, and Scalability","IIS","IntgStrat Undst Neurl&Cogn Sys","09/01/2016","08/17/2016","Seung-Jun Kim","MD","University of Maryland Baltimore County","Standard Grant","Jonathan Fritz","08/31/2022","$492,988.00","Tulay Adali","sjkim@umbc.edu","1000 Hilltop Circle","Baltimore","MD","212500002","4104553140","CSE","8624","8089, 8091, 8551","$0.00","This project is designed to develop important analysis methods for brain imaging data, provide new educational and outreach activities to help promote the workforce, and create a software tool to foster big data analysis of the human brain. Functional magnetic resonance imaging (fMRI) enables noninvasive study of brain function, typically through the estimation of functional networks of connectivity. These networks are relatively stable, but it is also clear that there is a wide degree of differences across individuals. Given that now large-scale multi-subject data have now become available across multiple repositories, there is a pressing need for the development of a flexible analysis framework for large-scale fMRI data that can capture the global traits in brain activity, while not losing the individual aspects of a given brain. Such an accurate estimation of each subject's functional connectivity maps enables the leveraging of large and distributed fMRI repositories. It also promises effective comparisons across different conditions, groups, and time points, thus further increasing the usefulness of fMRI in human brain research. The project provides rich educational experience necessary for student training and workforce development in this fast growing field. The benefits are enhanced further via undergraduate research projects and public outreach programs such as brain awareness weeks, in addition to scholarly dissemination through publications, presentations, and workshop organization. The software toolbox developed as part of the project is freely distributed and enables wider adoption and reuse of the methods by the academia and the practitioners to move forward the brain research collectively. Ultimately, the project outcomes contribute to the NSF's mission of promoting the progress of science and advancing the national health, prosperity and welfare.<br/><br/>Data-driven methods based on latent variable models such as independent component analysis (ICA) have been increasingly adopted in fMRI data analysis. Recently, there have been lively debates as to whether ICA leverages source independence, exploits sparsity, or both, igniting active research in sparse matrix models such as dictionary learning (DL) for fMRI analysis. Indeed, synergistically balancing multiple notions of diversity remains an important challenge. In this context, it is first recognized that jointly leveraging both independence and sparsity enables a powerful and flexible framework for analyzing large-scale fMRI data, by capturing the common traits as well as individual details in a data-driven manner. Therefore, the complementary strengths of the already widely used blind source separation approaches such as ICA, and the more recent, sparse matrix factorization models such as DL are advantageously integrated. Essential practical aspects for large-scale data integration studies, such as decentralized computation and privacy-aware sharing of the datasets across multiple repositories are also addressed by leveraging the complementary expertise of the team."
"1631910","NCS-FO: Sub-millisecond Optically-triggered Compound Release to Study Real-time Brain Activity and Behavior","CBET","IntgStrat Undst Neurl&Cogn Sys","08/01/2016","08/09/2016","Zhenpeng Qin","TX","University of Texas at Dallas","Standard Grant","Aleksandr Simonian","07/31/2021","$800,000.00","Jonathan Ploski, Sven Kroener","Zhenpeng.Qin@utdallas.edu","800 W. Campbell Rd., AD15","Richardson","TX","750803021","9728832313","ENG","8624","8089, 8091, 8551","$0.00","1631910<br/>Qin, Zhenpeng<br/><br/>Understanding how the brain controls behavior requires advanced tools to manipulate brain activity. Inspired by recent progress in optogenetics (i.e., a technique to control selected types of brain cells with genetic modification and light stimulation), this project seeks to develop a new set of tools that will allow localized and ultrafast control of brain activity to influence behavior in freely-moving animals. This will be achieved by using light stimulation to rapidly release compounds that are encapsulated in tiny nanometer-sized particles. The ultrafast feature of this novel compound technology is ideally suited to manipulate brain activity that typically occurs on the scale of milliseconds. Importantly, this new technology is suited to packaging and releasing a wide range of chemical and biological compounds, as well as combinations of such compounds. The project's success will have a number of broader impacts. Scientifically, this project will generate a new technology to better understand how the brain works, and thus new knowledge about the brain and behavior. The ultrafast compound release method can potentially develop into a platform technology for other research areas, including the nervous system outside the brain. The collaborative environment of this project will provide interdisciplinary training opportunities for two graduate students with cutting-edge technologies in the fields of engineering and neuroscience. Finally, this project will promote STEM education both in the lab and through community outreach programs.  <br/> <br/>Advances in methodologies and tools for neuroscience research often lead to fundamental insights into the function of the central and periphery nervous system. Currently available methods for drug infusions using relatively large metal cannulas are not ideal for studies in freely behaving animals, because drug delivery is slow and the cannulas often destroy the brain area under study and/or overlying brain areas. New methods are needed to perform drug infusion or local release in a minimally invasively manner in freely moving animals. Inspired by recent developments in optogenetics, the PIs will develop a versatile optically-triggered system for sub-millisecond compound burst release for the real-time study of brain activity and behavior. Plasmonic liposomes, i.e. liposomes coated with a gold shell layer, can encapsulate a wide range of molecular compounds and be deposited locally in the brain. Due to the small width and poor clearance of the extracellular space in the brain, the plasmonic liposomes can be designed to stay in the injected area for prolonged periods of time. The encapsulated compound can then be quickly burst-released by a near-infrared pulsed laser via an implanted optical fiber. The encapsulated compounds can be designed to release by repeated triggers, allowing multiple on-demand drug release events over an extended period for behavioral studies. In this project, an integrated approach will be developed to deliver and release the encapsulated compounds, and to study the resulting brain activity and behavior change in real-time utilizing Pavlovian fear conditioning. Successful development of this sub-millisecond optically-triggered burst release technique will represent a major technological advancement that addresses the limitations of current techniques for behavioral research. Specifically, improved bio-compatibility and reduced invasiveness are anticipated by the by one-time nanoparticle infusion and on-demand light-triggered drug release. The fast release feature of the new technique will provide sufficient speed to study neuronal communication in neuroscience research. Furthermore, this technique will find wide applications in neuropharmacology research where targeted delivery and localized rapid release are currently unavailable."
"1817226","CHS: Small: Improving Usability and Reliability for Motor Imagery Brain Computer Interfaces","IIS","HCC-Human-Centered Computing","09/01/2018","09/13/2018","Virginia de Sa","CA","University of California-San Diego","Continuing Grant","Ephraim Glinert","08/31/2021","$500,000.00","","vdesa@cogsci.ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930934","8585344896","CSE","7367","7367, 7923, 8089, 8091","$0.00","Brain-computer interfaces (BCIs) allow a user to interact with the world directly through brain activity.  These systems are being developed to provide a communication method for users with severe motor impairments who are not able to control the movements of their arms, tongue, and even eyes well enough to communicate in the usual ways.  While the cognitive abilities of these individuals are thought to be largely preserved, they are often described as being ""locked in"" to their bodies, unable to interact with the outside world through the usual means of typing, talking, etc.  Electroencephalogram (EEG) based motor imagery BCIs attempt to distinguish brain activity by measuring electrical activity on the scalp caused by the user imagining moving different body parts.  Commonly, such systems try to distinguish when the user is imagining moving their right or their left hand.  Imagining different body parts can then be mapped to different tasks to allow a user to interact with the world (e.g., to turn a light on or off, or to move a robot arm to one object or another).  The goal of this research is to make these types of systems easier for users to learn and more reliable, by improving the feedback that is given to the user and improving the classification of the brain signals.  The work has the potential to open up this method of communication for more people, and project outcomes may have even broader impact by enabling us to learn more about brain signals that can be used for communication in BCIs.  In addition, diverse graduate students will be trained in interdisciplinary research, and undergraduate students in the BCI class will work on small related projects, some of which will be presented to high school students to encourage and stimulate their interest in science.<br/><br/>The ability of users to generate discriminable control signals is very variable. Moreover, environmental effects such as other brain processes, emotion and fatigue affect current BCI systems.  The goal of this project is to improve the usability of EEG-based motor-imagery brain-computer interfaces. To this end, a multi-pronged approach will be used.  First, richer feedback will give users a better visualization of the effects of their imagery and provide them with a better chance to learn how to discriminate the motor imagery of different body parts.  Second, the machine classification of the EEG signal during motor imagery will be improved.  This will include looking for other signals that may provide additional insight into the top-level state and goals of the user as well as developing new deep learning algorithms that can benefit from multi-task learning and transfer learning between individuals.  Third, different closed-loop control methods will be explored to improve the total information transfer rate of the BCI as well as to reduce the number of training trials needed.  The team's prior work has shown that interactive signals that respond to the feedback provided by the system are more robust to system estimation errors and non-stationarities.  These signals can arise passively but also can be actively used by exploiting interactive commands that vary with the received feedback.  Whether active control of interactive commands, or active control of standard commands with passive interactive recognition, performs better will be tested.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1660816","Development of Symbolic Number Processing Brain Networks from Kindergarten to 2nd Grade","DRL","ECR-EHR Core Research","04/15/2017","04/05/2019","Gavin Price","TN","Vanderbilt University","Continuing Grant","Gregg Solomon","03/31/2022","$1,345,085.00","","gavin.price@vanderbilt.edu","Sponsored Programs Administratio","Nashville","TN","372350002","6153222631","EHR","7980","1545, 8089, 8091, 8212, 8817","$0.00","Math skills are a strong predictor of life success, yet many people struggle to acquire basic numerical and mathematical skills. Being able to fluently process symbolic numbers (i.e. Arabic digits) is a key foundation for the development of basic math skills. However, very little is known about the brain systems which support the processing numerical symbols, how those systems develop in the early school years, and how they are related to math skill development. Understanding the development of these systems will help in achieving new insights into typical and atypical math development. This project, led by a team of researchers at Vanderbilt University, will provide the first multimodal, cohesive characterization of the trajectories and interrelations of the component mechanisms within the symbolic number processing brain network, and crucially, their relation to growth in math skills, during a window of time crucial for successful math development. In so doing, this project will provide significant new knowledge regarding typical development of symbolic number processing mechanisms and their relation to math that is crucial if we are to understand the sources of math learning disabilities.  Thus, the results of the proposed project will lay the foundation for future research investigating the causal mechanisms underlying math learning disabilities such as dyscalculia, by providing both an experimental and theoretical framework for empirical testing. Furthermore, this project will yield new insights into the developmental relations between symbolic and nonsymbolic number processing mechanisms, and the relation between brain structure and function. The results of this project will provide empirical evidence to support the development of more effective pedagogies and intervention approaches for math education. Such knowledge is crucial if we are to better understand math disabilities and better facilitate the acquisition of math skills. The project is funded by the EHR Core Research (ECR) program, which supports work that advances the fundamental research literature on STEM learning.<br/><br/>The goal of this project is to provide a multimodal characterization of the neural networks involved in the processing of symbolic numbers using functional magnetic resonance imaging (fMRI), as well as structural metrics of grey and white matter. No prior study has assessed the longitudinal development of children's number processing neural networks. The proposed connective network for symbolic number processing (intraparietal sulci, left angular gyrus, supramarginal gyri, ventral occipito-temporal cortex, and inferior frontal gyrus) is well-motivated from the literature on adult symbolic number processing. The project will examine the development of those networks from kindergarten through 2nd grade, and will examine the extent to which they predict math skill development. Investigators will study 120 children longitudinally from kindergarten to 2nd grade. In each year participants will complete a battery of symbolic and nonsymbolic number processing tasks in the fMRI scanner, in addition to a battery of behavioral tests measuring math skills and general cognitive abilities. Measures of brain structure will also be collected in each year."
"2010778","Novel Continuous Structural and Functional Networks and Prediction of Individual Cognition","DMS","CRCNS-Computation Neuroscience, MATHEMATICAL BIOLOGY, IntgStrat Undst Neurl&Cogn Sys","01/01/2021","08/12/2020","Moo Chung","WI","University of Wisconsin-Madison","Standard Grant","Zhilan Feng","12/31/2023","$900,000.00","","mkchung@wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","MPS","7327, 7334, 8624","079Z, 7327, 8089, 8091","$0.00","In recent years, human brain networks have received great attention since they describe comprehensive maps of structural and functional connections in the brain in relation to cognition, neuropsychiatric and genetics. Existing methods for network analysis partition the brain into a few hundred regions. Functional or structural information is then overlaid on top of the parcellation for further analysis. However, the parcellation of a few hundred regions cannot fully characterize potential differences in the brain anatomy and function among individuals. This project will tackle the challenge by developing computationally efficient mathematical models for building continuous brain networks. We will demonstrate the various uses of the new models including the prediction of individual cognitive abilities. The project will produce new algorithms in network models, deep learning and accompanying codes and processed data that will serve as a testbed for the development of more advanced methods. The impact of the project goes beyond the intended applications and will support more advanced methods in other areas. The project has great potential to reshape the research on how networks are constructed and analyzed. We expect that the continuous brain networks characterize the fundamental nature of individual brains and improve the predictive power to individual differences in terms of cognitive abilities. The project will also provide versatile an open-source toolbox of algorithms for modeling and visualizing large-scale functional and structural brain networks continuously.<br/><br/>Researchers who use existing brain parcellations for building and analyzing brain network models face several challenges: 1) the inherent limitations of using predetermined parcellations for understanding brain organizations in multiple spatial scales; 2) conflicting network topology over the choice of parcellation; 3) decreased sensitivity over multimodal integration. These have been raised as major challenges for the connectome-based prediction of individual cognitive abilities. The prediction models may not perform optimally if the boundary of the brain parcels does not fit the data well. Further, the specific choice of brain parcellations may bias prediction outcomes. Given these limitations, the main goal of the project is to develop computationally efficient mathematical models for building continuous functional and structural brain networks without using existing brain parcellations. Using these novel network constructions, we will develop new computationally efficient deep learning approaches that incorporate the proposed network geometry and predict individual cognitive abilities without relying on predefined parcellations. We will demonstrate the use of the continuous networks to understand brain organizations in multiscale levels and predict individual cognitive abilities such as intelligence, working memory, attention and cognitive controls.<br/><br/>This award is being co-funded by the CISE Information and Intelligent Systems (IIS) through the CRCNA and BRAIN Programs, and the MPS Division of Mathematical Sciences (DMS) through the Mathematical Biology Program.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1835270","NCS-FO: Unraveling Cortical Circuits for Auditory Scene Analysis","IIS","IntgStrat Undst Neurl&Cogn Sys","10/01/2018","08/28/2018","Kamal Sen","MA","Trustees of Boston University","Standard Grant","Mitra Basu","09/30/2021","$999,736.00","Xue Han","kamalsen@bu.edu","881 COMMONWEALTH AVE","BOSTON","MA","022151300","6173534365","CSE","8624","8089, 8091, 8551","$0.00","In everyday social situations, normal hearing humans are able to listen to a speaker in the midst of other people talking and other sound sources. This is an example of a general problem termed auditory scene analysis. The understanding of auditory scene analysis remains a challenging problem in a diverse range of fields such as neuroscience, computer science, speech recognition and engineering, after more than 50 years of research. Although a difficult problem for machines and hearing impaired listeners, humans with normal hearing solve it with relative ease. This suggests the existence of a solution to this problem in the brain, but this solution remains unknown. This project will investigate how the brain solves this problem. By revealing circuits in the brain that contribute to the solution, this project will ultimately improve quality of life through applications in medical devices, e.g., hearing aids and cochlear implants; benefit society through applications in technology, e.g., applications for speech recognition; and create an educational platform to train students to integrate knowledge from a variety of disciplines to address challenging and important societal problems.<br/><br/>The spatial location of different sound sources is an important component of auditory scene analysis. The auditory cortex, with its unique spatial sound processing ability, is thought to play an important role in auditory scene analysis, although the underlying neural network mechanisms remain largely unknown. This project will investigate cortical circuits for auditory scene analysis in the primary auditory cortex of the mouse, employing powerful optogenetic tools to investigate both bottom-up and top-down mechanisms. First, the investigators will examine the influence of behavioral states on cortical spatial representations of sound mixtures across different cortical layers and test the hypotheses that such spatial representations vary across cortical layers and behavioral states of the animal. Second, the investigators will examine the causal role of parvalbumin positive (PV) inhibitory interneurons versus somatostatin positive (SOM) inhibitory interneurons in the primary auditory cortex, using optogenetic manipulations, and test the hypothesis that PV interneurons are critical in mediating bottom-up signaling, whereas SOM interneurons are selectively engaged during active behavioral states. Finally, the investigators will construct a computational model of the primary auditory cortex including excitatory, PV and SOM neurons to explain the experimental results and make predictions for future experiments.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1734916","Collaborative Research:NCS-FO:Volitional modulation of neural activity in the visual cortex","BCS","ECR-EHR Core Research, IntgStrat Undst Neurl&Cogn Sys","09/01/2017","08/07/2017","Byron Yu","PA","Carnegie-Mellon University","Standard Grant","Betty Tuller","08/31/2021","$498,410.00","","byronyu@cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122688746","SBE","7980, 8624","8089, 8091, 8551, 8817","$0.00","This project is funded by Integrative Strategies for Understanding Neural and Cognitive Systems (NSF-NCS), a multidisciplinary program jointly supported by the Directorates for Computer and Information Science and Engineering (CISE), Education and Human Resources (EHR), Engineering (ENG), and Social, Behavioral, and Economic Sciences (SBE). Even basic perception of the world is not as simple as light coming into the eyes or sound coming into the ears.  Rather, perception involves combining the incoming sensory information with cognitive processes such as past experiences, knowledge about the world, and personal tendencies.  In other words, two people observing the same events (i.e., receiving the same sensory information) can arrive at different interpretations of what is happening in the environment.  How the brain combines sensory information with these cognitive processes, and where this occurs in the brain, is incompletely understood.  The key innovation of this project is to use a brain-computer interface (BCI) to tease apart which aspects of the brain's activity are sensory versus cognitive and how the two are combined in the brain to produce perception of the world.  BCIs are widely-known for their ability to help paralyzed patients and amputees by allowing them to move a computer cursor or robotic arm simply by thinking about moving.  Few studies have used BCIs as an experimental tool to understand sensory areas of the brain, as this project seeks to do.  This work is likely to lead to a deeper understanding of how we perceive the world, as well as insights into how BCI can be used to help treat psychiatric disorders and recover function after injury.  Furthermore, the investigators are developing BCI-based lab exercises for undergraduate courses, training researchers to become well-versed in experimental and computational neuroscience, and involving undergraduates, including women and underrepresented minorities, in the research.  <br/><br/>This project focuses on visual area V4, which is known to be a crossroads for sensory and cognitive processes during visual perception.  To dissect what aspects of neural activity are sensory versus cognitive, the investigators train animal subjects to volitionally modulate their V4 activity.  The BCI provides subjects with moment-by-moment auditory feedback of their V4 activity.  This project assesses what aspects of V4 activity can be volitionally (i.e., cognitively) modulated, how volitional modulation of V4 activity affects visual perception, and how malleable is the interaction between V4 and another brain area (prefrontal cortex) during visual perception.  The key advantage of using BCI for this study is that it allows the investigators to challenge the subjects to produce particular patterns of neural activity.  The investigators can specify in the BCI which patterns of activity yield a reward.  This technique allows them to assess what aspects of the neural activity can be volitionally controlled by the animal (i.e., cognitive), and what aspects are hard-wired to the outside world (i.e., sensory). The applications of this BCI paradigm are extremely broad, and can be used to study other sensory, cognitive, and motor systems."
"1631681","NCS-FO: Collaborative Research: Operationalizing Students' Textbooks Annotations to Improve Comprehension and Long-Term Retention","DRL","ECR-EHR Core Research","09/01/2016","08/17/2016","Harold Pashler","CA","University of California-San Diego","Standard Grant","Gregg Solomon","08/31/2021","$300,000.00","","hpashler@ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930934","8585344896","EHR","7980","8089, 8091, 8551, 8817","$0.00","While traditional textbooks are designed to transmit information from the printed page to the learner, contemporary digital textbooks offer the opportunity to study learners as they interpret and process information being read. With a better understanding of a learner's state of mind, textbooks can make personalized recommendations for further study and review. How can the learner's state of mind be determined? Open a used printed textbook and the answer is clear: students feel compelled to engage with their texts by annotating key passages with highlights, tags, questions, and notes. Despite students' spontaneous desire to annotate as they read, this form of interaction has reaped few educational benefits in the past. At best, highlighted passages are re-read to study for exams, a strategy not nearly as effective as other strategies such as self-quizzing. This project will develop a new methodology that: assesses student knowledge level automatically based on annotations, transforms highlighted passages into appropriate study questions, and provides each student with well-timed, personalized review. Because the project is based on free, peer-reviewed, openly licensed materials from OpenStax that have been widely adopted at a range of institutions, particularly community colleges, the technology will reach beyond elite institutions to provide a broad spectrum of underserved students with access to a potentially powerful learning tool.<br/><br/>This project adopts a big-data approach that involves collecting annotations from a population of learners to draw inferences about individual learners. The project will determine how to exploit these data to model cognitive state, enabling the team to infer students' depth of understanding of facts and concepts, predict subsequent test performance, and perform interventions that improve learning outcomes. A tool will be developed that administers appropriately timed quizzes on material related to a student's highlights. A collaborative-filtering methodology will be employed that leverages population data to suggest specific passages for an individual to review. The proposed tool will reformulate selected passages into review questions that encourage the active reconstruction and elaboration of knowledge. The design and implementation of the tool will be informed by both randomized controlled studies within the innovative OpenStax textbook platform and coordinated laboratory studies. These studies will address basic scientific questions pertaining to why students annotate, how to improve their annotation skills, and techniques to optimize the use of annotations for guiding active review."
"1706207","CBET-EPSRC: Hybrid organic-CMOS devices for optogenetic stimulation and lens-free fluorescence imaging of the brain","CBET","BioP-Biophotonics","07/01/2017","04/13/2020","Kenneth Shepard","NY","Columbia University","Standard Grant","Leon Esterowitz","06/30/2022","$332,000.00","","shepard@ee.columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","ENG","7236","7236, 8089, 8091, 9251","$0.00","This collaborative proposal by Dr. Shepard from Columbia University and an international team of researchers from the UK, will develop an optical imaging approach to study freely-behaving animals and potentially humans. The proposal explores original and transformative approaches for overcoming current barriers of functional imaging of the brain. If successful, the platform developed by this project will be critical to many research projects, which will further understanding of the functioning of the brain as well as various brain disease mechanisms<br/><br/>The approach builds on the development of a dense 3D lattice of emitters and detectors embedded onto ultra-narrow implantable neural probes. The proposal includes 3 aims comprising (1) the development of fully integrated high-density optogenetic stimulators, (2) development of time-gated fluorescence detection of lens-free neuronal recordings and (3) in vitro and in vivo characterization and validation of the system.                              The work includes educational and outreach activities, including; integration of educational material into courses on neuroscience, bioelectronics and biophotonics at Columbia University and at St. Andrews."
"2024633","NCS-FO: Advantages of varying navigational abilities in humans and robots","IIS","IntgStrat Undst Neurl&Cogn Sys","10/01/2020","10/13/2020","Elizabeth Chrastil","CA","University of California-Irvine","Standard Grant","Kenneth Whang","09/30/2023","$996,438.00","Craig Stark, Jeffrey Krichmar, Mary Hegarty","chrastil@uci.edu","160 Aldrich Hall","Irvine","CA","926977600","9498247295","CSE","8624","8089, 8091, 8551, 9102","$0.00","Despite the importance of navigational skill, people?s ability to find their way around and the approaches they take vary widely. Yet we do not know why this variation exists or how different strategies are used during everyday navigation. In robotics, self-driving cars, and other autonomous systems, it has become increasingly clear that a one-size-fits-all approach is not viable for all environments and user needs. Similarly, producing autonomous systems with different navigational strengths could improve the capacity of autonomous systems as a whole, such as teams of exploring or search-and-rescue robots. This project brings together researchers from neuroscience, cognitive psychology, computer science, and robotics to study variability in navigation abilities and strategies in complex environments. The researchers combine behavioral, neuroscience, and computational approaches. Pinpointing the neural and behavioral markers that underlie individual differences will lead to customized solutions to navigational challenges and optimize the performance of autonomous systems for differing environmental conditions. The outcomes of this research will have the following specific benefits to society and scientific discovery: 1) advancing theoretical understanding of the processes involved in spatial navigation, 2) understanding the advantages of variation in both humans and robots, impacting how people approach both fields, 3) implications for improvements in self-driving cars, GPS wayfinding devices, and transportation signage, and 4) broader dissemination of virtual reality (VR) technology.<br/><br/>The overarching cross-disciplinary aims of this study are to 1) test whether human spatial navigation is a singular competence or whether multiple abilities contribute, 2) establish the neural markers of human navigational abilities through multi-modal imaging, and 3) implement and test different navigational abilities in robots in real-world situations. This study will be the largest to date (n = 270) to study human navigation abilities, using both structural equation modeling and multivariate analysis of imaging data to deeply address this question. Furthermore, the project will broaden the scope of abilities to relate navigation skills to working memory, learning, personality, and other factors. Implementing navigational strategies and abilities in robots provides a controlled test of their tradeoffs. By manipulating the planning and mapping strategies of robots, the researchers can isolate particular abilities and their contributions to navigation, testing both navigational theory and practical advantages for autonomous systems. The interdisciplinary approach of this project harnesses the strengths of cognitive science, robotics, and neuroscience to test the fundamental nature of human individual variability.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1813785","RI: Small: Sparse Predictive Coding for Energy Efficient Visual Navigation in Dynamic Environments","IIS","Robust Intelligence, IntgStrat Undst Neurl&Cogn Sys","10/01/2018","08/15/2018","Jeffrey Krichmar","CA","University of California-Irvine","Standard Grant","Kenneth Whang","09/30/2021","$450,000.00","Charless Fowlkes","jkrichma@uci.edu","160 Aldrich Hall","Irvine","CA","926977600","9498247295","CSE","7495, 8624","7495, 7923, 8089, 8091","$0.00","This project develops efficient machine vision algorithms inspired by the architecture and energetic efficiency of the primate visual system for motion processing. Navigating through a rich cluttered natural environment, while both the observer and the objects in the scene are moving, is a difficult problem in machine vision, particularly for real-time processing under power constraints. However, humans and other animals perform these tasks with ease. The nervous system is under tight metabolic constraints and this leads to incredibly efficient representations of important environmental features, such as the observer's heading, the depth of objects, and the motion of objects.  In addition, these efficient machine vision algorithms can be applied to robotics, the IoT, and edge processing.  The algorithms can be applied to a wide range of applications, including augmented reality, assistive robotics, autonomous vehicles, and the Internet of Things (IoT) Thus, they could have a transformative economic and societal impact by creating applications that can operate autonomously over long periods in remote locations.<br/><br/>Inspired by ability of the nervous system to efficiently encode and appropriately respond to the visual features that make up a dynamic scene, the algorithm uses sparse predictive coding techniques to process data streams from cameras. Because the algorithms can be realized in spiking neural networks, where the artificial neurons only send signals when an event occurs, they can run efficiently on low powered neuromorphic systems; computers that support such representations.  By employing an architecture inspired by the brain, where op-down signals from the frontal cortex and parietal cortex predict where objects will be in the future, the system will have better object tracking and overcome difficulties when objects become hidden from view.  These representations are sparse and reduced, leading to energy efficient processing, less computation, and thus low power consumption.  In summary, the machine vision algorithms: (1) increase our understanding of how the brain encodes behaviorally relevant signals in the world, (2) lead to computationally efficient handling of large data streams, and (3) realize power efficient processing for a wide range of embedded applications.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1926794","Collaborative Research: NCS-FO Biology and Function of Prosody: Integrative approach to individual differences","DUE","ECR-EHR Core Research","10/01/2019","08/21/2019","Reyna Gordon","TN","Vanderbilt University Medical Center","Standard Grant","Ellen Carpenter","09/30/2023","$606,605.00","Jennifer Below","reyna.gordon@vanderbilt.edu","1161 21st Ave. South","Nashville","TN","372325545","6153222450","EHR","7980","1545, 8089, 8091, 8817","$0.00","College readiness and career opportunities are highly dependent on young adults' reading proficiency. Yet, recent data indicate that almost two-thirds of tested students, including many students with dyslexia, do not possess the fundamental skills that are required to successfully master college-level reading material. Prosody, defined as linguistically relevant fluctuations in intonation, stress and timing, is an essential but underappreciated aspect of spoken language and reading. Humans vary in their sensitivity to the prosodic structure of speech, and there appears to be a strong link to individual differences in reading skills. With the support of the Integrative Strategies in Neural and Cognitive Systems program, this project will take bold steps towards investigating the biology and function of prosody with a creative array of approaches and research settings. With the first-ever dataset of its kind, the project intends to make critical progress towards integrating knowledge from a large population sample about the neurobiological basis of prosody across methods and levels (genetics, neuroimaging, and behavioral task performance). Beyond scientific advancement, the activities outlined in the proposed project will allow the research team to contribute to improving STEM education and educator development, addressing neurodevelopmental disorders such as dyslexia, increasing public engagement with science and technology, and enhancing big-data partnerships across academic sites.<br/><br/>The underlying biology of prosody is poorly understood at the neural and genetic level, despite its important function in humans' communication skills. Innovative combinations of multi-disciplinary approaches for novel data collection in large samples and use of existing large-scale resources are needed to yield significant knowledge of the biology and function of prosody. The first aim of this proposal will include a series of studies using a combination of EEG, eye tracking and standardized behavioral tasks to explore the time-dynamic processes of attending to prosodic cues in ecologically valid situations of speech perception and reading, and to examine the contribution of prosody sensitivity to individual differences in reading. The second aim will be a genome-wide association study of prosodic sensitivity and will be conducted through a diverse sample of individuals recruited online throughout the United States and in-person in the Middle Tennessee area in local community and educational settings. Cutting-edge genomic methodologies (PrediXcan and Gene Set Enrichment analysis) will be used to identify the genetic markers and novel neural endophenotypes (imputed gene expression in brain tissue) that give rise to individual differences in prosody. This series of studies builds essential groundwork for future planned studies that seek to disentangle shared versus separate genetic architecture of prosody and other aspects of language function and could reveal transformative knowledge about the biological mechanisms driving individual differences in reading and language skill. The collaborative research project leverages the team?s diverse backgrounds in Cognitive Neuroscience, Psycholinguistics, Communication Disorders, and Human Genetics.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1835202","NCS-FO: Collaborative Research - Human decision-making in complex environments","BCS","ECR-EHR Core Research, IntgStrat Undst Neurl&Cogn Sys","09/01/2018","08/28/2018","Ernst Niebur","MD","Johns Hopkins University","Standard Grant","Jonathan Fritz","08/31/2021","$632,675.00","Veit Stuphorn, Sridevi Sarma","niebur@jhu.edu","1101 E 33rd St","Baltimore","MD","212182686","4439971898","SBE","7980, 8624","7298, 8089, 8091, 8551, 8817","$0.00","Decision-making is one of the most central cognitive functions of importance at practically all levels of society. In many real-world decisions, which of the available alternatives is chosen is influenced by many different attributes. Such multi-attribute decisions are complex because they require the integration and comparison of many pieces of information. For instance, selecting the bundle of goods that maximizes value given a budget constraint in a supermarket that only stocks 100 different goods requires checking approximately 10^30 possible combinations. For this reason, humans do not use rational choice theory in all their decisions. In addition to having to combine the influence of all the different attributes, another complexity is that one alternative is often preferable on one set of attributes, but another is preferred on others. Making a choice then requires a trade-off, which further complicates the decision process. However, the cognitive and neural processes that are at the heart of preference formation are still poorly understood.  This complexity is thought to tax limited cognitive resources in humans who therefore can pay attention only to a limited set of information, on which the decision is then based. In addition, task history often systematically changes decision biases. This research program takes advantage of the opportunity to obtain direct recordings from individual's brains while they perform such complex decision. It will study these activity patterns to determine whether they can be explained via mathematical models of decision making. Understanding which attributes are considered during decision making, and how they are weighted could explain decision making in typical and a-typical populations. Furthermore this integrative research program forms an opportunity to expose engineering students to dynamical systems and control theories in an interdisciplinary context.<br/><br/>This project combines behavioral data, neural recordings in humans (patients undergoing epilepsy evaluation) implanted with multiple depth electrodes covering many cortical and subcortical brain areas, and computational approaches to develop a new theory of the neural mechanisms underlying multi-attribute decision-making in complex environments. This is a unique opportunity to study brain circuits simultaneously across multiple brain areas while humans make these decisions.  The overall goal of the present proposal is to understand the neural circuit involved in (1) representing the relevant decision variables, (2) integrating these variables to form subjective values, and (3) selecting one of the options in multi-attribute decisions. Participants, with implanted electrodes, will work in a novel behavioral task that makes it possible to observe their focus of attention while they evaluate the offers and select one of them.  Data will constrain cutting edge computational models of multi-attribute decision making that will combine: (i) a procedural model of the decision in each trial, and (ii) a latent variable model of biasing influence on decision-making resulting from past trial history. The computational models will make it possible to identify neuronal activity that represents task-relevant variables and the dynamic flow of information across the different elements of the identified neural circuit.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2011542","CRCNS US-German Research Proposal: Origin of distributed modular activity in the neocortex","IIS","Cross-BIO Activities, CRCNS-Computation Neuroscience","12/01/2020","10/19/2020","Gordon Smith","MN","University of Minnesota-Twin Cities","Continuing Grant","Sridhar Raghavachari","11/30/2023","$514,287.00","","gbsmith@umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","7275, 7327","7327, 8089, 8091, 9179","$0.00","In the brain, early developmental events define and constrain its future capabilities and functions. Large-scale cortical networks are critical to the processing of information in the brain, yet very little is known about how such networks arise in early development. This project will address this critical question by creating an interdisciplinary collaboration that will develop and then test novel computational models of neural activity in the early cortex. These models will aim to describe the mechanisms through which functional neural networks arise in the early cortex, thereby providing critical new insights into brain development. Furthermore, this project will employ cutting edge optical approaches to measure and manipulate networks in the developing cortex, providing a direct test of these models. This project will produce novel computational tools and unique large-scale imaging datasets of the early brain that will be valuable to the broad scientific community, while also providing key training for junior scientists in the tight integration of theory and experiment. Collectively, this project will yield new insights into fundamental questions of functional brain development and generate novel tools and datasets for future research. <br/><br/>Cortical activity in primates and carnivores is both modular (columnar) and distributed, linking functional units that are spread across cortical space. Computational models suggest that these two properties can arise from local network interactions in the early developing cortex, however both critical aspects of the proposed mechanisms and experimental validation are currently lacking. In order to address this key gap in the understanding of cortical network development, this project will combine computational modeling with highly sensitive calcium imaging and pharmacological and optogenetic methods for up-and down-regulating specific circuit components. This research will derive critical predictions for the effects of experimental manipulations of local network components on modular and distributed cortical activity and then perform these manipulations in vivo to test the validity of the proposed mechanisms. This work will greatly deepen the understanding of the origin of modular and distributed activity in the early developing cortex, while addressing long-standing issues in the field by identifying the cortical mechanism for generating modular activity and testing whether long-range network correlations can arise from local recurrent connections as a truly emergent property. By combining state of the art experimental approaches, data analysis, and theoretical modeling, this project will yield a quantitative understanding of the mechanisms that give rise in the young brain to two of the most prominent features of cortical activity. <br/><br/>A companion project is being funded by the Federal Ministry of Education and Research, Germany (BMBF).<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1926818","NCS-FO: Integrative Approaches to Study the Role of Early Life Sleep Disruption in Brain Development and Autistic Behaviors","BCS","ECR-EHR Core Research, IntgStrat Undst Neurl&Cogn Sys","10/01/2019","10/15/2020","Hung Cao","CA","University of California-Irvine","Standard Grant","Kenneth Whang","09/30/2022","$1,009,000.00","Payam Heydari, Plamen Atanassov, Miranda Lim","hungcao@uci.edu","160 Aldrich Hall","Irvine","CA","926977600","9498247295","SBE","7980, 8624","8089, 8091, 8551, 8817, 9251","$0.00","Early life sleep disruption (ELSD) has been shown to affect the development of complex social behaviors in animals, impairing social bonding between prairie voles in a manner reminiscent of autism in humans. In order to understand the underlying changes in brain development, there is a dire need to develop innovative tools that can measure neurotransmitter levels in real-time during complex social interactions among two or more animals. In this project, the research team will design, implement and test novel integrated biosensor microprobes that will simultaneously record two key brain neurotransmitters (L-glutamate, an excitatory neurotransmitter, and Gamma Aminobutyric Acid [GABA], an inhibitory neurotransmitter) in real time during complex social interactions using this vole model of autism. The biosensor system will be made wireless and will also be combined with electroencephalography (EEG), as a measure of brain electrical activity. This highly collaborative project advances neuroengineering by developing a much-needed method to measure Excitation:Inhibition (E:I) balance in the brain in real-time, which will inform fundamental questions about the brain control of social interactions in healthy and autistic individuals.<br/><br/>The specific tasks of this study are as follows: Task 1) Develop and test wired, enzyme-based flexible integrated dual-sensor probes to assess L-glutamate and GABA levels in prairie voles in order to examine E:I balance in the brain during complex social interactions. Task 2) Develop and test a wireless system with an integrated L-glutamate and GABA flexible dual-sensor probe to study changes in the E:I balance the brain during complex social interactions. Task 3) Develop and test a wireless dual sensor probe integrated with EEG as a way to investigate effects of ELSD on EEG gamma oscillations as a functional readout of E:I balance during complex social interactions. The microprobes and systems developed in this project can be generalized to other studies of neurological disorders using rodents or larger animal models. The outcomes would help reveal how neural processes may go awry in neurodevelopmental disorders, as well as enable the next generation of neural prostheses, therapeutics and brain machine interfaces.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1631556","NCS-FO: Collaborative Research: Operationalizing Students' Textbooks Annotations to Improve Comprehension and Long-Term Retention","DRL","ECR-EHR Core Research","09/01/2016","08/17/2016","Richard Baraniuk","TX","William Marsh Rice University","Standard Grant","Gregg Solomon","08/31/2021","$400,000.00","Phillip Grimaldi","richb@rice.edu","6100 MAIN ST","Houston","TX","770051827","7133484820","EHR","7980","8089, 8091, 8551, 8817","$0.00","While traditional textbooks are designed to transmit information from the printed page to the learner, contemporary digital textbooks offer the opportunity to study learners as they interpret and process information being read. With a better understanding of a learner's state of mind, textbooks can make personalized recommendations for further study and review. How can the learner's state of mind be determined? Open a used printed textbook and the answer is clear: students feel compelled to engage with their texts by annotating key passages with highlights, tags, questions, and notes. Despite students' spontaneous desire to annotate as they read, this form of interaction has reaped few educational benefits in the past. At best, highlighted passages are re-read to study for exams, a strategy not nearly as effective as other strategies such as self-quizzing. This project will develop a new methodology that: assesses student knowledge level automatically based on annotations, transforms highlighted passages into appropriate study questions, and provides each student with well-timed, personalized review. Because the project is based on free, peer-reviewed, openly licensed materials from OpenStax that have been widely adopted at a range of institutions, particularly community colleges, the technology will reach beyond elite institutions to provide a broad spectrum of underserved students with access to a potentially powerful learning tool.<br/><br/>This project adopts a big-data approach that involves collecting annotations from a population of learners to draw inferences about individual learners. The project will determine how to exploit these data to model cognitive state, enabling the team to infer students' depth of understanding of facts and concepts, predict subsequent test performance, and perform interventions that improve learning outcomes. A tool will be developed that administers appropriately timed quizzes on material related to a student's highlights. A collaborative-filtering methodology will be employed that leverages population data to suggest specific passages for an individual to review. The proposed tool will reformulate selected passages into review questions that encourage the active reconstruction and elaboration of knowledge. The design and implementation of the tool will be informed by both randomized controlled studies within the innovative OpenStax textbook platform and coordinated laboratory studies. These studies will address basic scientific questions pertaining to why students annotate, how to improve their annotation skills, and techniques to optimize the use of annotations for guiding active review."
"1926793","NCS-FO: Developing engineering solutions to investigate microbiome-to-neuron communication","ECCS","IntgStrat Undst Neurl&Cogn Sys","09/15/2019","08/27/2019","Reza Ghodssi","MD","University of Maryland, College Park","Standard Grant","John Zhang","08/31/2022","$1,000,000.00","William Bentley, Wolfgang Losert, Jens Herberholz","ghodssi@umd.edu","3112 LEE BLDG 7809 Regents Drive","College Park","MD","207425141","3014056269","ENG","8624","8089, 8091, 8551","$0.00","The goal of this project is to create an engineering solution to measure and predict the molecular communication across the gut-microbiome-brain axis. This platform has the potential to facilitate the fundamental understanding of gut microbiome communication with the nervous system. The project will quantify release patterns of key molecules involved in this cross-talk and identify their influence on neural activation and behavior. The gut-microbiome-brain axis, comprising a vast network of nerves innervating the gut and propagating signals to the brain, is a major influencer of behavior and cognition. The neurotransmitter serotonin is a key molecule in this pathway; gut epithelial cells sense luminal conditions and release serotonin to stimulate nearby neurons. The gut microbiome has been shown to mediate this serotonin release, a process that is also linked to the co-occurrence of gastric and neural disorders. The technical underpinnings of this work involve designing and constructing a device that enables researchers to assemble the essential components of the gut-microbiome-neuron tissue interface. The device is fabricated with sensors to obtain information that is currently inaccessible - collecting molecular information at the length and time scales of the cells and tissues under investigation. The data extracted from this platform will enable temporal correlation and prediction of microbial, gut, and neural signaling patterns. This work provides opportunities to bring together researchers and stakeholders from various disciplines including electrical and computer engineering, bioengineering, molecular biology, neuroscience, and data science to develop a system-oriented approach. Further, this project promotes the participation of women, historically underrepresented in engineering, and undergraduates through programs such as Women in Engineering Research Fellowship and First-Year Innovation and Research Experience (FIRE). <br/><br/>Multidisciplinary engineering methods are essential to building an in vitro discovery platform capable of directly monitoring chemical transduction patterns along the gut-neuron axis. In TASK 1, electrochemical sensors will be directly fabricated on a porous cell culture substrate, allowing direct access to cellular and molecular mechanisms of an in vitro model gut epithelium. Impedance monitoring of the cell layer will detect physical changes over time (e.g., barrier integrity). Potentiometric monitoring will detect real-time serotonin released from gut cells due to bacterial metabolite stimulation. In TASK 2, the neural effect of gut serotonin signaling will be studied by exposing this cell-released serotonin to an isolated ex vivo crayfish nerve cord with connected and innervated hindgut. Neurobehavioral activation patterns will be recorded during hindgut peristalsis in motor and sensory neurons that bidirectionally connect the central and enteric nervous systems. Machine learning approaches will identify key variables to quantify discrete serotonin release and neuronal activation patterns. In TASK 3, the mucosal layer of the gut epithelium will be colonized with specific gut microbes to assess bacterial influence on barrier integrity, serotonin release patterns, and resulting neuromuscular activation. Classification via machine learning will quantify the wholistic and synergistic effects of different microbial combinations on time-dependent serotonin release profiles and downstream effects. There are multiple novel aspects of this work. First, this is a new platform implementing extensive integrated cell-interfacial sensors for direct access to real-time cell and molecular data. Second, the use of this technology to investigate the interplay between gut and nervous system can give unprecedented insight into the vast and relatively inaccessible gut-brain transduction pathways. Third, machine learning analysis can identify meaningful patterns of serotonergic communication and predict the expected impact of gut bacteria on neural behavior.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1835278","NCS-FO: Engineering Living Neural Networks for Learning","ECCS","CCSS-Comms Circuits & Sens Sys, IntgStrat Undst Neurl&Cogn Sys","09/01/2018","05/12/2020","Xiaochen Guo","PA","Lehigh University","Standard Grant","John Zhang","08/31/2022","$509,038.00","Zhiyuan Yan, Yevgeny Berdichevsky","xig515@lehigh.edu","Alumni Building 27","Bethlehem","PA","180153005","6107583021","ENG","7564, 8624","090E, 8089, 8091, 8551, 9251","$0.00","Recent developments in optogenetics, patterned optical stimulation, and high-speed optical detection enable simultaneous stimulation and recording of thousands of living neurons. Connected biological living neurons naturally exhibit the ability to perform computations and to learn. The proposed project will engineer living neural network to compute for learning task. Experimental testbed will be built to allow optical stimulation and detection. Algorithms will be developed to train the living neuron networks. The proposed testbed can be used by neuroscientists to verify network-level hypotheses. Insights learned from the proposed research can inspire other neuromorphic architectures based on solid state devices. Throughout this project, graduate students will be trained in computer engineering, bioengineering, and signal processing. Students will have the opportunity to work on interdisciplinary research in these fields. New courses based on the results from the proposed work will be introduced and new modules will be added to existing curriculum. The proposed outreach activities aim to attract interest to computer engineering and neural engineering.<br/><br/>The goal of this project is to use optogenetic in vitro neural network to run learning applications. Living neural networks have spontaneous activities, which can interfere with precise modification of synaptic strength. This research will study how to stabilize the living neural network such that a Spike Time Dependent Plasticity (STDP)-based programming protocol can imprint the desired synaptic strengths onto a living neural network. This research will also investigate how to strategically design and apply an STDP-based protocol to maximize programming throughput and optimize convergence rate of the network states. On the algorithm side, the proposed research will study data representation and training algorithms that consider various constraints of the proposed wetware system. Learning algorithms will be designed to work on random neural networks of unknown topology. Observable details of neuron activities will be used to improve accuracy of learning tasks.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1835268","NCS-FO: Collaborative Research: Optoelectronic Tools for Closed-Loop Neuron Ensemble Recording and Control during Complex Behaviors","ECCS","IntgStrat Undst Neurl&Cogn Sys","09/15/2018","06/19/2019","Guangyu Xu","MA","University of Massachusetts Amherst","Standard Grant","John Zhang","08/31/2022","$953,300.00","David Moorman, Geng-Lin Li","guangyux@umass.edu","Research Administration Building","Hadley","MA","010359450","4135450698","ENG","8624","8089, 8091, 8551","$0.00","Brain science will benefit from the capabilities in tracing complex animal behaviors down to ensembles of individual neurons, and moreover establishing a real-time closed-loop brain-interface, ideally with deep brain access in a free-moving animal. This research project aims to address the focus areas in this National Science Foundation program by merging novel neurotechnology, evaluation of neural circuits during performance of complex cognitive behaviors, and large-scale neuron ensemble analysis and closed-loop behavioral control. The outcome of this research will result in new technologies and computational tools that can be used across the field of neuroscience and behavior, strengthening research efforts of multiple research groups. The educational objectives of this proposal are aimed at training and inspiring young engineers and scientists who are equipped with the multidisciplinary background required to help define the future trajectory of brain interfaces and data sciences. The broader impacts of this project include: 1) advancing transformative device technologies for next-generation neurotechnology and providing new and more powerful tools for neuroscience studies, 2) educating underrepresented undergraduate and graduate researchers to contribute to the nation's workforce needs in biotechnology, 3) contributing to the K-12 science, technology, engineering, and mathematics education through weekend seminars and mentoring student-teacher pairs from local middle/high schools; and 4) promoting neuroscience and neurotechnology among local senior citizens and support groups for neurological diseases.  <br/><br/>The research objective of this proposal is to combine high precision optoelectronic neural probes with real-time neural decoding to feedback optogenetic control over animal behavior. Such closed-loop neural interface will establish a generalizable technology platform to study complex animal behaviors using optogenetic tools and real-time learning. The proposed work will open ample research opportunities and form connections among hardware engineering, cognitive neuroscience, and data science. The intellectual merit of the proposed work will be evidenced by three major contributions: 1) demonstration of high-precision optogenetic brain interface that combines multiplexed recording from and bi-directional control over neuron ensembles, 2) demonstration of closed-loop brain interface that employs real-time neural decoding and adaptive learning to control animal behavior, and 3) characterization of complex decision-making using high-precision, multiplexed data linking multiple brain areas.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1734883","The Impact of Real World Stressors on Problem-Solving","DUE","ECR-EHR Core Research, IntgStrat Undst Neurl&Cogn Sys","10/01/2017","07/22/2019","Ying Choon Wu","CA","University of California-San Diego","Standard Grant","Gregg Solomon","09/30/2021","$769,024.00","Tzyy-Ping Jung, Sheldon Brown","yingchoon@gmail.com","Office of Contract & Grant Admin","La Jolla","CA","920930934","8585344896","EHR","7980, 8624","8089, 8091, 8212, 8551, 8816, 8817","$0.00","This project examines how variability in daily stress and fatigue--previously dismissed as uncontrollable 'noise' in cognitive processing--relates to variability in learning and problem-solving.  This project is motivated in part by evidence that performance on tests of executive function and memory can fluctuate as a function of recently experienced, real-world, daily stressors.  Because problem-solving recruits these and other cognitive abilities, it is hypothesized that day-to-day stressors can also impact our approaches to and success with complex, open-ended challenges regularly faced in educational and professional contexts.  Further, on the basis of preliminary research, it is anticipated that a subset of individuals will exhibit greater resilience to stressors than others.  In other words, for some, day-to-day stressors may create contexts that facilitate tackling problems to greater or lesser degrees, whereas for others, recent stressors may impact outcomes minimally.  This work wields important implications for STEM education given the increasing priority placed on problem-solving skills.  It will offer new foundations for modeling individual differences in resilience and vulnerability to everyday stressors during complex tasks. Moreover, understanding stressor-related intra-individual variability can lead to strategies for improving performance of high-stakes, resource demanding operations (e.g., piloting an airplane).  <br/><br/>Building from methods of Ecological Momentary Assessment (EMA), both subjective and physiological measures of stress and fatigue will be sampled from healthy adults on a daily basis as they engage in their regular routines of daily life. These data will be uploaded by participants to a secure server via smart phone and will be monitored by research staff. When daily sampling logs suggest the recent experience of high, medium, or low levels of stressors, participants will be scheduled for a testing session to be conducted in their own home or at the research facilities of the Swartz Center for Computational Neuroscience. They will engage in STEM-related problem-solving tasks modeled after real world activities. Simultaneously, electroencephalographic (EEG) data, eye movement, and electrocardiography will be recorded and synchronized. Monitoring periods are expected to last between one and three months and encompass nine testing sessions. This project will result in a rich corpus of data that can be probed from many different angles, offering an unprecedented view of intra-individual variability in task performance as a function of day-to-day changes in physiological and cognitive state.  It is expected to reveal behavioral and brain dynamics supporting insight and discovery.  Further, expanding from episode-based models of the metacognitive components of problem-solving, it is expected to tease apart ways in which various theorized components--such as representing the problem space, exploring, planning a solution, and implementation--may be differently affected by daily stressors.  This project is funded by Integrative Strategies for Understanding Neural and Cognitive Systems (NSF-NCS), a multidisciplinary program jointly supported by the Directorates for Computer and Information Science and Engineering (CISE), Education and Human Resources (EHR), Engineering (ENG), and Social, Behavioral, and Economic Sciences (SBE)."
"1735004","NCS-FO: Collaborative Research: Integrative Foundations for Interactions of Complex Neural and Neuro-Inspired Systems with Realistic Environments","IIS","IntgStrat Undst Neurl&Cogn Sys","09/01/2017","08/07/2017","Terrence Sejnowski","CA","The Salk Institute for Biological Studies","Standard Grant","Kenneth Whang","08/31/2021","$481,411.00","","terry@salk.edu","10010 N TORREY PINES RD","LA JOLLA","CA","920371002","8584534100","CSE","8624","8089, 8091, 8551","$0.00","This project will integrate the capabilities of deep learning networks into a biologically inspired architecture for sensorimotor control that can be used to design more robust platforms for complex engineered systems. Studies of the flexibility and contextual aspects of sensorimotor planning and control will extend existing paradigms for human-robot interactions and serve as the foundation for creating personal assistants that are able to operate in natural settings. Growing understanding of how these layered architectures are organized in the brain to produce highly robust, flexible, and efficient behavior will have many applications to rapidly evolving technologies in complex environments, including the Internet of Things, autonomous transportation, and sustainable energy networks.<br/><br/>The nervous system is a layered architecture, seamlessly integrating high-level planning with fast lower level sensing, reflex, and action in a way that this project aims to both understand more deeply and mimic in advanced technology. The central goal is to develop a theoretical framework for layered architectures that takes into account both system level functional requirements and hardware constraints. There are both striking commonalities and significant differences between biology and technology in using layered architectures for active feedback control. The most salient and universal hardware constraints are tradeoffs between speed, accuracy, and costs (to build, operate, and maintain), and successful architectures cleverly combine diverse components to create systems that are both fast and accurate, despite being built from parts that are not.   Recent progress has made it possible to integrate realistic features and constraints for sensorimotor coordination in a coherent and rigorous way using worst-case L-infinity bounded uncertainty models from robust control, but much remains to explore to realize its potential in neuroscience and neuro-inspired engineering. Another application of this framework will be to software defined networking, which explicitly separates data forwarding and data control, and provides an interface through which network applications (such as traffic engineering, congestion control and caching) can programmatically control the network.  This makes it a potential ""killer app"" for a theory of integrated planning/reflex layering; research collaborators will be eager to deploy new protocols on testbeds and at scale."
"1903951","CAREER: Scaling-up Resistive Synaptic Arrays for Neuro-inspired Computing","CCF","Software & Hardware Foundation, IntgStrat Undst Neurl&Cogn Sys","07/01/2018","03/18/2020","Shimeng Yu","GA","Georgia Tech Research Corporation","Continuing Grant","Sankar Basu","01/31/2022","$373,825.00","","shimeng.yu@ece.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7798, 8624","1045, 7945, 8089, 8091, 8551","$0.00","Neuro-inspired deep learning algorithms have demonstrated their power in executing intelligent tasks such as image and speech recognition. However, training of such deep neural networks requires huge amount of computational resources that are not affordable for mobile applications. Hardware acceleration of deep learning, with orders of magnitude improvement in speed and energy efficiency, remains a grand challenge for the conventional hardware based on silicon CMOS technology and von-Neumann architecture. As the learning algorithms extensively involve matrix operations, neuro-inspired architectures that leverage the distributed computing in the neuron nodes and localized storage in the synaptic networks are very attractive. The ultimate goal of this project is to advance the neuro-inspired computing with emerging nano-device technologies towards a self-learning chip. A chip that learns in real-time and consumes low-power can be placed at frontend sensors, bringing broad benefits for a number of current applications. The PI will establish close collaboration with industry through student internships and technology transfer. The plan for integration of research and education will train students with interdisciplinary skills. The cross-layer nature of this project ranging from semiconductor device, circuit design, electronic design automation, and machine learning is expected to provide an ideal platform for this educational goal.<br/><br/>The technical goal of this project is to overcome the challenges that prevent scaling up of the crossbar array size for neuro-inspired architecture. Resistive devices with continuous multilevel states have been proposed to function as synaptic weights in the crossbar architecture. However, with the increase of the array size, issues associated with device yield, device variability, and array parasitics will arise and may degrade the system performance. The PI plans to tackle these challenges by exploiting hierarchical research efforts from devices, circuits and architectures. The outcome of the research includes device compact model, circuit-level benchmark simulator for estimating the area/latency/power of the crossbar array macro, and architectural tool for efficiently mapping the learning algorithms into the crossbar architecture.  The PI has established a custom fabrication channel for tape-out of resistive devices on top of CMOS peripheral circuits via his collaboration with academic partners. The prototype chip with measured data is expected to make a strong impact on this field, which previously relied on the simulations for predicting large-scale array performance."
"1631704","NCS-FO: Collaborative Research: Rebuilding Neural Pathway Function Using Miniature Integrated Optics for Neuron-Level Readout and Feedback","CBET","IntgStrat Undst Neurl&Cogn Sys","08/01/2016","08/09/2016","Juliet Gopinath","CO","University of Colorado at Boulder","Standard Grant","Christina Payne","07/31/2021","$200,000.00","Victor Bright","juliet.gopinath@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","ENG","8624","8089, 8091, 8551","$0.00","1631912/1631704<br/>Gibson/Gopinath<br/><br/>Development of a miniature implantable device to allow transfer of neural information from one brain area to another will have a major impact on the understanding of brain function and will be applicable to treatment of brain disease. The proposed research spans neuroscience, materials science, physics and engineering, and will&#8232;provide excellent interdisciplinary research opportunities for students. Dissemination of&#8232;the work will occur through teaching, additional educational outreach, opportunities for undergraduates, and journals and conference publications. The capability of this research to develop an optical feedback control to repair brain function will captivate these future scientists. <br/><br/>Non-invasive feedback control to repair brain function is one of the ultimate goals in neuroscience. The recent and evolving development of genetically encoded fluorescent indicators and optogenetics makes optical readout and control a real possibility.  However, there is still a critical need to understand how an optical feedback system can fully recover function in an awake behaving animal. This proposal seeks to demonstrate for the first time the actual recovery of function in an awake behaving animal using an engineered optical feedback system.  The project will be performed by a highly interdisciplinary team with extensive expertise in neuroscience, optogenetics, and cognitive research in awake behaving animals along with experts in optical and MEMS devices.  The proposal combines the technology development side with behavioral research with the potential for major discoveries. Unprecedented progress in the study of brain function will be enabled with the proposed device. The PIs have recently developed technology for a lightweight head-mounted miniature multiphoton microscope that can image over hundreds of neurons in three dimensions in brain tissue.  The technology is the first to use electrowetting optics for non-mechanical steering of the excitation laser and enables single cell resolution imaging.  We propose to combine a spatially shaped second laser at a different wavelength from our excitation laser to allow both imaging and directed optogenetic stimulation of neurons.  Importantly, modulation of neural activity on the level of individual neurons is essential for controlling function in the brain.  Therefore readout and control by optics has a real potential to restore function as opposed other methods such as ultrasound, EEG, and fMRI that are theoretically limited in spatial resolution.  We propose to readout and control firing of individual neurons in the piriform cortex using a real-time feedback control system. We will use behavior studies in mice to determine if association of olfactory identity with reward can be recovered as we selectively turn on and off the input nerve connections to the piriform cortex where odor identity is thought to be represented. The study will allow us to identify which neurons contain information essential for decision making. The oscillatory basis for information transfer can be tested using certain frequency ranges or phases of neural activity. These studies will be useful for testing models of neural circuit function and applicable for neuroengineering devices for therapeutic use."
"2011369","CRCNS Research Proposal: Exploring the Mechanism of 3-Hinge Gyral Formation and its Role in Brain Networks","IIS","CRCNS-Computation Neuroscience, IntgStrat Undst Neurl&Cogn Sys","10/01/2020","10/19/2020","Xianqiao Wang","GA","University of Georgia Research Foundation Inc","Continuing Grant","Kenneth Whang","09/30/2023","$364,957.00","Tianming Liu","xqwang@uga.edu","310 East Campus Rd","ATHENS","GA","306021589","7065425939","CSE","7327, 8624","7327, 8089, 8091","$0.00","A 3-hinge gyrus, a conjunction of cortical folds coming from three directions, is a promising metric to characterize brain folding patterns and has potential to transform the study of the brain structure-function relationship. However, there are several significant gaps in understanding its significance, for example, why a growing brain preferentially develops 3-hinge gyral patterns as opposed to many other possible folding patterns; what fundamental mechanisms contribute to this complex process; and whether 3-hinge gyri can serve as hubs in brain networks and show cross-subject similarity. The goal of this project is to explore the fundamental mechanism of 3-hinge gyral formations and their role in brain networks. The study will help reveal fundamental principles of brain architecture and produce a unified theoretical framework relating between cortical folding, axonal wiring, and 3-hinge gyral formation. <br/><br/>The long-term goal of this project is to offer a novel model to describe the relationships among brain morphology, connectivity, and function. The investigators will employ an integrated computational modeling and data-mining methodology to understand 3-hinge gyral pattern formation and its structure-function relationship in the cerebral cortex. The specific objectives are as follows: (1) Develop a computational mechanical model to explain 3-hinge gyral formation and the specific roles of geometrical parameters and axonal fibers. (2) Conduct neuroimaging studies to examine the potential role of cortical 3-hinge gyri as hubs in brain networks. (3) Perform imaging data analysis to test whether cortical 3-hinge gyri link the cross-subject similarity of cortical folding patterns to the correspondences of structural brain wiring diagrams and brain functions. By exploring the complementary information provided by cortical folding and 3-hinge gyral patterns, this project will offer a unique perspective to treat brain anatomy and connectivity collectively and better understand their relationships.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1912266","Collaborative Proposal: CRCNS US-German Data Sharing Proposal: DataLad - a decentralized system for integrated discovery, management, and publication of digital objects of science","IIS","Cognitive Neuroscience, CRCNS-Computation Neuroscience, IntgStrat Undst Neurl&Cogn Sys","12/01/2019","03/17/2021","Yaroslav Halchenko","NH","Dartmouth College","Continuing Grant","Jonathan Fritz","11/30/2022","$649,643.00","","Yaroslav.O.Halchenko@Dartmouth.edu","OFFICE OF SPONSORED PROJECTS","HANOVER","NH","037551421","6036463007","CSE","1699, 7327, 8624","1699, 7327, 8089, 8091, 9150","$0.00","Scientists collect terabytes of critical data every year. Recently a strong open science movement has generated traction for the beneficial practice of sharing data across laboratories, universities and research institutions. Yet, sharing data is not enough. Data must be shared using standardized formats and accompanied by curated metadata to allow for tracking, search, and organization. Metadata are essential for scientific discovery, as they are routinely used to complete all data analyses. However, to date, most brain projects focus on collecting or analyzing data, not on metadata management. Typical metadata records consist of heterogeneous study descriptions, developed at study release stage, without consistency across records or standard mechanisms to track changes. <br/>This project will increase access to brain data and improve metadata handling by combining two NSF-funded projects. It will develop a first-of-its-kind metadata management system able to track data and metadata distributed across heterogeneous geographical locations, storage systems and data formats. This portion of the project will expand the functionality of a previously funded NSF project DataLad. DataLad will also be enhanced to interoperate with major data repositories such as OSF and Figshare. Furthermore, the project will use the NSF-funded cloud computing platform brainlife.io to create a data and metadata marketplace by gathering data from multiple currently separated repositories into a single ecosystem . The goal is to improve interoperability across open science projects and make data and metadata easily searchable and available for computing on national cyberinfrastructure systems, ultimately advancing scientific discovery by increasing data discoverability, utilization, and publication. <br/><br/>This project will generate various technological advances. The core target will be an extensible system capable of automated gathering of metadata from various domains. It will be comprised of two major components: 1) a set of metadata parser algorithms that extract metadata from datasets and individual files using a flexible JSON-LD based data structure (with the ability to encode controlled vocabularies where available) and 2) an aggregation procedure that merges the aggregated metadata across parsers and stores them into compressed files that are optimized for bandwidth-efficient exchange and can be queried directly, or used as input into SQL or graph databases for data discovery applications. Extracted metadata will be included within the same datasets under Git and git-annex version control for unambiguous referencing and versatile data logistics. In parallel development we will improve interoperability of DataLad with existing data publishing portals (such as Figshare and OSF) by taking advantage of extracted metadata (e.g., Author, Description) to prefill required fields, and also by bundling the entire Git object store within the publication to make such published datasets installable back by DataLad without any loss of information. To make such published datasets discoverable, we will establish a crowd-sourced registry (with a RESTful API) which will get announcements on the availability of new datasets upon publication and aggregate their metadata to enable querying across datasets and data hosting providers. The final development will be the integration of DataLad within the brainlife.io data marketplace. This will make it possible to search and install datasets on brainlife.io as well as to process the data utilizing the brainlife.io analyses Apps on various NSF-funded national cyberinfrastructure high-throughput computer systems.<br/><br/>A companion project is being funded by the Federal Ministry of Education and Research, Germany (BMBF).<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1748954","Project MAPS: Mapping Non-Response to Math Interventions","DRL","ECR-EHR Core Research","12/01/2017","03/17/2021","Benjamin Clarke","OR","University of Oregon Eugene","Continuing Grant","Robert Ochsendorf","11/30/2021","$2,499,491.00","Keith Smolkowski, Hank Fien, Lina Shanley, Fred Sabb","clarkeb@uoregon.edu","5219 UNIVERSITY OF OREGON","Eugene","OR","974035219","5413465131","EHR","7980","1545, 8089, 8091","$0.00","Students who perform poorly in mathematics early in school are at risk for continuing to struggle in mathematics throughout elementary school and beyond. Recent empirical studies of targeted interventions for students at-risk in mathematics indicate overall effectiveness at positively impacting student outcomes. However, a subset of students fail to exhibit a positive response to generally efficacious intervention programs. To date limited research has investigated the behavioral, cognitive, and neural mechanisms underlying non-response to such mathematics interventions. <br/><br/>The goal of this project is to identify patterns of performance on critical mathematics constructs, their underlying neural signatures, and achievement outcomes for on-track learners, at-risk controls, responders, and non-responders within the context of a randomized control trial of a research-validated first grade math intervention. The work will extend beyond examining specific regions of the brain in isolation to an approach that examines functional connectivity across regions. The project will investigate changes in functional connectivity in concert with behavioral measures to facilitate an in depth exploration of critical early math processes and the behavioral and neural indicators thereof. Findings from the work will be utilized to generate hypotheses on critical math constructs as potential targets for supplemental intervention components to improve intervention outcomes for non-responders. Coupling neuroimaging and school-based intervention research in an early mathematics context represents a unique contribution to the field of mathematics development and the broad array of constructs examined may offer insights into the interaction of mathematics development with other neurological disorders including dyslexia. <br/><br/>This project is supported by NSF's EHR Core Research (ECR) program. The ECR program emphasizes fundamental STEM education research that generates foundational knowledge in the field. Investments are made in critical areas that are essential, broad and enduring: STEM learning and STEM learning environments, broadening participation in STEM, and STEM workforce development. The program supports the accumulation of robust evidence to inform efforts to understand, build theory to explain, and suggest intervention and innovations to address persistent challenges in STEM interest, education, learning and participation."
"2024581","NCS-FO: Neural Correlates of Social States in Macaques","IIS","ECR-EHR Core Research, IntgStrat Undst Neurl&Cogn Sys","09/01/2020","10/13/2020","Hyun Soo Park","MN","University of Minnesota-Twin Cities","Standard Grant","Ellen Carpenter","08/31/2023","$998,608.00","Ben Hayden, Jan Zimmermann","hspark@umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","7980, 8624","8089, 8091, 8551","$0.00","Many biological organisms interact with one another by transmitting and perceiving social signals.  These include gaze, facial expression, and body pose that convey information about the individual?s internal state, including their focus of attention, intended actions, and emotional level.  Despite the ubiquity and potential value of these social interactions, understanding how neural activity gives rise to social interactions is still a largely uncharted area.  Past experiments were conducted either by subjective behavioral observations in natural social settings or by quantifiable methods such as neuroimaging in restricted social settings.  This project will address these limitations by leveraging the project team's recently developed high resolution motion capture system, which can measure, detect, and quantify natural social behaviors and their corresponding neural activity.  This research will open new opportunities to study early behavioral markers, such as those for at-risk children with autism spectrum disorder, schizophrenia, and obsessive-compulsive disorder.<br/><br/>The project team's main innovation is a new statistical model called social states, designed to encode the social context of joint behaviors. These social states will be associated with neurophysiological activities in two brain regions, the dorsolateral prefrontal cortex (dLPFC) and dorsal anterior cingulate cortex (dACC), both located in the prefrontal cortex.  Using the neural correlates of social states, the project will develop a novel method to model the dynamics of social state transitions, facilitating an understanding of how these two brain regions are responsible for processing social signals.  While the project will focus on specific brain regions, the planned research will provide a general computational foundation for understanding the complex social behaviors of macaques.  The planned research will advance the computational understanding of cognitive and neural processes by learning from millions of neurobehavioral data points in real, unrestricted environments.  Developing such a computational model is a complex, real world problem, requiring a new holistic, transformative, and integrative approach.  The planned solution is built upon domain knowledge from multiple disciplines, including machine learning, primate physiology, neuroscience, and computer vision.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1840818","NeuroDataRR. Collaborative Research: Testing the relationship between musical training and enhanced neural coding and perception in noise","BCS","Perception, Action & Cognition, IntgStrat Undst Neurl&Cogn Sys","09/15/2018","07/06/2019","Andrew Oxenham","MN","University of Minnesota-Twin Cities","Standard Grant","Betty Tuller","08/31/2021","$106,769.00","","oxenham@umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","SBE","7252, 8624","040Z, 7252, 7298, 8089, 8091, 9251","$0.00","This project will determine whether formal musical training is associated with enhanced neural processing and perception of sounds, including speech in noisy backgrounds. Music forms an important part of the lives of millions of people around the world, and it is one of the few universals shared by all known human cultures. Yet its utility and potential evolutionary advantages remain a mystery. This project will test the hypothesis that early musical exposure has benefits that extend beyond music to critical aspects of human communication, such as speech perception in noise. In addition, the investigators will test whether early musical training is associated with less severe effects of aging on the ability to understand speech in noisy backgrounds. Degraded ability to understand speech in noise is a common complaint among older listeners and hearing loss has been shown to be associated with social isolation and more rapid cognitive and health declines. If formal musical training is shown to affect improved perception and speech communication in later life, the outcomes could have a potentially major impact on quality of life,<br/><br/>Earlier studies have suggested relationships between early musical training and improved auditory neural processing and perception, but the studies' impact has been limited by small sample numbers and inconsistent methods between different studies. This project will test a large number of participants (N=360) with uniform recruitment criteria and testing protocols across six different sites. Measures will include the neural frequency following response (FFR) to speech sounds, behavioral frequency selectivity, speech perception in noise, speech perception against a background of competing talkers, pitch discrimination, and auditory masking. The participants will also complete other assessments, including a personality inventory questionnaire, a profile of musical perception skills, a spatial reasoning test to assess general cognitive ability, as well as a background questionnaire to determine socio-economic status, education, and musical background. Participants will be selected to span a wide range of ages and musical experience. The neural data and the speech perception measures will be related to factors of musical training, such as the number of years of musical training and the age at which musical training began. Scientific rigor will be assured by preregistering the study and the analyses and by making the data and analysis code publicly available via a dedicated website.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1816363","CHS: Small: Optimizing Human-Machine Performance via Neurofeedback and Adaptive Autonomy","IIS","HCC-Human-Centered Computing","09/01/2018","08/14/2018","Paul Sajda","NY","Columbia University","Standard Grant","Ephraim Glinert","08/31/2022","$498,785.00","","ps629@columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","CSE","7367","7367, 7923, 8089, 8091","$0.00","Our society is being fundamentally transformed by increased interaction between humans and autonomous artificial intelligence (AI) systems. However, the addition of autonomy to our lives will not be successful unless we understand how smart machines and humans should best interact and communicate. Human-machine communication today is almost entirely linguistic, using spoken language for systems such as Siri or Alexa, or typed text for chatbots.  However, humans communicate extremely efficiently with each other byu sing much more than just words; for example by being sensitive to facial expression, gestures, gait, and intonation. In fact, great teams, whether sports teams or military combat teams, are excellent at predicting teammates behavior and state of mind. In this project, the investigators consider both basic science and technology questions with respect to how to communicate that cognitive and physiological state of a human that is co-operating with an autonomous AI. The project has very broad implications since it addresses fundamental questions related to the interactions between humans and smart machines.<br/><br/>The project investigates the  hypothesis that adaptive autonomy together with coordinated neurofeedback can be employed in the same system to optimize human-machine performance. Investigators will develop a framework and investigate the hypothesis within the context of boundary avoidance tasks, or BAT, which  is a class of tasks in which  task critical boundaries surround the optimal operating point of the control system. These tasks are particularly interesting when considering human control because they typically result in a positive feedback loop that systematically increases the arousal state of the human subject, resulting in increasingly poor task performance and ultimate task failure, consistent with the Yerkes-Dodson law. Our framework uses a brain-computer interface (BCI) to both engage autonomy as well as being a source for neurofeedback that can shift human subjects to their performance 'sweet-spot'. This project will advance the science and technology development of how human-machine systems can be optimally integrated, specifically when both 1) the machine has access to ongoing changes in human cognitive and physiological state during performance of the task and 2) the human is made aware of their own state via appropriate neurofeedback.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1912320","CRCNS Research Proposal: Collaborative Research: Mechanisms and dynamics of retronasal olfactory coding","IIS","OFFICE OF MULTIDISCIPLINARY AC, MSPA-INTERDISCIPLINARY","10/01/2019","09/05/2019","Andrea Barreiro","TX","Southern Methodist University","Standard Grant","Edda Thiels","09/30/2022","$206,857.00","","abarreiro@smu.edu","6425 BOAZ","Dallas","TX","752750302","2147684708","CSE","1253, 7454","1228, 7327, 8089, 8091, 9150, 9178, 9179","$0.00","How do our brain, nose, and mouth work together to generate the flavor of food and drink?  When flavor perception goes wrong, can this play a role in diseases like obesity?  The sense of smell is very important for perceiving flavor, largely because of odors that originate in the mouth and are exhaled through the nose via the back of the throat ? a process called retronasal olfaction.  In this study, researchers from the University of Arkansas, the Virginia Commonwealth University, and Southeastern Methodist University are teamed up to gain better understanding of how retronasal olfaction works using rats as an animal model.  The researchers combine direct measurements of the brain in action together with computer simulations of air flow through the nose and neural networks. They are testing the idea that different forces in the nose caused by reversing airflow through the nasal cavity are responsible for how the brain distinguishes exhaled retronasal odors from inhaled odors. In addition, the researchers offer training opportunities at each of the three institutions and are developing an educational video game aimed at introducing users to basic concepts of neurobiology and cognitive neuroscience. <br/><br/>Smells that enter the nose retronasally, i.e., from the back of the nasal cavity, play an essential role in flavor perception, yet many questions about the neuroscience of retronasal olfaction remain unanswered.  How does simply reversing the direction of air flow through the nasal cavity result in different neural input to the olfactory bulb (OB)?  How are retronasal and orthonasal (inhaled) olfactory signals encoded at the level of spiking neurons in the OB?  How do interactions within OB circuits facilitate selective response to retronasal versus orthonasal stimuli?  In this study, researchers from the University of Arkansas, the Virginia Commonwealth University, and Southeastern Methodist University are teamed up to answer these questions, guided by a two-part hypothesis. First, they hypothesize that, at the sensory periphery, retro- and orthonasal stimuli produce distinct spatiotemporal patterns of mechanosensory excitation of olfactory receptor neurons.  Second, they hypothesize that, in the OB, cell-type-specific inhibitory circuit interactions are crucial for dynamic changes in retronasal coding.  To test these hypotheses, the research team is combining high-density multi-electrode recordings in rat OB with fluid dynamics computer simulations based on the three-dimensional shape of the nasal cavity of the same animals. Moreover, the team is performing state-of-the-art realistic computational modeling to identify OB circuit-level principles of retronasal coding.  This work is expected to generate new understanding of the neural basis of retronasal olfaction that includes both peripheral mechanisms in the nose and central mechanisms at the level of M/T cells in the OB. This project is jointly funded by the cross-directorate Collaborative Research in Computational Neuroscience program, the Established Program to Stimulate Competitive Research(EPSCoR), and the MPS Office of Multidisciplinary Activities.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1835181","NCS-FO: Distributed neural organization of sensorimotor dynamics","BCS","IntgStrat Undst Neurl&Cogn Sys","09/01/2018","08/28/2018","Daniel Margoliash","IL","University of Chicago","Standard Grant","Jonathan Fritz","08/31/2021","$1,000,000.00","Howard Nusbaum","dan@bigbird.uchicago.edu","6054 South Drexel Avenue","Chicago","IL","606372612","7737028669","SBE","8624","8089, 8091, 8551","$0.00","Speaking is one of the most complicated human behaviors and yet speech is produced easily and with little conscious effort.  Understanding the way the brain controls the various organs and muscles of vocalization is a basic scientific question that may illuminate more general principles that can describe how the brain programs and controls all behavior.  In order to understand the neural mechanisms of motor behavior in vocal production, the proposed research will test specific hypotheses about the timing of different brain regions, the timing of muscles that produce vocal behavior, and the response to normal and abnormal auditory feedback.  Understanding the neural mechanisms of motor control can have broad implications, including the development of more human-like robots, better computer-generated speech and vocal prostheses, as well as new therapies for treating articulatory disorders such as stuttering, dysarthria, aphasia, and other problems in speech production.<br/><br/>The proposed research will measure the timing of neural circuits that control vocalization in humans and song birds.  The bird song production system has long been used as a model system that has relevance to understanding speech production. While simpler than humans and with less behavioral control of the experiments, studying birdsong is complementary in providing more granular measurements of neural activity in a vocal learning system than possible in humans. The experiments will test a novel hypothesis, that the motor system is not organized by the commonly assumed ""top down"" organizational scheme, but by a coherent network that operates as a unitary mechanism as described by certain mathematics of non-linear systems. The comparison between species will also be informative about how robust the results are across very different species and neural systems offering the possibility of generalization of the results.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1631864","Collaborative Research: NCS-FO: A Computational Neuroscience Framework for Olfactory Scene Analysis within Complex Fluid Environments","IIS","IntgStrat Undst Neurl&Cogn Sys","09/01/2016","08/17/2016","Matthew Reidenbach","VA","University of Virginia Main Campus","Standard Grant","Mitra Basu","08/31/2021","$249,237.00","","reidenbach@virginia.edu","P.O.  BOX 400195","CHARLOTTESVILLE","VA","229044195","4349244270","CSE","8624","8089, 8091, 8551","$0.00","Most animals survive in turbulent air or water environments and are living proof that it is possible to quantify odor signals in complex turbulent flow conditions to track and find sources of odors (such as food, mates, etc.). However, our engineering knowledge is still incapable of formulating simple and effective measurements that will enable man-made systems to predict, navigate and utilize properties of this turbulent flow to locate sources of chemical release. This project builds on recent exciting computational modeling of the neurobiology of organisms by the proposers, which predict that lobsters are capable of estimating not only the concentration of odors but also the time since the last odor was encountered. Lobsters accomplish this by using ensemble competition across a population of olfactory receptor neurons (ORNs), called ""bursting ORNs"". Bursting ORNs function to compute the time since last encounter of an odor that, along with concentration, can provide a measure of the distance to the odor source. This research will seek to increase understanding of how ORNs perceive odor concentration and intermittency measured within an odor plume, and how this information is integrated within the lobster's brain. An additional major objective is to develop new neurobiology-based theories in the search for odor sources that can be implemented within human-engineered autonomous underwater vehicles that have the ability to navigate in turbulent chemical plumes. This work will enhance defense and civilian applications of a new generation of electronic noses for tracking chemicals in natural or man-initiated disasters. Through this project, there are also excellent resources and outreach opportunities for integrated education and training of students at the intersection of fluid dynamics, neuroscience, computer engineering and information processing. Outreach will be coordinated through the Center of Innovative Brain Machine Interfaces at the University of Florida and will provide opportunities for undergraduate and graduate research, promote neurotechnology innovations, and foster entrepreneurship activities in order to create potential future start-up companies.<br/><br/>This research brings together a multidisciplinary and complementary team of experts, including a fluid dynamicist, a neurobiologist, and an electrical engineer with the very clear goal of understanding and exploiting olfactory scene analysis in turbulent flow. The research will include laboratory experiments of chemical plume mixing and ORN responses to odor encounters by lobsters, theoretical analysis of search optimization, as well as numerical simulations and novel system architecture for electronic noses with the goal of equipping autonomous underwater vehicles with the ability to navigate in turbulent chemical plumes. This will increase our understanding of how bursting olfactory neuron responses are exploited by the olfactory lobe, the first olfactory relay, and how this information is integrated with the odor specific information in the olfactory bulb. Moreover, this work will enhance our understanding of turbulent plume dynamics in order to develop a new neurobiology-based theory in the search for odor sources. Using information obtained from a large-scale plume, the researchers will use the olfactory organs of the lobster as a model system to understand the physical constraints placed on these chemosensors and examine the role of spatial and temporal relationships of odor inputs in the excitation of olfactory receptor neurons. The work will provide a conceptual substrate for olfactory scene analysis informed by neurobiology, which is still in its infancy compared with vision and audition."
"2011595","US-German Research Proposal: ADaptive low-latency SPEEch Decoding and synthesis using intracranial signals (ADSPEED)","IIS","IntgStrat Undst Neurl&Cogn Sys","01/01/2021","10/19/2020","Dean Krusienski","VA","Virginia Commonwealth University","Continuing Grant","Kenneth Whang","12/31/2023","$205,786.00","Jerry Shih","djkrusienski@vcu.edu","P.O. Box 980568","RICHMOND","VA","232980568","8048286772","CSE","8624","7327, 8089, 8091","$0.00","Recent research has demonstrated that it is possible to synthesize intelligible speech sounds directly from invasive measurements of brain activity. However, these approaches have a perceptible delay between brain activity and audible speech output, preventing a natural spoken communication. Furthermore, the approaches generally require pre-recorded speech and thus cannot be directly applied to people who are unable to speak and generate such recordings. This project aims to develop methods for synthesizing speech from brain activity without perceptible processing delay that do not rely on pre-recorded speech from the user. The ultimate goal is to develop a system that restores natural spoken communication to the millions of people who suffer from severe speech disorders, including those with complete loss of speech. <br/><br/>The project is organized into three research thrusts. The first thrust focuses on asynchronous and acoustics-free model training, where novel surrogates to the user's vocalized speech will be created using approaches based on dynamic time warping and the inference of intended inner-speech acoustics from corresponding textual representations. The second thrust focuses on online validation and user adaptation, where the existing low-latency speech decoding and synthesis scheme, which is not inherently adaptable, will be validated in a closed-loop fashion using online human-subject experiments. This will provide valuable insights into how the user responds and adapts to the artificial, synthesized speech output. The third thrust focuses on the development and testing of low-latency system-user co-adaptation schemes. Co-adaptation, where both the user and system adapt to optimize the synthesized output, is crucial for revealing the elusive representations of inner (i.e., imagined or attempted) speech in the absence of a reliable surrogate for modeling. As a result, this research will simultaneously advance the understanding of the neural representations of inner speech and, in turn, co-adaptive inner speech decoding toward the development of practical closed-loop speech neuroprosthetics.<br/><br/>A companion project is being funded by the Federal Ministry of Education and Research, Germany (BMBF).<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2024923","NCS-FO: Neural mechanisms of agency in motor control and sensorimotor learning","BCS","ECR-EHR Core Research, IntgStrat Undst Neurl&Cogn Sys","09/15/2020","10/13/2020","Howard Nusbaum","IL","University of Chicago","Standard Grant","Gregg Solomon","08/31/2023","$994,065.00","Pedro Lopes","hcn@speech.uchicago.edu","6054 South Drexel Avenue","Chicago","IL","606372612","7737028669","SBE","7980, 8624","8089, 8091, 8551","$0.00","Reaching for a pen to write or a tool to hammer a nail are the kinds of intentional actions produced every day. This project will advance our understanding the conscious control of behavior by investigating the neural mechanisms that underlie the sense of agency ? the feeling that one has both intended to and executed a particular movement.  Scientists are now able to stimulate muscles electrically in order to enhance the performance of such routine movements.  For some people, this externally stimulated action is felt to be the result of their own intentional control; for others, the action feels externally produced and not of their own agency.  By measuring the distribution and timing of neural signals in these two situations of stimulated action that is felt to be intentional compared to movements that are felt to be externally controlled, the research will test cognitive and neural theories of consciousness and subjective experience in the initiation and control of behavior. The findings can lead to new ways of thinking about the neuroscience of action.  They can also provide guidance for the improvement of user-system interfaces for robotic control and training methods for the future of work at the human-technology frontier, the development of new prosthetics as well as new rehabilitation therapies for the recovery of motor function following disease or trauma. This project is funded by Integrative Strategies for Understanding Neural and Cognitive Systems (NCS), a multidisciplinary program jointly supported by the Directorates for Computer and Information Science and Engineering (CISE), Education and Human Resources (EHR), Engineering (ENG), and Social, Behavioral, and Economic Sciences (SBE).<br/><br/>The research will enhance typically controlled human motor movements by manipulating them externally through functional electrical stimulation (FES), the use of a robotic exoskeleton, or the induction of illusory motion in order to probe the role of corollary discharge and reafferent signals in determining the time course and strength of the sense of agency.  A set of six experiments will identify the role of agency in motor learning, the conditions under which agency is lost, and the extent to which voluntary movements can be externally modified without losing the sense of agency.  Measurements of the activity and timing in the motor system and in somatosensory cortex using human electroencephalography (EEG) and functional Magnetic Resonance Imaging (fMRI) will be used to model neural responses.  Measurements taken when enhanced movement is felt to be self-initiated will be compared to those taken when the movement is experienced as externally guided. This contrast between a sense of intentional agency in enhanced movement and passive unintentional movement will be related to the patterns of neural activity across different forms of external movement enhancement.  The sense of agency for external stimulation of action has been predictive of improved motor learning and the neural signals related to agency will be used to model motor learning.  These analyses will be used to test specific models of agency and consciousness in intentional action relating efferent motor cues, the striatal reward system, and learning. Understanding the neural mechanisms of conscious control of behavior can lead to new models for neuroengineering and brain-inspired design, provide new information about individual differences and variation in cognitive control of behavior and learning, and yield new understanding of how neural processes operate in realistic and complex environments.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2024486","Collaborative Research: NCS-FO: Intelligent Closed-Loop Neural Interface System for Studying Mechanisms of Somatosensory Feedback in Control of Functional and Stable Locomotion","ECCS","IntgStrat Undst Neurl&Cogn Sys","09/01/2020","07/27/2020","Yaoyao Jia","NC","North Carolina State University","Standard Grant","John Zhang","08/31/2023","$303,634.00","","yjia6@ncsu.edu","2601 Wolf Village Way","Raleigh","NC","276957514","9195152444","ENG","8624","8089, 8091, 8551","$0.00","Sensory feedback from moving legs is critical for functional and dynamically stable locomotion. Although it is clear that motion-related sensory feedback influences inter-leg coordination and selection of gaits (walking, trotting, galloping, etc.), it is not known which sensory modalities (e.g., muscle length- or force-related signals) and sources of feedback (e.g., hip or knee muscles) mediate these locomotor changes. Therefore, this project aims to understand how sensory neurons providing information about the length of hip muscles regulate interlimb coordination and gait selection. This goal will be accomplished by selectively and reversibly stimulating these sensory neurons in an intelligent, closed-loop, and well-controlled manner. This project will lead to the development of new neural implant tools and associated computational algorithms for an in-vivo manipulation of motion-related sensory signals in a large animal model, the cat. The new findings of this project and the developed methods will substantially enhance our understanding of the mechanisms of sensory locomotor control and contribute to developing novel therapeutic interventions. The proposed multidisciplinary research approaches will also significantly expand the utility and capabilities of the rapidly growing field of optogenetics, enabling transformative research and providing unprecedented new experimental tools for neuroscience. The most noticeable long-term benefits of this work to society will be an improvement in the quality of life for a sizable population of people affected by a wide range of movement deficits, from limb loss to sensory neuropathy. These individuals will benefit from the development of neural interfaces between the nervous and engineering systems controlled by machine learning algorithms. Throughout this project, efforts will be made to recruit and train graduate and undergraduate students from underrepresented groups. Outreach activities will also be organized to share resources, tools, and knowledge with teachers, students, and underrepresented groups. The results of the proposed research and educational activities will be shared with students, scientific communities, and the public through science fairs, publications, workshops, conferences, and the Internet.<br/><br/>The overall goal of this proposal is to characterize the mechanisms of somatosensory control of interlimb coordination and gait selection by spindle afferents of hip muscles in the cat model by developing and utilizing in-vivo an intelligent and closed-loop optoelectronic neural interface system. In particular, in this proposal high-density, efficient, and wirelessly-powered implantable opto-electro (WIOE) neural interface devices will be developed. Each WIOE heterogeneously incorporates an optoelectronic array of 64 transparent microelectrodes and 16 microscale light-emitting-diodes (LEDs), a system-on-a-chip (SoC), and a power receiver (Rx) coil in an mm3-size package, capable of optogenetic stimulation and electrical recording of neural activities. Wireless telemetry links will be implemented for efficient transcutaneous power and wideband data transmission between an external data-acquisition/control unit and the distributed array of WIOE implants. Multiple WIOE devices will be implanted in selected dorsal root ganglia (DRG) of the cat. Neural activities of DRG neurons, EMG activities of selected muscles of the four limbs, and full-body locomotor kinematics will be recorded, and spindle afferent activities will be manipulated via optogenetic stimulation in selected DRGs during unconstrained cat locomotion. Machine learning (ML) models leveraging the spatiotemporal structures in the signals and mapping afferent  activities in DRGs to limb kinematics will be applied for achieving closed-loop control of the optogenetic  neuromodulation. The proposed research activities will be conducted by a team of collaborators with complementary research expertise in the areas of bioMEMS, wireless microelectronics, machine learning, artificial intelligence, and behavioral neuroscience. The successful development of the proposed intelligent and closed-loop optoelectronic neural interface will yield a robust building block for a comprehensive set of minimally invasive neural interfaces to study somatosensory control of movement, as well as monitor or treat somatosensory pathological conditions.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2024270","Collaborative Research: NCS-FO: Intelligent Closed-Loop Neural Interface System for Studying Mechanisms of Somatosensory Feedback in Control of Functional and Stable Locomotion","ECCS","IntgStrat Undst Neurl&Cogn Sys","09/01/2020","07/27/2020","Wen Li","MI","Michigan State University","Standard Grant","John Zhang","08/31/2023","$390,000.00","Jiayu Zhou","wenli@egr.msu.edu","Office of Sponsored Programs","East Lansing","MI","488242600","5173555040","ENG","8624","8089, 8091, 8551","$0.00","Sensory feedback from moving legs is critical for functional and dynamically stable locomotion. Although it is clear that motion-related sensory feedback influences inter-leg coordination and selection of gaits (walking, trotting, galloping, etc.), it is not known which sensory modalities (e.g., muscle length- or force-related signals) and sources of feedback (e.g., hip or knee muscles) mediate these locomotor changes. Therefore, this project aims to understand how sensory neurons providing information about the length of hip muscles regulate interlimb coordination and gait selection. This goal will be accomplished by selectively and reversibly stimulating these sensory neurons in an intelligent, closed-loop, and well-controlled manner. This project will lead to the development of new neural implant tools and associated computational algorithms for an in-vivo manipulation of motion-related sensory signals in a large animal model, the cat. The new findings of this project and the developed methods will substantially enhance our understanding of the mechanisms of sensory locomotor control and contribute to developing novel therapeutic interventions. The proposed multidisciplinary research approaches will also significantly expand the utility and capabilities of the rapidly growing field of optogenetics, enabling transformative research and providing unprecedented new experimental tools for neuroscience. The most noticeable long-term benefits of this work to society will be an improvement in the quality of life for a sizable population of people affected by a wide range of movement deficits, from limb loss to sensory neuropathy. These individuals will benefit from the development of neural interfaces between the nervous and engineering systems controlled by machine learning algorithms. Throughout this project, efforts will be made to recruit and train graduate and undergraduate students from underrepresented groups. Outreach activities will also be organized to share resources, tools, and knowledge with teachers, students, and underrepresented groups. The results of the proposed research and educational activities will be shared with students, scientific communities, and the public through science fairs, publications, workshops, conferences, and the Internet.<br/><br/>The overall goal of this proposal is to characterize the mechanisms of somatosensory control of interlimb coordination and gait selection by spindle afferents of hip muscles in the cat model by developing and utilizing in-vivo an intelligent and closed-loop optoelectronic neural interface system. In particular, in this proposal high-density, efficient, and wirelessly-powered implantable opto-electro (WIOE) neural interface devices will be developed. Each WIOE heterogeneously incorporates an optoelectronic array of 64 transparent microelectrodes and 16 microscale light-emitting-diodes (LEDs), a system-on-a-chip (SoC), and a power receiver (Rx) coil in an mm3-size package, capable of optogenetic stimulation and electrical recording of neural activities. Wireless telemetry links will be implemented for efficient transcutaneous power and wideband data transmission between an external data-acquisition/control unit and the distributed array of WIOE implants. Multiple WIOE devices will be implanted in selected dorsal root ganglia (DRG) of the cat. Neural activities of DRG neurons, EMG activities of selected muscles of the four limbs, and full-body locomotor kinematics will be recorded, and spindle afferent activities will be manipulated via optogenetic stimulation in selected DRGs during unconstrained cat locomotion. Machine learning (ML) models leveraging the spatiotemporal structures in the signals and mapping afferent  activities in DRGs to limb kinematics will be applied for achieving closed-loop control of the optogenetic  neuromodulation. The proposed research activities will be conducted by a team of collaborators with complementary research expertise in the areas of bioMEMS, wireless microelectronics, machine learning, artificial intelligence, and behavioral neuroscience. The successful development of the proposed intelligent and closed-loop optoelectronic neural interface will yield a robust building block for a comprehensive set of minimally invasive neural interfaces to study somatosensory control of movement, as well as monitor or treat somatosensory pathological conditions.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1926829","NCS-FO: Collaborative Research: Analysis, prediction, and control of synchronized neural activity","IIS","ECR-EHR Core Research, IntgStrat Undst Neurl&Cogn Sys","09/01/2019","08/29/2019","Fabio Pasqualetti","CA","University of California-Riverside","Standard Grant","John Zhang","08/31/2023","$499,540.00","","fabio.pasqualetti@ucr.edu","Research & Economic Development","RIVERSIDE","CA","925210217","9518275535","CSE","7980, 8624","8089, 8091, 8551, 8817","$0.00","Understanding the relations between the anatomical structure of the human brain and its functions in healthy and diseased states can not only lead to the design of novel, targeted, non-invasive, and highly-effective treatments for neurological disorders, but also inform the application of innovative stimulation schemes to enhance cognitive performance and executive capabilities. Leveraging data obtained with state-of-the-art sensing and imaging technologies, this project pursues these objectives by innovatively studying the human brain as a dynamic network system comprising neuronal ensembles and white-matter fibers, and as governed by principles similar to social and technological cyber-physical networks. This project develops and validates new rigorous theories and tools to address an outstanding problem in network neuroscience. Namely, to leverage the brain anatomical structure to characterize, predict, and control patterns of synchronized neural activity, and to validate the methods with realistic brain data. This project will not only contribute to the theories of networks, controls, and neuroscience, but also to their integration, by leveraging different levels of abstraction (brain representations from diffusion imaging data, electrocorticography time series, mathematical models) and distinct disciplinary approaches. In addition to new methods to study synchronized activity in the brain and inform the next generation of diagnostics, this project pursues far-reaching teaching and outreach activities, including (i) a number of university-level initiatives at the graduate and undergraduate levels, (ii) outreach activities that will engage young people from the local communities in Philadelphia and Riverside, and (iii) dissemination activities that will bring together traditionally separated communities and promote multi-disciplinary initiatives to tackle some of the most pressing problems in neuroscience.<br/><br/>The central hypothesis of this project is that the interconnected structure of the brain determines its performance and controls its transitions between healthy and diseased states. Building on this hypothesis, this project addresses the unsolved problems of characterizing, predicting, and controlling patterns of synchronized neural activity in the human brain from sparse and coarse temporal measurements and interventions. Additionally, to support the hypothesis and validate the theories of neural synchronization, the project leverages three unique and extensive multimodal neuroimaging datasets combining high-resolution electrocorticography and diffusion imaging that will allow to assess the relations between synchronization patterns and underlying structural network architecture. Specifically, this project is organized around two main tasks. Task 1, abstracts the problem of controlling patterns of neural activity as the problem of controlling the degree of synchronization among interconnected nonlinear oscillators, where oscillators represent brain regions and their interconnections reflect the anatomy of the human brain as reconstructed by diffusion magnetic resonance imaging. The idea is put forth that altered synchronization patterns are the results of, possibly small, modifications to the oscillators' interconnection structure and weights, and that desirable patterns can be restored by minimal and localized structural interventions. Task 2 uses empirical data to obtain inferences complementing those acquired in the formal theoretical and modeling work in Task 1. Because the focus here is the analysis, prediction, and control of cluster synchronization, the empirical efforts remain constrained to the study of functional neuroimaging data with clear electrographic signatures of synchronization. Specifically, the project uses electrocorticography data, which boasts markedly greater temporal resolution than functional magnetic resonance imaging and does not suffer from the issues of volume conduction that are more common in electroencephalography and magnetoencephalography. The project blends and extends tools from control and network theories, dynamical systems, data analysis, and network neuroscience. While this project focuses on synchronization problems in neural activity, the methods have broad applicability in engineering, for instance to design optimized networks and sparse controllers, network neuroscience, and network science.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1834994","NCS-FO: Collaborative Research: Optoelectronic Tools for Closed-Loop Neuron Ensemble Recording and Control during Complex Behaviors","ECCS","IntgStrat Undst Neurl&Cogn Sys","09/15/2018","08/31/2018","Ethan Meyers","MA","Hampshire College","Standard Grant","John Zhang","08/31/2022","$46,700.00","","emmCS@hampshire.edu","893 West Street","Amherst","MA","010023372","4135595378","ENG","8624","8089, 8091, 8551","$0.00","Brain science will benefit from the capabilities in tracing complex animal behaviors down to ensembles of individual neurons, and moreover establishing a real-time closed-loop brain-interface, ideally with deep brain access in a free-moving animal. This research project aims to address the focus areas in this National Science Foundation program by merging novel neurotechnology, evaluation of neural circuits during performance of complex cognitive behaviors, and large-scale neuron ensemble analysis and closed-loop behavioral control. The outcome of this research will result in new technologies and computational tools that can be used across the field of neuroscience and behavior, strengthening research efforts of multiple research groups. The educational objectives of this proposal are aimed at training and inspiring young engineers and scientists who are equipped with the multidisciplinary background required to help define the future trajectory of brain interfaces and data sciences. The broader impacts of this project include: 1) advancing transformative device technologies for next-generation neurotechnology and providing new and more powerful tools for neuroscience studies, 2) educating underrepresented undergraduate and graduate researchers to contribute to the nation's workforce needs in biotechnology, 3) contributing to the K-12 science, technology, engineering, and mathematics education through weekend seminars and mentoring student-teacher pairs from local middle/high schools; and 4) promoting neuroscience and neurotechnology among local senior citizens and support groups for neurological diseases.  <br/><br/>The research objective of this proposal is to combine high precision optoelectronic neural probes with real-time neural decoding to feedback optogenetic control over animal behavior. Such closed-loop neural interface will establish a generalizable technology platform to study complex animal behaviors using optogenetic tools and real-time learning. The proposed work will open ample research opportunities and form connections among hardware engineering, cognitive neuroscience, and data science. The intellectual merit of the proposed work will be evidenced by three major contributions: 1) demonstration of high-precision optogenetic brain interface that combines multiplexed recording from and bi-directional control over neuron ensembles, 2) demonstration of closed-loop brain interface that employs real-time neural decoding and adaptive learning to control animal behavior, and 3) characterization of complex decision-making using high-precision, multiplexed data linking multiple brain areas.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1533611","NCS-FO: Imaging synaptic activity deep in the brain using super-resolution cannula microscopy","ECCS","CCSS-Comms Circuits & Sens Sys, EFRI Research Projects, IntgStrat Undst Neurl&Cogn Sys","09/01/2015","04/27/2018","Rajesh Menon","UT","University of Utah","Standard Grant","John Zhang","08/31/2021","$933,000.00","Erik Jorgensen, Jason Shepherd","rmenon@eng.utah.edu","75 S 2000 E","SALT LAKE CITY","UT","841128930","8015816903","ENG","7564, 7633, 8624","8089, 8091, 8551, 9251","$0.00","Proposal # 1533611<br/>Institute: University of Utah<br/>Title: NCS-FO: Imaging synaptic activity deep in the brain using super-resolution cannula microscopy<br/><br/>Objective:  This project will develop a tool for high-resolution (<100-nm) imaging of synapses in freely moving animals for neuronal studies. It will accomplish this goal by the development and integration of compact and lightweight cannula microscopy with in vitro fluorescence imaging with accompanying technology and methodologies for imaging synapses.<br/><br/>Non-Technical <br/>The long-term vision of this project is to image with high resolution deep inside the brain of freely moving mice using inexpensive technologies so as to elucidate the fundamental basis of information processing and memory. Changes in synaptic strength at specific synapses are thought to underlie memory encoding and storage, yet there is very little experimental evidence for this theory in the intact brain due to technical limitations of visualizing the specific synaptic pattern involved in experience-dependent learning. This project aims to overcome this limitation by transforming a simple, inexpensive cannula into a super-resolution fluorescence microscope. Commercialization of this technology will be pursued after the fundamental science and engineering has been demonstrated for widespread dissemination. <br/><br/>Technical:<br/>The objective of this proposal is to image neuronal activity, neuron structure and protein localization deep in the brain with sub-100nm resolution using computational cannula microscopy (CM) and novel molecular reporters of synaptic activity. CM will allow imaging of the brain in awake, freely moving animals at unprecedented spatial resolution. Current techniques in freely moving animals are limited to imaging the brain near the surface, include large and heavy head stages with moving parts, and cannot penetrate deep into the brain without significant damage to surrounding tissue. The ultimate goal of this proposal is to allow imaging of individual synapses in freely moving animals. We have already developed the framework for in vitro fluorescence imaging using CM. During this project, we will extend CM to enable: (1) super-resolution (< 100nm resolution) fluorescence microscopy and (2) deep-brain imaging (depth > 1mm) with the vision of imaging activity and protein localization in individual synapses in the deep brain of freely moving animals. Changes in the strength of individual synapses are thought to underlie learning and memory in the brain, yet this fundamental theory of brain function lacks tangible experimental evidence to support it in vivo. Our project will enable studies that address the causal role of molecular events at individual synapses in mediating behavior and information processing."
"1912293","CRCNS US-German Research Proposal: Neural Computations Underlying Mechanical -Flow Sensing in Zebrafish","IIS","Cross-BIO Activities, BMMB-Biomech & Mechanobiology","12/01/2019","09/11/2019","Florian Engert","MA","Harvard University","Standard Grant","Sridhar Raghavachari","11/30/2022","$507,000.00","","florian@mcb.harvard.edu","1033 MASSACHUSETTS AVE","Cambridge","MA","021385369","6174955501","CSE","7275, 7479","028E, 7327, 8089, 8091","$0.00","In recent years, the zebrafish has emerged as an important model organism as researchers have become able to obtain detailed information about the connectivity and activity of its brain.  The laboratory of the Principal Investigator recently presented work that makes use of this wealth of available information to better understand zebrafish behavior at the level of specific neural circuitry. To that end, a realistic network model, composed of experimental verified functional cell types, was developed that accurately models the fish's tendency to swim in a particular direction in response to a moving visual stimulus. The purpose of this collaboration project is to develop a similar theoretical circuit model for mechanosensory-based rheotaxis, a more sophisticated behavior that also is displayed readily by larval zebrafish. The project combines experimental and computational approaches, and constitutes a significant step towards establishing the larval zebrafish as a vertebrate model where whole-brain imaging can be combined with whole-brain circuit modelling in order to generate a unified theoretical basis for the holistic study of neural circuits.  The project also provides undergraduate and graduate students from diverse backgrounds opportunities to receive hands-on laboratory experiences.<br/><br/>As a first step towards the scientific goal of the project, the investigators demonstrated that larval zebrafish can perform efficient rheotaxis in complete darkness and in the absence of any other direct cues from the external reference frame.  Furthermore, the investigators showed that this behavior requires the presence of a flow velocity gradient, and presented behavioral data that support a novel algorithm that fish use to efficiently navigate laminar flow:  detailed behavioral analysis shows that fish use the hair-cells of their lateral line to measure (1) the curl of the local velocity vector field to detect the presence of flow, and (2) the temporal change in curl magnitude following swim bouts to deduce flow direction. As such, a precise and predictive algorithm is presented, whose quantitative description allows to examine its neural implementation, and eventually to generate a realistic and testable circuit model of all brain areas involved in executing this computation. The complementary expertise of the researchers of the two participating laboratories allows testing, verification, and refinement of this model-circuit based on an iterative combination of whole-brain imaging, genetic perturbations and quantitative modeling. A companion project is being funded by the Federal Ministry of Education and Research, Germany (BMBF).<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1902395","US-German Data Sharing Proposal: CRCNS Data Sharing: REvealing SPONtaneous Speech Processes in Electrocorticography (RESPONSE)","IIS","CRCNS-Computation Neuroscience, IntgStrat Undst Neurl&Cogn Sys","09/01/2018","01/30/2019","Dean Krusienski","VA","Virginia Commonwealth University","Standard Grant","Jonathan Fritz","07/31/2021","$388,060.00","","djkrusienski@vcu.edu","P.O. Box 980568","RICHMOND","VA","232980568","8048286772","CSE","7327, 8624","7327, 8089, 8091","$0.00","The uniquely human capability to produce speech enables swift communication of abstract and substantive information. Currently, nearly two million people in the United States, and far more worldwide, suffer from significant speech production deficits as a result of severe neuromuscular impairments due to injury or disease. In extreme cases, individuals may be unable to speak at all. These individuals would greatly benefit from a device that could alleviate speech deficits and enable them to communicate more naturally and effectively. This project will explore aspects of decoding a user's intended speech directly from the electrical activity of the brain and converting it to synthesized speech that could be played through a loudspeaker in real-time to emulate natural speaking from thought. In particular, this project will uniquely focus on decoding continuous, spontaneous speech processes to achieve more natural and practical communication device for the severely disabled.<br/><br/>The complex dynamics of brain activity and the fundamental processing units of continuous speech production and perception are largely unknown, and such dynamics make it challenging to investigate these speech processes with traditional neuroimaging techniques. Electrocorticography (ECoG) measures electrical activity directly from the brain surface and covers an area large enough to provide insights about widespread networks for speech production and understanding, while simultaneously providing localized information for decoding nuanced aspects of the underlying speech processes. Thus, ECoG is instrumental and unparalleled for investigating the detailed spatiotemporal dynamics of speech. The research team's prior work has shown for the first time the detailed spatiotemporal progression of brain activity during prompted continuous speech, and that the team's Brain-to-text system can model phonemes and decode words. However, in pursuit of the ultimate objective of developing a natural speech neuroprosthetic for the severely disabled, research must move beyond studying prompted and isolated aspects of speech. This project will extend the research team's prior experiments to investigate the neural processes of spontaneous and imagined speech production. In conjunction with in-depth analysis of the recorded neural signals, the researchers will apply customized ECoG-based automatic speech recognition (ASR) techniques to facilitate the analysis of the large amount of phones occurring in continuous speech. Ultimately, the project aims to define fundamental units of continuous speech production and understanding, illustrate functional differences between these units, and demonstrate that representations of spontaneous speech can be synthesized directly from the neural recordings. A companion project is being funded by the Federal Ministry of Education and Research, Germany (BMBF)"
"1450936","BRAIN EAGER: New Tools for Real-Time Imaging of Molecular-Resolution Connectomics of Synapses","CBET","BioP-Biophotonics, EFRI Research Projects","09/01/2014","01/26/2021","Xiaohong Nancy Xu","VA","Old Dominion University Research Foundation","Standard Grant","Leon Esterowitz","08/31/2021","$359,307.00","","xhxu@odu.edu","4111 Monarch Way","Norfolk","VA","235082561","7576834293","ENG","7236, 7633","005E, 7916, 7974, 8089, 8091, 9251","$0.00","PI: Xu, X. Nancy<br/>Proposal: 1450936<br/>Title: BRAIN EAGER: New Tools for Real-Time Imaging of Molecular-Resolution Connectomics of Synapses<br/><br/>Significance<br/>The successful outcome of this EAGER project will have a broad impact in neuroscience. The proposed project will offer new insights into the roles and functions of neurotransmitters in synaptic plasticity and regeneration. This will lead to the development of innovative tools for molecular identification and characterization of roles and functions of multiple types of neurotransmitters, their receptors, and their interactions and dynamics in synapses at the spatial and temporal resolution level.  These powerful new tools are expected to become extremely valuable in addressing a wide range of pressing biological, biochemical and biomedical questions related to molecular and real-time characterization of functions of single live cells (neurons). <br/><br/>Technical Description<br/>The brain comprises large number of neurons, which are not continuous. Synapses enable them to communicate complex and specific commands with each other by passing specific electrical or chemical signals to another cell. Each synapse contains extensive arrays of molecular machinery that links the membranes of the coupled partner neurons, an array of neurotransmitters and their receptors. The aims of this project is to develop a novel imaging platform, including next-generation multicolored far-field photostable optical nanoscopy (PHOTON) with photostable multicolored single molecule nanoparticle optical biosensors (SMNOBS).  This platform will quantitatively image and molecularly characterize roles and functions of multiple types of molecules (neurotransmitters, receptors) at individual live synapses in real time at nanometer (nm) resolution. These capabilities will enable the identification of the roles and functions of single neurotransmitter-receptor interactions, identify and characterize their roles in modulating and regulating functions of single synapses and neurons in real time. They will use the multicolored PHOTON: (i) to quantitatively and simultaneously detect and map diffusion and molecular dynamics of multiple types of neurotransmitters, their receptors and their interactions on each synapse with both spatial and temporal resolutions; (ii) to construct the connection of individual neurons at individual synapses at the molecular resolution; (iii) to explore the possibility of creating connectomics to determine the functions and related molecular pathways of synapses and their roles in neuron and brain functions at the molecular resolution  level."
"2016241","International Mind, Brain and Education Society (IMBES): 2020 Biennial Conference","DRL","Discovery Research K-12","03/15/2020","03/02/2020","Nora Newcombe","PA","Temple University","Standard Grant","Robert Ochsendorf","12/31/2021","$64,524.00","","newcombe@temple.edu","1801 N. Broad Street","Philadelphia","PA","191226003","2157077547","EHR","7645","7556, 8089, 8091, 8817","$0.00","The International Mind, Brain, and Education Society (IMBES) conference has taken place every 2-3 years since 2007. IMBES aims to facilitate cross-cultural collaboration in biology, education, and the cognitive and developmental sciences. The IMBES meeting is an opportunity for scholars and educators to come together to engage in reciprocal dialogue about research and practice.  Researchers investigating learning processes have the opportunity to share results with educators and receive feedback on the translational opportunities for the research.  Educators can update their understanding of the cognitive and neural bases of learning and impart their knowledge of efficacious techniques, tools, and classroom practices with researchers. This type of interaction between researchers and practitioners is crucial for generating research that contributes to usable knowledge for education. This conference aims to assess the degree to which scientific ideas are ready for the classroom, consider the extent to which further educational research is still required, evaluate the potential of current research in meaningfully shaping pedagogy, and recognize opportunities to use the classroom to challenge the robustness of research.<br/><br/>This award to Temple University will provide partial support for the International, Mind, Brain, and Education Society (IMBES) conference to be held in Montreal in June 2020. This award will specifically support teacher practitioners from the U.S. to attend the conference and learn more about educational neuroscience and its potential implications for practice. The teacher practitioners will also have opportunities to share with researchers the nature of effective educational practice.  The project is supported by the Discovery Research preK-12 program, which supports research and development efforts to improve STEM teaching and learning in the U.S.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1835000","NCS-FO: Closed-loop neuromodulation for chronic pain","CBET","IntgStrat Undst Neurl&Cogn Sys","02/01/2019","08/31/2018","Zhe Chen","NY","New York University Medical Center","Standard Grant","Aleksandr Simonian","01/31/2022","$877,220.00","Jing Wang","Zhe.Chen@nyulangone.org","One Park Avenue, 6th FL","New York","NY","100165800","2122638822","ENG","8624","8089, 8091, 8551","$0.00","Proposal Title: NSF-FO: Closed-loop neuromodulation for chronic pain<br/><br/>Pain is a complex and multi-dimensional experience that nevertheless occurs commonly in people's daily lives. Chronic pain affects 1.5 billion people worldwide and has contributed to major healthcare costs. The treatment of chronic pain remains insufficient, highlighted by the current opioid epidemic. In the past few decades, neuroscience research has provided accumulating knowledge of pain processing in the central nervous system. However, effective analgesic options with limited side effects remain elusive, in large part because the neural mechanism for how chronic pain is perceived and modulated in the brain is poorly understood. This proposal tries to challenge the status quo using chronic pain-treated rodent models. The use of rodent models would allow researchers to examine the brain activity at specific localized neural circuits at a cellular resolution, and to further provide a guideline for neuromodulation-based pain treatment. The project has great translational potential to advance personalized pain medicine and provide therapy for the chronic pain associated with a wide range of neuropsychiatric disorders. This project will also promote education and diversity in training undergraduate/graduate students or postdoctoral fellows, and will be committed to data sharing and outreach activity in order to maximize the benefit to society.<br/><br/> <br/>This research project will integrate behavior and electrophysiology studies to investigate the causal impact of neuromodulation on neocortical circuits in chronic pain conditions. The ultimate objective of this proposal is to develop a noninvasive brain machine interface system for detecting and relieving chronic pain in a rodent model. On the one hand, this project will investigate examine basic neuroscience questions regarding the neural variability underlying complex sensory and affective processes. On the other hand, this project will investigate a minimally invasive neuromodulation strategy for treating chronic pain. In Aim 1, in vivo extracellular neural activity (including the ensemble spike activity and local field potentials) will be recorded from the primary somatosensory cortex and anterior cingulate cortex of freely behaving chronic pain-treated rats. This will allow researchers to characterize nociceptive response variability under different chronic pain conditions. In Aim 2, a closed-loop rodent neuromodulation interface will be developed for chronic pain control, which combines the detection of pain signals (?detection arm?) and neuromodualtion (?treatment arm?). This aim will optimize neural signal processing using multi-region local field potentials and further leverage advances in neuromodulation techniques to employ epicranial current stimulation on the targeted brain region (such as the primary motor cortex). In Aim 3, the current stimulation parameters (e.g., intensity and duration) will be optimized using online neurofeedback to improve the efficacy of neuromodulation in light of reinforcement learning. In summary, the brain-machine interface system will tease apart the mechanism of cortical pain circuits, and characterize the nociceptive response variability under different (inflammatory vs. neuropathic) chronic pain conditions. Together, these results will reveal novel insights into circuit mechanisms of chronic pain.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1734744","NCS-FO: Active Listening and Attention in 3D Natural Scenes","DUE","ECR-EHR Core Research, IntgStrat Undst Neurl&Cogn Sys","08/01/2017","07/29/2020","Cynthia Moss","MD","Johns Hopkins University","Standard Grant","Ellen Carpenter","01/31/2022","$1,137,675.00","Rajat Mittal, Mounya Elhilali, Susanne Sterbing-D'Angelo","cynthia.moss@jhu.edu","1101 E 33rd St","Baltimore","MD","212182686","4439971898","EHR","7980, 8624","8089, 8091, 8551, 8817","$0.00","As humans and other animals move around, the distance and direction between their bodies and objects in their environment are constantly changing.  Judging the position of objects, and readjusting body movements to steer around the objects, requires a constantly updated map of three-dimensional space in the brain.  Generating this map, and keeping it updated during movement, requires dynamic interaction between visual or auditory cues, attention, and behavioral output.  An understanding of how spatial perception is generated in the brain comes from decades of research using visual or auditory stimuli under restricted conditions.  Far less is known about the dynamics of how natural scenes are represented in freely moving animals.  This project will bridge this gap by studying how freely flying bats navigate through their environment using echolocation.  Specifically, a team of engineers and neuroscientists will investigate how the bat brain processes information associated with flight navigation. The project team will provide education and training in engineering and science to public school, undergraduate and graduate students, and to postdoctoral researchers. This research will also contribute to a rich library of materials, including videos and a website, which will be available to educators and scientists working in both the private and public sectors.<br/><br/>This project leverages innovative engineering tools, cutting-edge neuroscience methods and neuroethological modeling to pursue a multidisciplinary investigation of dynamic feedback between 3D scene representation, attention and action-selection in freely moving animals engaged in natural tasks. The echolocating bat, the subject of the project's research, actively produces the acoustic signals that it uses to represent natural scenes and therefore provides direct access to the sensory information that guides behavior. The specific goals of the project are to test the hypotheses that 1) natural scene representation operates through the interplay between sensory processing, adaptive motor behaviors, and attentional feedback, 2) spatio-temporal responses to sensory streams across ensembles of neurons sharpen when an animal adapts its behavior to attend to selected targets, and 3) spatio-temporal sharpening of neural responses enables figure-ground segregation in the natural environment. The project integrates 1) novel acoustic measurements and computational analyses to represent the sonar scene based on reconstructions of the bat's sonar transmitter and receiver characteristics, combined with a 3D acoustic model of the environment, 2) quantitative analysis of the echolocating bat's adaptive echolocation and flight behaviors as it negotiates complex environments, 3) multichannel neural telemetry recordings from the midbrain of the free-flying bat as it attends to targets, obstacles and other acoustic signals in its surroundings, and 4) computational modeling of auditory system architecture, attention and working memory mechanisms.  Collectively, this research will deepen the understanding of behavioral modulation of natural scene representation. <br/><br/>This project is funded by Integrative Strategies for Understanding Neural and Cognitive Systems (NSF-NCS), a multidisciplinary program jointly supported by the Directorates for Computer and Information Science and Engineering (CISE), Education and Human Resources (EHR), Engineering (ENG), and Social, Behavioral, and Economic Sciences (SBE)."
"1632259","NSF/SBE-BSF:Integration of kinesthetic and tactile information in perception, action, and learning","BCS","Cross-Directorate  Activities, Disability & Rehab Engineering, Engineering of Biomed Systems, Perception, Action & Cognition, EFRI Research Projects, IntgStrat Undst Neurl&Cogn Sys","09/15/2016","09/09/2017","Ferdinando Mussa-Ivaldi","IL","Rehabilitation Institute of Chicago","Continuing Grant","Betty Tuller","08/31/2021","$479,212.00","","sandro@northwestern.edu","355 East Erie Street","Chicago","IL","606113167","3122385195","SBE","1397, 5342, 5345, 7252, 7633, 8624","014Z, 1397, 7252, 8089, 8091","$0.00","Simple acts such as opening a jar or lighting a match depend on the ability to grasp objects with different shapes and to apply well-regulated forces and movements in different directions. When we hold a glass of water, the forces applied by the fingers are directed against the surface of the glass, and our brain coordinates these forces to prevent slippage and maintain the orientation of the glass. The planned studies will combine computational methods derived from control engineering and robotics with techniques and theories from neuroscience to understand how the brain controls grip forces when lifting and manipulating objects and how it estimates an object's mechanical properties. The investigations will consider how grasping an object is affected by uncertainties about the object properties (e.g., it's hardness, slipperiness, texture, etc) and how fundamental manipulation skills may be enhanced by artificially augmenting tactile information. The outcomes of these studies will influence several domains including (1) neuroscience (understanding our ability to  control and manipulate objects with our hands); (2) technology (for presenting force information to users of robotic devices such as teleoperation and robot-assisted surgery); and (3) neurorehabilitation (for developing intelligent robotic prostheses and new exercises to promote the recovery of lost manual skills). These studies will establish a collaborative interaction between scientists in the United States and Israel having a range of expertise that includes robotics, control, motor systems neuroscience and neurorehabilitation.<br/><br/>Getting the fingers to cooperate during dexterous manipulation requires the integration of different types of information. The fingers have a rich array of tactile sensors that generate signals related to the interaction with the object. However, for the brain to know the magnitude and direction of these forces, it must also know the orientation of the fingers in space. This information is obtained by other sources that form the basis for the sense of position of the body in space. The control of grasp can also be informed by kinesthetic force sensors in the muscles that in turn are integrated with the sense of the joint's configuration in space. This project takes advantage of a new technology that allows applying controlled stretches to the skin of the fingers. Skin stretch devices mounted on a robotic manipulator will be used to apply a variety of controlled perturbations while subjects are performing manipulation tasks. Perturbations will be applied to increase or decrease the consistency between tactile and kinesthetic feedback, and to investigate how the brain adapts the ability to maintain a stable grasp during both unpredictable and predictable forces. The approach will combine theory and experiments to tackle the integration of multiple information sources in perception and in controlling manipulation and grip forces.<br/><br/>This project is being supported by a partnership between the National Science Foundation and the U.S.-Israel Binational Science Foundation."
"1835231","NCS-FO: Analyzing Synapses, Motifs and Neural Networks for Large-Scale Connectomics","IIS","IntgStrat Undst Neurl&Cogn Sys","11/01/2018","08/28/2018","Hanspeter Pfister","MA","Harvard University","Standard Grant","Kenneth Whang","10/31/2021","$999,568.00","Jeff Lichtman","pfister@seas.harvard.edu","1033 MASSACHUSETTS AVE","Cambridge","MA","021385369","6174955501","CSE","8624","8089, 8091, 8551","$0.00","High-resolution analysis of the brain's connectivity, which reveals the actual wiring diagram connecting nerve cells of the brain, provides insights unattainable any other way into the way the healthy brain works and what goes awry in diseases and disorders of the nervous system. The primary challenge of this approach is that at present there are no reliable, robust and powerful computer-based techniques to analyze the extraordinarily large and vastly complicated networks of brain cells to detect connectional motifs in their highly branching and connected structure. Nor are there visualization tools that allow neuroscientists to explore the brain network patterns effectively. This work will analyze large brain networks from electron microscopy datasets in young and old mammalian brain samples. These data sets each contains hundreds of thousands of nerve cells and billions of synapses that interconnect them. The proposal aims to develop new methods and tools to analyze these vast brain networks at the synapse, motif, and network levels. If successful, the project will provide data and analysis tools for the development of new theories of how the brain works.<br/><br/>Recent advances in image acquisition using multi-beam serial-section electron microscopy (sSEM) and automated segmentation methods have enabled data collection for large tissue samples in a variety of animals. These data will be used to curate large-scale datasets with one million labeled synapses with synaptic cleft locations, pre- and postsynaptic polarity predictions, and excitatory and inhibitory type predictions. This has not been accomplished previously given the enormous amount of data. The aim is to discover synaptic motifs by subdividing complex neural networks into quantifiable and meaningful subgraphs. Automatic generation of candidates for motifs will be created by developing an efficient neurite-centric wiring-diagram reconstruction method and subgraph detection algorithm to find common patterns. These data will be used to quantify and compare reconstructed neural networks from different specimens at different spatial and temporal scales and build a visualization platform to assist neuroscientists to analyze these networks as they seek to ask and answer fundamental questions related to neural circuits in the brain.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1926789","NCS-FO: Developing dyadic fMRI methodology to quantify and model human brain-to-brain interactions","DGE","ECR-EHR Core Research, IntgStrat Undst Neurl&Cogn Sys","10/01/2019","08/08/2019","Ray Lee","NY","Columbia University","Standard Grant","Ellen Carpenter","09/30/2022","$999,834.00","Paul Sajda, Nim Tottenham","rl2946@columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","EHR","7980, 8624","8089, 8091, 8551, 8817","$0.00","The neural mechanisms that underlie and promote social interaction and communication remain elusive, despite a large number of evidence-based studies in psychology and psychiatry.  This is partially due to the lack of instruments and technology that can directly measure natural human interactions.  The proposed project intends to develop a dyadic functional magnetic resonance imaging (dfMRI) system to directly observe the brains of pairs of individuals while they are interacting with each other visually and by touch.  The project also hopes to develop a computer model to quantify these interactions.  Developing this technology will improve the level of knowledge about how brains work in complex environments.  Findings from this project will serve the national interest by assisting in the design of social robots, which will interact more naturally with humans.  Project findings may also help in identifying the neural underpinnings of mental disorders, particularly those that affect communication.<br/><br/>This project will leverage a pioneering dfMRI technology and methodology that can simultaneously scan two people in one commercial MRI scanner, and has generated successful feasibility tests in observing and analyzing brain-to-brain coupling in live face-to-face communication.  The first aim will be to develop a state-of-the-art dfMRI technology that will significantly improve temporal resolution and imaging quality by implementing local static magnetic field shimming and parallel imaging.  The second aim will be to use the new system to address two fundamental hypotheses in brain-to-brain interactions: (1) Face-to-face communication (measured by dfMRI) recruits more brain faculty that the Internet-based communications (measured by MR hyperscanning); therefore, it conveys more social and affective information. (2) A multi-channel cerebral network model - derived from dfMRI data - may be trained to deduce some basic social attribution processes in dyadic interaction; thus, a causal relationship between social behaviors and brain network can be identified.  Overall, this is a transformative, high-risk, high-payoff interdisciplinary proposal integrating engineering and social and behavioral science to enable new technology and methods to study human social interaction, mental disorders, and social robots.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1926747","Collaborative Research: NCS-FR: Shedding light on brain circuits mediating navigation of the odor plume in a natural environment","BCS","ECR-EHR Core Research, IntgStrat Undst Neurl&Cogn Sys","09/15/2019","09/16/2019","Ioannis Kymissis","NY","Columbia University","Standard Grant","Jonathan Fritz","08/31/2022","$356,164.00","","johnkym@ee.columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","SBE","7980, 8624","7298, 8089, 8091, 8551","$0.00","Animals have a keen ability to find odor sources such as food, partners, pups and predators through the sense of smell in a manner that cannot be replicated by machines. How brains mediate navigation of the environment (the odor plume) through smell is an important unsolved problem. Indeed there are many instances where using machines to navigate an odor landscape is an unmet need to society. For example, even though their training requires lengthy one on one interaction with a trainer, dogs are still used to find explosives in airports and in the battlefield. Our multidisciplinary Odor Plume Neurophotonics (OPeN) team will tackle understanding the brain circuits mediating odor plume navigation. This is a daunting task because it involves characterizing how odors diffuse in the air (environmental engineering), developing advanced miniature microscopes to record from the brain of freely moving animals (electrical and mechanical engineering), recording from brain regions processing odor plume information in real time (systems neuroscience and integrative neurophotonics), and developing mathematical procedures to quantify how the information necessary for successful odor plume navigation is represented in the brain (applied mathematics). Our team will engineer a novel miniature microscope to record activity as mice navigate the odor plume and will assess how the activity of these neurons result in successful odor plume navigation. Furthermore, the team members of OPeN are thoroughly committed to foster advancement of women, underrepresented minorities, veterans and disabled individuals in science and participate in various programs to promote science diversity. Additionally, the team members have a track record of disseminating their work and have an established partnership with a local small business, Intelligent Imaging Innovation, Inc. with world headquarters located in Denver. We will continue our commercial dissemination efforts of the technology developed in this project. Finally, we will endeavor to communicate science to the broader audience through venues such as Scientific American, Public Broadcasting Service and outreach through the Denver Museum of Nature and Science.<br/><br/>Members of our OPeN interdisciplinary team developed a novel two photon fiber-coupled microscope for 3D imaging of brain activity in the freely moving mouse and generated and quantified realistic odor environments in the laboratory to explore algorithms used for odor-guided navigation. In this project we leverage the extensive expertise and achievements of the team to crack the circuit basis for odor plume navigation. We will develop a low-weight, miniature 3-photon fiber coupled microscope (3P-FCM) to record neuronal activity simultaneously in one brain area in two planes of view. In addition, OPeN will develop a portable photoionization (PID) sensor to detect the odorant concentration at the nostril as the animal navigates the odor plume. Members of the OPeN team will record neural activity in the hippocampus and cerebellum of animals navigating the odor plume and will develop a Bayesian analysis method to decode odor plume navigation from neural activity. This multidisciplinary approach will result in understanding of the brain mechanisms of odor plume navigation.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1912232","CRCNS US-German Research Proposal: Choice-induced biases in human decision-making","IIS","CRCNS-Computation Neuroscience, Robust Intelligence","10/01/2019","10/15/2020","Alan Stocker","PA","University of Pennsylvania","Continuing Grant","Jonathan Fritz","09/30/2024","$999,991.00","","astocker@psych.upenn.edu","Research Services","Philadelphia","PA","191046205","2158987293","CSE","7327, 7495","7327, 8089, 8091","$0.00","The choices we make not only influence how we remember the past but also how we will perceive the future. In both cases, our judgments are biased in favor of our preceding choice. Such choice-induced biases have been known for centuries. They affect our judgments in daily life including in situations where judgment errors are critical (e.g., medical diagnoses, scientific hypothesis testing, or political decisions). Why the human brain generates these biases and tends towards self-confirmation has long remained elusive. Supported by the Collaborative Research in Computational Neuroscience program, the proposed research will set out to identify the underlying computational and neural mechanisms of choice-induced biases in human decision-making. The proposed work employs a highly interdisciplinary approach that combines measures of behavior and brain activity with theory and computational modeling. It perfectly draws from the complimentary experimental and computational expertise of each PI and their laboratories. The goal is to develop and validate a novel theory of decision-making under uncertainty, in which choice-induced biases play a central role. Unraveling the source and function of choice-induced biases is not only critical for understanding the limits of human rationality but has also immediate and important implications for society at large. For example, the insights can help training of physicians to reduce judgment errors in clinical diagnostics, as well as that of other decision-makers in the legal and corporate sectors. Finally, the experimental methods and results of the proposed research may help to shed light on the biological underpinnings of important brain disorders, in particular schizophrenia, for which confirmation biases are aggravated.<br/><br/>The central focus of the proposed work is to test the hypothesis that choices generate subjective expectations that influence the subsequent evaluation process of both past and future evidence. The proposed research will record psychophysical and functional neuroimaging (magnetoencephalography (MEG)) measurements of healthy human subjects while they are performing a range of novel behavioral tasks specifically developed to assess choice-induced biases in low-level perception as well has high-level cognition. Theory and computational modeling will be crucial to interpret these signals and ultimately to help infer the underlying cognitive operations. The results of this research will not only advance our understanding of choice-induced bias effects in decision-making, but of decision-making in general. The combined approach of simultaneously using behavioral, neural, and theoretical/computational measurements and methods imposes strong constraints on the expected results and explanations while at the same time lending also extraordinarily strong confidence to the findings as they are supported on all levels. To the degree that they demonstrate how choices influence subsequent evidence evaluation, our results have the potential to drastically change the traditional understanding of decision-making as a simple feedforward accumulation-to-bound process.<br/><br/>A companion project is being funded by the Federal Ministry of Education and Research, Germany (BMBF).<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1903783","US-French Collaboration: Collaborative Research: Neuro-Computational Models of Natural Language","IIS","Linguistics, Perception, Action & Cognition, CRCNS-Computation Neuroscience, Robust Intelligence","09/01/2018","11/16/2018","John Hale","GA","University of Georgia Research Foundation Inc","Continuing Grant","Jonathan Fritz","08/31/2021","$309,932.00","","jthale@uga.edu","310 East Campus Rd","ATHENS","GA","306021589","7065425939","CSE","1311, 7252, 7327, 7495","7327, 8089, 8091","$0.00","Our society is built upon shared ideas, ideas that get from one person to another via language that is ""understood."" But how do brains give us the ability to understand a stream of spoken words? This is a grand challenge question in computational neuroscience. This project addresses it using mathematical models of the language understanding process. These models reflect insights from computer science as well as linguistics. They allow investigators to ask: which process model best accounts for the signals from a particular brain region, at particular moment in time? The signals come from people listening to French and English versions of the same book. By comparing across models and across languages, the project seeks to differentiate between aspects of the understanding process that are language-specific and aspects that might be common to all humans. Increasingly precise modeling of this sort paves the way for future work with individuals who have trouble using language, such as those with Autism Spectrum Disorder. It could also lead to better computer systems, ones that use language in a brain-inspired way.<br/><br/>Bringing together computational linguists and cognitive neuroscientists, this project pursues two specific questions: (1) what aspects of sentence structure determine our expectations for upcoming words? and (2) what is the detailed balance between memorization and composition in natural language? Using electroencephalography (EEG) and functional Magnetic Resonance Imaging (fMRI) the PIs examine participants' neural responses to the spoken recitation of a literary work. These neural signals are fitted by time series predictors, themselves derived from linguistically plausible grammars and other language models. The project explores a family of such models, varying the size of grammatical units as well as the propensity for such units to be simply memorized as opposed to built up, step by step. Via information-theoretical complexity metrics, these theories derive quantitative predictions about the moment-by-moment neural responses of a person hearing a story. The approach as a whole leads to computationally explicit process models that are grounded in human brain responses to naturalistic text across two languages.<br/><br/>A companion project is being funded by the French National Research Agency (ANR)."
"1848840","Conference on Cognitive Computational Neuroscience (CCN): September 2018, Philadelphia, PA","BCS","Cognitive Neuroscience, Robust Intelligence","09/01/2018","08/23/2018","Alyson Fletcher","CA","University of California-Los Angeles","Standard Grant","Jonathan Fritz","08/31/2021","$50,000.00","Thomas Naselaris","akfletcher@ucla.edu","10889 Wilshire Boulevard","LOS ANGELES","CA","900951406","3107940102","SBE","1699, 7495","1699, 7556, 8089, 8091","$0.00","This project will provide three-years of support for the Conference on Cognitive Computational Neuroscience (CCN). This conference provides an annual scientific meeting for neuroscientists whose goal is to develop computationally defined models of brain information processing that explain rich measurements of brain activity and behavior. Historically, different disciplines have met subsets of these goals: Cognitive science has developed computational models at the cognitive level; computational neuroscience has developed neurobiologically plausible computational models at lower levels; cognitive neuroscience has mapped processes onto brain regions; and artificial intelligence has developed synthetic systems.  CCN is unique in its focus on the intersection between these fields.  In addition to advancing research, CCN seeks to contribute to the growing commercial use of biologically inspired hardware and software in Artificial Intelligence as well as being a vehicle for broadly impacting education and society.  One particular focus of CCN is increasing the visibility of women and scientists from underrepresented populations via speaking opportunities. This award will partially support travel grants for this purpose.  The conference will also include hands-on tutorials, and materials from these will propagate to various university curricula.  The award will support video recordings of the tutorials and talks.  These recordings will be made publicly available on the website to increase the broader impact of the conference to the wider community and those unable to attend. <br/><br/>A central goal of neuroscience is to understand how vast populations of neurons give rise to complex behavior. Today, advances in various domains offer tangible possibilities to make fundamental conceptual breakthroughs. Modern neural recording technologies now provide opportunities to observe neural activity at unprecedented resolution and scale. At the same time, research in cognitive science has become increasingly sophisticated in identifying computational principles that may serve as the basis for human cognition, and machine learning and artificial intelligence have made great strides in building models to autonomously solve complex cognitive tasks. However, interactions among these distinct disciplines remain rare. This new conference may stimulate unifying frameworks that fully realize the cross-disciplinary potential of these individual advances. Concretely, the goal of CCN is to create and foster a community that will develop models of brain information processing with several key features. These models should (1) be fully computationally defined and implemented in computer simulations; (2) be neurobiologically plausible; (3) explain measurements of brain activity (and continue to do so as spatiotemporal resolution and scale improve); (4) explain behavior in the context of naturalistic stimuli and tasks; and (5) perform feats of intelligence such as recognition, internal modelling and representation of the environment, decision-making, planning, action, and motor control. Such models currently do not exist and are unlikely to emerge without greatly improved cross-disciplinary engagement.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1644540","Neurocognitive underpinnings of dyslexia and dyscalculia","DRL","ECR-EHR Core Research","09/15/2016","09/15/2017","John Gabrieli","MA","Massachusetts Institute of Technology","Continuing Grant","Robert Ochsendorf","08/31/2021","$1,579,146.00","Joanna Christodoulou","gabrieli@mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","EHR","7980","1545, 8089, 8091","$0.00","Difficulties in math and reading prevent many students from succeeding in STEM education which demands both math and reading skills.  Dyslexia is the most common type of learning disability affecting reading proficiency but many students with dyslexia also exhibit dyscalculia, or math disability. To date, little research has sought to understand the extent of the neurobiological connections between dyslexia and dyscalculia.  <br/><br/>This proposal will explore the cognitive underpinnings of dyscalculia observed in children with dyslexia. Dyslexia and dyscalculia have traditionally been studied as separate development difficulties but this project will seek to determine whether math difficulties that exist in children with dyslexia are similar or different from the math difficulties that exist in children with dyscalculia only.  The investigators will recruit 150 children aged 10-12 and screen them for dyslexia, dyscalculia, and both dyslexia and dyscalculia. A battery of behavioral measures in both reading and math are planned along with neuroimaging (fMRI) data collection methods.   <br/><br/>This project is supported by NSF's EHR Core Research (ECR) program. The ECR program emphasizes fundamental STEM education research that generates foundational knowledge in the field. Investments are made in critical areas that are essential, broad and enduring: STEM learning and STEM learning environments, broadening participation in STEM, and STEM workforce development. The program supports the accumulation of robust evidence to inform efforts to understand, build theory to explain, and suggest intervention and innovations to address persistent challenges in STEM interest, education, learning and participation."
"1944389","EAGER: EEG-based Cognitive-state Decoding for Interactive Virtual Reality","IIS","HCC-Human-Centered Computing, IntgStrat Undst Neurl&Cogn Sys","10/01/2019","09/04/2019","Dean Krusienski","VA","Virginia Commonwealth University","Standard Grant","Balakrishnan Prabhakaran","09/30/2021","$209,996.00","","djkrusienski@vcu.edu","P.O. Box 980568","RICHMOND","VA","232980568","8048286772","CSE","7367, 8624","7367, 7916, 8089, 8091","$0.00","The increasing availability of affordable, high-performance virtual reality (VR) headsets creates great potential for applications including education, training, and therapy. In many applications, being able to sense a user's mental state could provide key benefits. For instance, VR environments could use brain signals such as the electroencephalogram (EEG) to infer aspects of the user's mental workload or emotional state; this, in turn, could be used to change the difficulty of a training task to make it better-suited to each user's unique experience.  Using such EEG feedback could be valuable not just for training, but in improving people's performance in real applications including aviation, healthcare, defense, and driving. This project's goal is to develop methods and algorithms for integrating EEG sensors into current VR headsets, which provide a logical and unobtrusive framework for mounting these sensors. However, there are important challenges to overcome. For instance, EEG sensors in labs are typically used with a conducting gel, but for VR headsets these sensors will need to work reliably in ""dry"" conditions without the gel. Further, in lab settings, motion isn't an issue, but algorithms for processing the EEG data will need to account for people's head and body motion when they are using headsets. <br/><br/>To address these challenges, the project team will build on recent advances in dry EEG electrode technologies and motion artifact suppression algorithms, focusing on supporting passive monitoring and cognitive state feedback. Such passive feedback is likely to be more usable in virtual environments than active EEG feedback, both because people will be using other methods to interact with the environment directly and because passive EEG sensing is more robust to slower response times and decoding errors than active control. Prior studies have demonstrated the potential of EEG for cognitive-state decoding in controlled laboratory scenarios, but practical EEG integration for closed-loop neurofeedback in interactive VR environments requires addressing three critical next questions: (1) can more-practical and convenient EEG dry sensors achieve comparable results to wet sensors?, (2) can passive EEG cognitive-state decoding be made robust to movement-related artifacts?, and (3) can these decoding schemes be generalized across a variety of cognitive tasks and to closed-loop paradigms?  To address these questions, classical cognitive tasks and more-complex simulator tasks will be implemented and tested as novel, interactive VR environments. Building upon preliminary results that successfully characterized movement artifacts and decoded cognitive workload in interactive VR using active-wet EEG sensors, this work will further explore the practical integration of EEG sensors with room-scale VR headsets to balance data quality, cognitive decoding performance, ease of setup and use, and user comfort.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1822683","CRCNS Research Proposal: Collaborative Research: Evaluating Machine Learning Architectures Using a Massive Benchmark Dataset of Brain Responses to Natural Scenes","IIS","CRCNS-Computation Neuroscience","10/01/2018","09/10/2018","Kendrick Kay","MN","University of Minnesota-Twin Cities","Standard Grant","Kenneth Whang","09/30/2021","$652,405.00","","kay@umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","7327","7327, 8089, 8091","$0.00","Machine learning technologies have the potential to radically transform the study of the human brain, but require far more data than is typically collected during conventional neuroscience experiments. The goal of this project is to drive the application of ML techniques to neuroscience research by generating a massive dataset of brain responses from the human visual system. The resulting dataset will be freely available to scientists, educators, and students. Through a yearly modeling competition, neuroscientists will gain experience in the application of advanced computational methods and ML researchers will gain a deeper understanding of the challenges and complexities of the human brain. Results of the modeling competition will be presented at an annual conference attended by both machine learning and neuroscience researchers and students, providing an opportunity for the two groups to interact and discuss approaches. This project will foster open collaboration between neuroscientists and artificial intelligence researchers and a culture of sharing data, ideas, and progress. <br/><br/>The long-term goal of this work is to generate data that will lead to the development of experimentally validated and computationally powerful models of the human visual system. The project leaders will use high-field (7 Tesla) functional magnetic resonance imaging (fMRI) to measure brain responses to a broad sampling of natural images in human observers. The specific objectives are as follows: (1) Acquire, pre-process, and distribute a massive, high-resolution fMRI dataset that exploits state-of-the-art imaging techniques. The dataset will include multiple samples of brain responses to roughly eighty thousand photographs drawn from an image collection that is widely used by the ML community. (2) Establish and host an annual competition for modeling this rich dataset at the conference on Cognitive Computational Neuroscience. (3) Bridge the gap between ML architectures and the human brain by testing new ML-inspired architectures as models of the visual system. The project leaders will focus specifically on recent developments in ML that suggest new hypotheses about the dorsal visual stream.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1912338","CRCNS Research Proposal: Collaborative Research: Mechanisms and dynamics of retronasal olfactory coding","IIS","Cross-BIO Activities, MSPA-INTERDISCIPLINARY","10/01/2019","09/05/2019","Cheng Ly","VA","Virginia Commonwealth University","Standard Grant","Edda Thiels","09/30/2022","$233,464.00","","cly@vcu.edu","P.O. Box 980568","RICHMOND","VA","232980568","8048286772","CSE","7275, 7454","1228, 7327, 8089, 8091, 9150, 9178, 9179","$0.00","How do our brain, nose, and mouth work together to generate the flavor of food and drink?  When flavor perception goes wrong, can this play a role in diseases like obesity?  The sense of smell is very important for perceiving flavor, largely because of odors that originate in the mouth and are exhaled through the nose via the back of the throat in a a process called retronasal olfaction.  In this study, researchers from the University of Arkansas, the Virginia Commonwealth University, and Southeastern Methodist University are teamed up to gain better understanding of how retronasal olfaction works using rats as an animal model.  The researchers combine direct measurements of the brain in action together with computer simulations of air flow through the nose and neural networks. They are testing the idea that different forces in the nose caused by reversing airflow through the nasal cavity are responsible for how the brain distinguishes exhaled retronasal odors from inhaled odors. In addition, the researchers offer training opportunities at each of the three institutions and are developing an educational video game aimed at introducing users to basic concepts of neurobiology and cognitive neuroscience. <br/><br/>Smells that enter the nose retronasally, i.e., from the back of the nasal cavity, play an essential role in flavor perception, yet many questions about the neuroscience of retronasal olfaction remain unanswered.  How does simply reversing the direction of air flow through the nasal cavity result in different neural input to the olfactory bulb (OB)?  How are retronasal and orthonasal (inhaled) olfactory signals encoded at the level of spiking neurons in the OB?  How do interactions within OB circuits facilitate selective response to retronasal versus orthonasal stimuli?  In this study, researchers from the University of Arkansas, the Virginia Commonwealth University, and Southeastern Methodist University are teamed up to answer these questions, guided by a two-part hypothesis. First, they hypothesize that, at the sensory periphery, retro- and orthonasal stimuli produce distinct spatiotemporal patterns of mechanosensory excitation of olfactory receptor neurons.  Second, they hypothesize that, in the OB, cell-type-specific inhibitory circuit interactions are crucial for dynamic changes in retronasal coding.  To test these hypotheses, the research team is combining high-density multi-electrode recordings in rat OB with fluid dynamics computer simulations based on the three-dimensional shape of the nasal cavity of the same animals. Moreover, the team is performing state-of-the-art realistic computational modeling to identify OB circuit-level principles of retronasal coding.  This work is expected to generate new understanding of the neural basis of retronasal olfaction that includes both peripheral mechanisms in the nose and central mechanisms at the level of M/T cells in the OB. This project is jointly funded by the cross-directorate Collaborative Research in Computational Neuroscience program, the Established Program to Stimulate Competitive Research(EPSCoR), and the MPS Office of Multidisciplinary Activities.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1822476","CRCNS Research Proposal:  Collaborative Research:  Wiring synaptic chain networks for precise timing during development","EF","Cross-BIO Activities, CRCNS-Computation Neuroscience","09/01/2018","08/10/2018","Dezhe Jin","PA","Pennsylvania State Univ University Park","Standard Grant","Edda Thiels","08/31/2022","$660,000.00","","djin@phys.psu.edu","201 Old Main","University Park","PA","168021503","8148651372","BIO","7275, 7327","7327, 8089, 8091, 9178, 9179","$0.00","Skilled behaviors such as singing and playing the piano require precise timing. The primary goal of this project is to use theoretical and experimental approaches to understand the network properties of neurons that can produce the extremely precise activity necessary to enable these actions. Such networks are likely to be wired during the development of the brain, but the precise mechanisms involved remain a mystery. Previous computational models and experimental observations suggest that the wiring process is gradual. The investigators of this project will study how individual neurons are incorporated into the network. Of particular interest are postnatally born neurons, which have more immature properties compared with other neurons within the circuit, including a higher degree of spontaneous activity, which potentially facilitates their recruitment into the network. These ideas will be tested by experimentally tagging and manipulating immature neurons, as well as by constructing computational models and simulating the network growth process. The findings may shed light on how functional neuronal networks develop.  The research may also help to formulate strategies of repairing dysfunctional or injured brain networks through manipulation of neuron maturity. This research will involve a wide range of innovative experimental and computational techniques and provide opportunities for students to gain expertise in electrophysiology, neural data analysis, and modern methods of computational neuroscience. The principal investigators will train postdoctoral researchers as well as graduate students, undergraduates, and summer high school interns. <br/><br/>The model system used in this project is the motor control circuitry of the zebra finch, a songbird whose adult courtship song consists of a highly repeatable sequence of vocal elements (or motif) sung with millisecond precision. The timing of song is controlled by a premotor forebrain region called HVC (proper name). Each premotor HVC neuron fires once per motif with sub-millisecond timing jitter across renditions. As a population, these neurons drive downstream song production circuits to produce specific acoustic patterns. During development, precise timing within HVC gradually emerges while the bird is learning to perform his song. Previous experimental observations suggest that neurons are gradually incorporated into the network generating song-relevant neural sequences, potentially from the newly born neurons that are robustly added to HVC during this period. This project aims to investigate the cellular and synaptic mechanisms underlying the development of the sequence generating network in HVC. The central hypothesis of this work is that these spontaneously active, newly born neurons are preferentially added to the leading edge of the growing timing network. This hypothesis will be tested with a combined experimental and computational modeling approach: (1) directly imaging the dynamics of network integration of newly born neurons in vivo through a targeted retroviral method; (2) constructing a computational model of HVC that is constrained by these observations and using the model to investigate the mechanisms of the network growth; and (3) measuring the cellular and synaptic properties of newly born neurons and their spontaneous activity as they mature.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1629913","II-New: Collaborative: A Mixed Reality Environment for Enabling Everywhere Data-Centric Work","CNS","Special Projects - CNS, CCRI-CISE Cmnty Rsrch Infrstrc, IntgStrat Undst Neurl&Cogn Sys","10/01/2016","08/29/2018","Aidong Lu","NC","University of North Carolina at Charlotte","Standard Grant","Balakrishnan Prabhakaran","09/30/2021","$493,140.00","Shaoting Zhang","alu1@uncc.edu","9201 University City Boulevard","CHARLOTTE","NC","282230001","7046871888","CSE","1714, 7359, 8624","7359, 8089, 8091, 8551, 9251","$0.00","This infrastructure project will develop an open source software toolkit, called OpenMR, to support building ""mixed reality"" data analysis systems that project data into the physical world using a new class of display devices such as Microsoft Hololens and Oculus Rift. Through OpenMR, these lightweight, wearable, mobile devices will tap into data-intensive infrastructures hosted in the cloud, with the goal of developing systems that allow users to perform data-intensive tasks from anywhere, without requiring heavy dedicated large-format displays supported by dedicated local computers.  To pursue this research, the investigators will acquire both dedicated cloud-computing servers (to support data analysis) and mixed reality hardware devices (to create the interfaces).  They will develop OpenMR to connect this hardware, to support common analysis tasks such as selecting, filtering, and classifying data, and to create data displays in the physical world. To both demonstrate the toolkit and advance data analysis research, they will build a number of prototype mixed reality interfaces for researchers whose work requires analyzing a large amount of data in domains including weather, biology, and medical imaging.  In addition to advancing those specific research areas, studying these prototypes with real users will support research around the underlying data analysis techniques, the cognitive science of how people interact with data in the physical world, and the design principles needed to build mixed reality systems.  This, in turn, will make these emerging technologies more likely to succeed and spread, and increase the chance of finding potential 'killer apps' for these systems.  The infrastructure will also directly support education and research at the partner universities around data visualization, computer graphics, computer vision, and machine learning, while the release of the toolkit will benefit the wider community.  This research is timely and important because as smart devices, in particular virtual and mixed reality devices such as Google Glass, Microsoft Hololens, Oculus Rift and Google Cardboard, become commonplace, these devices will play an increasingly important role relative to traditional laptop and digital computers when interacting with digital information. <br/><br/>The long-term vision of the project is to develop a mixed reality research infrastructure to support everywhere data-centric innovations, providing immersive, intuitive, location-free, advanced machine learning, data analysis, reduction, summary and storage tools.  This includes advanced support for the full pipeline of data-centric work in mixed reality spaces through the OpenMR open source toolkit, including front end visualization and interaction that leverages awareness of available rendering spaces and hardware along with effective visualization patterns in 2D and 3D spaces to optimize interaction; key components of data analysis and machine learning on the middle layers including automatic, generic feature engineering and joint optimization of classification performance and effective identification of discriminating features; and high-performance computing and cost-sensitive job management on the server.  The team will evaluate OpenMR's efficiency, stability, scalability, functionality, flexibility, and ease of adoption through a number of mechanisms, including self-evaluations and documentation of the design process, review from domain experts, and evaluation with both expert and novice users on data analysis tasks that cur across the specific application domains described above.  The toolkit itself will be released on the GitHub open source platform during the third year of the project after it has reached an initial level of maturity and usefulness.  The investigators will publicize OpenMR through a Youtube channel with a set of demonstration videos; outreach to relevant researchers interested in immersive visualization, visual analytics, multi-sensory human-computer interaction, machine learning with human-in-the-loop, and high-performance computing; and collaboration with undergraduates in the Students, Technology, Academia, Research, and Service Computing Corps consortium."
"2022685","Mechanisms for causal and non-causal predictive learning","BCS","Cognitive Neuroscience, IntgStrat Undst Neurl&Cogn Sys","09/01/2020","10/13/2020","Anna Leshinskaya","CA","University of California-Davis","Standard Grant","Jonathan Fritz","08/31/2023","$657,263.00","Charan Ranganath, Erie Boorman","aleshinskaya@ucdavis.edu","OR/Sponsored Programs","Davis","CA","956186134","5307547700","SBE","1699, 8624","1699, 8089, 8091","$0.00","A key feature of human learning is use of the past to predict what is likely in the future. For example, people rely on past experience to predict that thunder is often followed by a downpour. But there are different ways to learn how events are related. For example, some events co-occur (thunder and rain), while others are causally related (cloud cover and rain). People can also learn long-range relationships?for example, that rain will lead to more flowers, which leads to more insects, even though rain may not directly affect insects population. This project will investigate how different brain areas support these different kinds of learning abilities, and will fill important gaps in understanding exactly how the brain changes in response to experience. As such, the proposed research will significantly advance our understanding of how the brain supports learning and memory. Because predictive and causal relationships are at the heart of many high-level cognitive activities including reasoning, language, decision making, the proposed research will have a broad scientific impact. More broadly, the findings may have important implications for education by elucidating how we learn, and for artificial intelligence, in which causal reasoning is a major frontier. Additional impacts on education and society will also be enabled through our outreach activities. <br/><br/>A set of neural areas, important for memory, show learning-related changes that represent predictive relations. However, it is unknown how predictive memories form, or what they reflect about observed experience. This project will investigate which ?core predictive memory? areas support learning of causal or non-causal predictive relations. Experimental aims will focus on three major principles of causal learning: sensitivity to confounds, temporal specificity, and representation of structure. Computational models will make specific predictions about how these areas should respond to evidence if they learn according to classic theories from theoretical neuroscience. A well-established fMRI measure of relational strength will then test these model predictions in core memory areas. The first aim will test whether core memory areas are sensitive to confounds, or reflect simple co-occurrence. The second aim will test whether core memory areas are temporally specific. This will resolve whether and which areas learn temporally precise, causal relations as opposed to cumulative predictive relations better suited for planning. The third aim will test whether core memory areas represent explicit structure. Overall, these findings will sharpen and deepen understanding of how predictive memory areas work together to support higher order cognition.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1926676","Collaborative Research: NCS-FR: Shedding light on brain circuits mediating navigation of the odor plume in a natural environment","BCS","Modulation, ECR-EHR Core Research, IntgStrat Undst Neurl&Cogn Sys","09/15/2019","09/16/2019","Diego Restrepo","CO","University of Colorado at Denver","Standard Grant","Jonathan Fritz","08/31/2022","$1,550,323.00","Emily Gibson, Abigail Person","Diego.Restrepo@ucdenver.edu","MS F428, AMC Bldg 500","Aurora","CO","800452570","3037240090","SBE","7714, 7980, 8624","7298, 8089, 8091, 8551","$0.00","Animals have a keen ability to find odor sources such as food, partners, pups and predators through the sense of smell in a manner that cannot be replicated by machines. How brains mediate navigation of the environment (the odor plume) through smell is an important unsolved problem. Indeed there are many instances where using machines to navigate an odor landscape is an unmet need to society. For example, even though their training requires lengthy one on one interaction with a trainer, dogs are still used to find explosives in airports and in the battlefield. Our multidisciplinary Odor Plume Neurophotonics (OPeN) team will tackle understanding the brain circuits mediating odor plume navigation. This is a daunting task because it involves characterizing how odors diffuse in the air (environmental engineering), developing advanced miniature microscopes to record from the brain of freely moving animals (electrical and mechanical engineering), recording from brain regions processing odor plume information in real time (systems neuroscience and integrative neurophotonics), and developing mathematical procedures to quantify how the information necessary for successful odor plume navigation is represented in the brain (applied mathematics). Our team will engineer a novel miniature microscope to record activity as mice navigate the odor plume and will assess how the activity of these neurons result in successful odor plume navigation. Furthermore, the team members of OPeN are thoroughly committed to foster advancement of women, underrepresented minorities, veterans and disabled individuals in science and participate in various programs to promote science diversity. Additionally, the team members have a track record of disseminating their work and have an established partnership with a local small business, Intelligent Imaging Innovation, Inc. with world headquarters located in Denver. We will continue our commercial dissemination efforts of the technology developed in this project. Finally, we will endeavor to communicate science to the broader audience through venues such as Scientific American, Public Broadcasting Service and outreach through the Denver Museum of Nature and Science.<br/><br/>Members of our OPeN interdisciplinary team developed a novel two photon fiber-coupled microscope for 3D imaging of brain activity in the freely moving mouse and generated and quantified realistic odor environments in the laboratory to explore algorithms used for odor-guided navigation. In this project we leverage the extensive expertise and achievements of the team to crack the circuit basis for odor plume navigation. We will develop a low-weight, miniature 3-photon fiber coupled microscope (3P-FCM) to record neuronal activity simultaneously in one brain area in two planes of view. In addition, OPeN will develop a portable photoionization (PID) sensor to detect the odorant concentration at the nostril as the animal navigates the odor plume. Members of the OPeN team will record neural activity in the hippocampus and cerebellum of animals navigating the odor plume and will develop a Bayesian analysis method to decode odor plume navigation from neural activity. This multidisciplinary approach will result in understanding of the brain mechanisms of odor plume navigation.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1926668","Collaborative Research: NCS-FR: Shedding light on brain circuits mediating navigation of the odor plume in a natural environment","BCS","IntgStrat Undst Neurl&Cogn Sys","09/15/2019","09/16/2019","Juliet Gopinath","CO","University of Colorado at Boulder","Standard Grant","Jonathan Fritz","08/31/2022","$1,093,512.00","Victor Bright, John Crimaldi","juliet.gopinath@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","SBE","8624","7298, 8089, 8091, 8551","$0.00","Animals have a keen ability to find odor sources such as food, partners, pups and predators through the sense of smell in a manner that cannot be replicated by machines. How brains mediate navigation of the environment (the odor plume) through smell is an important unsolved problem. Indeed there are many instances where using machines to navigate an odor landscape is an unmet need to society. For example, even though their training requires lengthy one on one interaction with a trainer, dogs are still used to find explosives in airports and in the battlefield. Our multidisciplinary Odor Plume Neurophotonics (OPeN) team will tackle understanding the brain circuits mediating odor plume navigation. This is a daunting task because it involves characterizing how odors diffuse in the air (environmental engineering), developing advanced miniature microscopes to record from the brain of freely moving animals (electrical and mechanical engineering), recording from brain regions processing odor plume information in real time (systems neuroscience and integrative neurophotonics), and developing mathematical procedures to quantify how the information necessary for successful odor plume navigation is represented in the brain (applied mathematics). Our team will engineer a novel miniature microscope to record activity as mice navigate the odor plume and will assess how the activity of these neurons result in successful odor plume navigation. Furthermore, the team members of OPeN are thoroughly committed to foster advancement of women, underrepresented minorities, veterans and disabled individuals in science and participate in various programs to promote science diversity. Additionally, the team members have a track record of disseminating their work and have an established partnership with a local small business, Intelligent Imaging Innovation, Inc. with world headquarters located in Denver. We will continue our commercial dissemination efforts of the technology developed in this project. Finally, we will endeavor to communicate science to the broader audience through venues such as Scientific American, Public Broadcasting Service and outreach through the Denver Museum of Nature and Science.<br/><br/>Members of our OPeN interdisciplinary team developed a novel two photon fiber-coupled microscope for 3D imaging of brain activity in the freely moving mouse and generated and quantified realistic odor environments in the laboratory to explore algorithms used for odor-guided navigation. In this project we leverage the extensive expertise and achievements of the team to crack the circuit basis for odor plume navigation. We will develop a low-weight, miniature 3-photon fiber coupled microscope (3P-FCM) to record neuronal activity simultaneously in one brain area in two planes of view. In addition, OPeN will develop a portable photoionization (PID) sensor to detect the odorant concentration at the nostril as the animal navigates the odor plume. Members of the OPeN team will record neural activity in the hippocampus and cerebellum of animals navigating the odor plume and will develop a Bayesian analysis method to decode odor plume navigation from neural activity. This multidisciplinary approach will result in understanding of the brain mechanisms of odor plume navigation.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1835317","NCS-FO: Electrocortical Processes in Real World Locomotion","BCS","Cross-Directorate  Activities, GOALI-Grnt Opp Acad Lia wIndus, ECR-EHR Core Research, IntgStrat Undst Neurl&Cogn Sys","09/01/2018","10/15/2020","Daniel Ferris","FL","University of Florida","Standard Grant","Jonathan Fritz","08/31/2022","$863,641.00","","dferris@bme.ufl.edu","1 UNIVERSITY OF FLORIDA","GAINESVILLE","FL","326112002","3523923516","SBE","1397, 1504, 7980, 8624","019Z, 8089, 8091, 8551, 8817","$0.00","Technology for mobile brain imaging with electroencephalography (EEG) has advanced in recent years, but it is still difficult to capture electrical brain dynamics while people move in the real world. The body movement of walking and running creates considerable motion and muscle artifacts, making it difficult to determine what is true brain activity. This project proposes to advance electrode technology and signal processing of EEG to enable measurement of brain electrical activity outside the laboratory in the real world, including playing tennis, a complex, active, goal-directed motor task. The project will use novel methods to measure brain electrical activity as people walk on a university campus. Some subjects will be physically intact; some will have lower limb amputations. The technological and scientific advancements from these studies will permit future use of mobile EEG for clinical diagnosis and rehabilitation, as well as development of new mobile brain computer interfaces.<br/><br/>To understand how the human brain works in the real world, it is necessary to study human brain dynamics in real-world environments and tasks. Stationary functional brain imaging techniques like magnetic resonance imaging and magnetoencephalography are inherently limited in studying brain function of people moving through the real world. Creating and validating new mobile brain imaging methods with both good temporal and spatial resolution are necessary to advance neuroscience and facilitate non-invasive brain computer interfaces for real-world use. This project will combine high-density EEG with independent component analysis and source localization to identify brain areas involved in the control and active perception of moving in real-world urban and natural environments and in playing tennis. Motion and muscle artifacts complicate interpretation of EEG data during active whole body movement. New hardware and software solutions are necessary to increase the quality of EEG as a mobile brain imaging tool during locomotion. This project will advance novel dual-layer EEG electrodes that can cancel motion artifacts and improve the fidelity of electrocortical measures. The project combines cognitive neuroscience, signal processing, sensor technology, biomechanics, and motor control to make recordings of human brain dynamics that have never been made before. The advances and validation of neurotechnology will provide neuroscientists with new capabilities to transform the study of human brain function in the real world. This research will advance technology for mobile brain imaging and provide new insight into the cortical control of human movement in health and disability.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1845928","NCS-FO: Collaborative Research: Developing Underwater EEG Electrodes for Octopus Research","BCS","IntgStrat Undst Neurl&Cogn Sys","09/01/2018","08/08/2018","Walter Besio","RI","University of Rhode Island","Standard Grant","Jonathan Fritz","08/31/2021","$100,000.00","","besio@uri.edu","RESEARCH OFFICE","KINGSTON","RI","028811967","4018742635","SBE","8624","7916, 8089, 8091, 8551, 9150","$0.00","The octopus is a social animal, with high intelligence and problem-solving skills, that is very distant from humans in terms of its evolution.  This project aims to fabricate neuroelectric sensors and experimental protocols that would enable studying visual and higher level cognitive processes in the octopus while they are engaged in natural behaviors in an underwater environment. This will necessitate development of new engineering solutions for crafting electroencephalography (EEG) sensors that can record signal underwater, new solutions for removing noise artifacts from these highly complicated recordings, as well as careful design of experiments that could study such behaviors in a virtual-reality environment. While the brain of the octopus is very different from that of the human, it does support well-defined cognitive functions. Therefore, understanding whether and how octopuses' brains implement processes such as learning, attention, habituation, and surprise can produce new and important understandings of how neurobiological systems can support function.  This research might reveal that the neural substrates of cognitive function in the octopus are organized according to principles that differ drastically from those found in in humans.<br/><br/>This EAGER project has several aims. It will develop the first underwater EEG, first testing well-validated paradigms on humans performing task underwater and benchmarking against known waveforms. The electrodes will be constructed so that they do not corrode in salt water. It will also develop high-quality virtual reality stimulation that could impact octopuses' behavior in an underwater environment. It will utilize EEG frequency-tagging techniques to determine processing of environmental stimulus by the octopus. This will allow studying whether octopuses present characteristic responses that are analogous to surprise, adaptation, working memory and attention effects (in primates and other vertebrates). The study will also allow answering how and in what manner do octopuses sleep. All data, artifacts and modeling software will be made publicly available and constitute an important resource for the community. The results of this study could impact our general understanding of how brains support complex cognitive functions, with direct relevance to artificial intelligence efforts.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1734854","NCS-FO: Data-driven modeling of visual cortex","SMA","MATHEMATICAL BIOLOGY, IntgStrat Undst Neurl&Cogn Sys","09/01/2017","08/07/2017","Robert Shapley","NY","New York University","Standard Grant","Jonathan Fritz","08/31/2021","$599,968.00","Lai-Sang Young","shapley@cns.nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","SBE","7334, 8624","4444, 8089, 8091, 8251, 8551","$0.00","One of the great challenges of modern neuroscience is a comprehensive theory of the function of the cerebral cortex. The overall aim of the present project is to answer this challenge with a new model of the visual cortex. The modeling process will lead to the discovery of common, canonical neural mechanisms behind a multitude of visual phenomena, giving special emphasis to canonical computations that are performed not just in the visual cortex but also in other regions of the cerebral cortex. The project aims to enhance understanding of cortical function by looking beyond structure to study the dynamics of cortical activity. An important part of the project's broader impact will be to provide interdisciplinary training for young researchers in response to society's need for an educated workforce with multi-disciplinary skills bridging mathematics and neurobiology. Additionally, the principal investigators will reach out to broad scientific audiences as well as high school students. Specifically, the results of this project will be disseminated by giving invited scientific lectures to national and international scientific meetings. The investigators also participate in university-sponsored outreach events for New York City-area high school students, such as the annual C-Splash lectures at the NYU Courant Institute of Mathematical Sciences. <br/><br/>This project  adopts an integrative strategy to apply ideas from dynamical systems theory to theoretical neuroscience. The project will construct a next-generation model of the visual cortex that is realistic and comprehensive in the way it reproduces the dynamics of cortex and its visual functions. The model will be constrained by hundreds of sets of visual neuroscience data and by all that is known about cortical neuroanatomy. Such a model is a tool to advance neuroscience and a step toward building robotic intelligent systems that emulate human perception. The visual cortex will be modeled as a large network of spiking, conductance-based neurons. It will be analyzed as a complex dynamical system. Specific projects are: 1) network models of local circuitries; 2) extended models of the visual cortex covering a substantial portion of the visual field, and 3) dynamical interactions on neuronal scale to perceptual organization of two- and three-dimensional objects. The modeling and analysis will have wide impact beyond visual cortex in studies of the functional, dynamical consequences of canonical computations that are performed throughout the cerebral cortex. <br/><br/>This project is funded by Integrative Strategies for Understanding Neural and Cognitive Systems (NSF-NCS), a multidisciplinary program jointly supported by the Directorates for Computer and Information Science and Engineering (CISE), Education and Human Resources (EHR), Engineering (ENG), and Social, Behavioral, and Economic Sciences (SBE).  This award is co-funded by the Division of Mathematical Sciences in the Directorate for Mathematical and Physical Sciences (MPS)."
"1607251","US-French Collaboration: Collaborative Research: Neuro-Computational Models of Natural Language","IIS","CRCNS-Computation Neuroscience","09/01/2016","09/19/2017","Jonathan Brennan","MI","Regents of the University of Michigan - Ann Arbor","Continuing Grant","Jonathan Fritz","08/31/2021","$292,168.00","","jobrenn@umich.edu","3003 South State St. Room 1062","Ann Arbor","MI","481091274","7347636438","CSE","7327","7327, 8089, 8091","$0.00","Our society is built upon shared ideas, ideas that get from one person to another via language that is ""understood."" But how do brains give us the ability to understand a stream of spoken words? This is a grand challenge question in computational neuroscience. This project addresses it using mathematical models of the language understanding process. These models reflect insights from computer science as well as linguistics. They allow investigators to ask: which process model best accounts for the signals from a particular brain region, at particular moment in time? The signals come from people listening to French and English versions of the same book.  By comparing across models and across languages, the project seeks to differentiate between aspects of the understanding process that are language-specific and aspects that might be common to all humans. Increasingly precise modeling of this sort paves the way for future work with individuals who have trouble using language, such as those with Autism Spectrum Disorder. It could also lead to better computer systems, ones that use language in a brain-inspired way. <br/><br/>Bringing together computational linguists and cognitive neuroscientists, this project pursues two specific questions: (1) what aspects of sentence structure determine our expectations for upcoming words? and (2) what is the detailed balance between memorization and composition in natural language? Using electroencephalography (EEG) and functional Magnetic Resonance Imaging (fMRI) the PIs examine participants' neural responses to the spoken recitation of a literary work. These neural signals are fitted by time series predictors, themselves derived from linguistically plausible grammars and other language models. The project explores a family of such models, varying the size of grammatical units as well as the propensity for such units to be simply memorized as opposed to built up, step by step. Via information-theoretical complexity metrics, these theories derive quantitative predictions about the moment-by-moment neural responses of a person hearing a story.  The approach as a whole leads to computationally explicit process models that are grounded in human brain responses to naturalistic text across two languages. <br/><br/>A companion project is being funded by the French National Research Agency (ANR)."
"1926736","Collaborative Research: NCS-FO Biology and Function of Prosody: Integrative approach to individual differences","DGE","ECR-EHR Core Research, IntgStrat Undst Neurl&Cogn Sys","10/01/2019","08/21/2019","Cyrille Magne","TN","Middle Tennessee State University","Standard Grant","Ellen Carpenter","09/30/2023","$393,394.00","","cyrille.magne@mtsu.edu","1301 E. Main","Murfreesboro","TN","371320001","6154947848","EHR","7980, 8624","1545, 8089, 8091, 8551, 8817","$0.00","College readiness and career opportunities are highly dependent on young adults' reading proficiency. Yet, recent data indicate that almost two-thirds of tested students, including many students with dyslexia, do not possess the fundamental skills that are required to successfully master college-level reading material. Prosody, defined as linguistically relevant fluctuations in intonation, stress and timing, is an essential but underappreciated aspect of spoken language and reading. Humans vary in their sensitivity to the prosodic structure of speech, and there appears to be a strong link to individual differences in reading skills. With the support of the Integrative Strategies in Neural and Cognitive Systems program, this project will take bold steps towards investigating the biology and function of prosody with a creative array of approaches and research settings. With the first-ever dataset of its kind, the project intends to make critical progress towards integrating knowledge from a large population sample about the neurobiological basis of prosody across methods and levels (genetics, neuroimaging, and behavioral task performance). Beyond scientific advancement, the activities outlined in the proposed project will allow the research team to contribute to improving STEM education and educator development, addressing neurodevelopmental disorders such as dyslexia, increasing public engagement with science and technology, and enhancing big-data partnerships across academic sites.<br/><br/>The underlying biology of prosody is poorly understood at the neural and genetic level, despite its important function in humans' communication skills. Innovative combinations of multi-disciplinary approaches for novel data collection in large samples and use of existing large-scale resources are needed to yield significant knowledge of the biology and function of prosody. The first aim of this proposal will include a series of studies using a combination of EEG, eye tracking and standardized behavioral tasks to explore the time-dynamic processes of attending to prosodic cues in ecologically valid situations of speech perception and reading, and to examine the contribution of prosody sensitivity to individual differences in reading. The second aim will be a genome-wide association study of prosodic sensitivity and will be conducted through a diverse sample of individuals recruited online throughout the United States and in-person in the Middle Tennessee area in local community and educational settings. Cutting-edge genomic methodologies (PrediXcan and Gene Set Enrichment analysis) will be used to identify the genetic markers and novel neural endophenotypes (imputed gene expression in brain tissue) that give rise to individual differences in prosody. This series of studies builds essential groundwork for future planned studies that seek to disentangle shared versus separate genetic architecture of prosody and other aspects of language function and could reveal transformative knowledge about the biological mechanisms driving individual differences in reading and language skill. The collaborative research project leverages the team's diverse backgrounds in Cognitive Neuroscience, Psycholinguistics, Communication Disorders, and Human Genetics.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1909756","AF: Small: Collaborative Research: A Computational Theory of Brain Function","CCF","Robust Intelligence, Algorithmic Foundations","10/01/2019","08/23/2019","Santosh Vempala","GA","Georgia Tech Research Corporation","Standard Grant","A. Funda Ergun","09/30/2022","$200,000.00","","vempala@cc.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7495, 7796","7923, 7927, 8089, 8091","$0.00","This project seeks to identify, explore, render rigorous, and validate one piece of the solution to the puzzle ""how does the brain work?"" - one of the truly fundamental and most challenging frontiers in all of science. Computation in the brain will be approached at an intermediate level of scale, far larger than that of individual neurons and synapses yet significantly smaller than that of the whole brain. The core hypothesis is that ""assemblies,"" large and highly interconnected sets of neurons, are the engine of brain computation. Studying computation at this level is crucial for understanding higher cognitive functions, especially in humans, such as reasoning, planning, and language; and this formulation of brain computation is particularly amenable to the methodology and point of view of the theory of computation, and will further its reach. This project is quintessentially interdisciplinary, and will provide multi-faceted training to graduate and undergraduate students in Computer Science Theory, Machine Learning, and Cognitive Neuroscience and Psychology. It will develop interdisciplinary graduate courses in this particular scientific interface. The results of the project will be disseminated broadly via conferences and journals in all these disciplines, but also in colloquia and public lectures, while students of a great variety of backgrounds will participate in a cutting-edge research experience.<br/> <br/>Assemblies can be the basis of a powerful computational system involving a repertoire of operations including project, associate, and merge. These operations can be shown, through theorems and simulations, to be plausible (that is, they can be ""compiled down"" to the level of neurons and synapses) and useful (in the sense that they can help explain extant experimental results). The project will pursue this assembly hypothesis through: (1) expanding our modeling and our mathematical techniques of analysis for the study of assembly computation; (2) developing more accurate and efficient simulation methodology; (3) embarking on a multi-pronged exploration of the computational power of assemblies in novel modalities beyond formal computation, in particular (a) probabilistic and dynamical systems-like computation through pattern completion and (b) learning and prediction; (4) mathematical modeling and algorithmic investigation of the ways in which the dynamics and biases of synaptic connectivity, as well as assembly overlap, affect the various modes of brain computation; and, importantly, (5) functional magnetic resonance imaging (fMRI) experiments, and the analysis of the results of these experiments and extant electrocorticography (ECoG) data through novel algorithmic and machine learning techniques for the purpose of identifying evidence of assembly computation in the human brain.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1804540","Collaborative Proposal: Understanding Motor Cortical Organization through Engineering Innovation to TMS-Based Brain Mapping","CBET","Engineering of Biomed Systems","09/01/2018","11/27/2019","Wasim Malik","MA","Massachusetts General Hospital","Standard Grant","Stephanie George","08/31/2021","$300,000.00","","wmalik@partners.org","Research Management","Somerville","MA","021451446","8572821670","ENG","5345","8089, 8091","$0.00","This project addresses a question that has vexed scientists for more than a century: how does the motor cortex, i.e. the part of the brain where nerve impulses initiate voluntary muscular activity, represent and coordinate multiple muscles in order to produce a vast range of movements? To answer this question, this project will harness the unique strengths of non-invasive, navigated, transcranial magnetic stimulation (TMS) mapping to establish causal links between brain physiology and behavior. TMS is achieved by placing a coil of wires near the scalp, which when activated with an electrical current will create a magnetic field across the scalp and skull.  TMS is the only non-invasive method available to stimulate the brain as effectively as invasive stimulation for mapping the motor cortex. However, innovations in three areas are critically needed to use TMS-based motor mapping to understand multi-muscle physiology and control: 1) drastically improving the efficiency, efficacy and reliability of the TMS-based motor cortex mapping processes, 2) characterizing and validating TMS-based mapping as a probe for understanding the relationship between multi-muscle activation and voluntary movement, and 3) applying a neural network computational method to improve understanding of motor control and organization. Enhanced understanding of motor cortex physiology through TMS mapping of motor representations has the potential to better map the brain in applications such as surgical removal of tumors, assessing brain injury due to concussions or stroke, and identifying cortical networks needed for successful brain-machine interactions for controlling prostheses. Students involved with this project will be trained to address multidisciplinary challenges at the intersection of neuroscience, non-invasive brain stimulation, software design, control theory, machine-learning, statistical signal processing, data dimensionality reduction and visualization. Partnership with Boston-based leaders in the technology industry will provide state-of-the-art training to undergraduate, graduate, and post-graduate trainees. Through cooperative educational programming at Northeastern University and internships with Mass General Hospital, STEM-based learning opportunities will be provided for middle- and high-school students, inspiring a diverse body of students to pursue STEM careers. To promote STEM careers and demonstrate impact, the team will reach out to local venues that promote public awareness and appreciation of science, such as science fairs and the Boston Museum of Science.<br/><br/>The goal of this collaborative project is to develop a deeper mechanistic understanding of the role of the motor cortex (M1) in controlling single muscles and synergies in producing complex movements. This will be accomplished by developing several innovations in the use of non-invasive transcranial magnetic stimulation (TMS) to map the spatial distribution of synergies and single muscles. Transformative computational advances will be used to extract more accurate information about brain interaction with other physiological systems outside the motor domain and increase the rigor of analysis and data visualization to enhance interpretability, and repeatability. An enhanced understanding of corticomotor organization of complex movement will pave the way to studying motor system development across the lifespan, the basis of human performance enhancement, and the basis and characterization of neuromotor diseases. The research plan is organized under 3 aims. AIM 1 is to accelerate acquisition of TMS-based maps by developing an active learning process based on a Gaussian Process Model (GPM) of Muscle Evoked Potentials (MEPs) as a function of 2D spatial coordinates on the scalp. The developed Active-GMP learning algorithm is expected to speed up the mapping process by diverting time spent on loci with null data to loci where the model needs more samples to improve certainty. The efficacy and the accuracy of the new algorithm will be compared to three existing alternatives. AIM 2 is to test the behavioral relevance of synergies derived from human multi-muscle TMS mapping, i.e., to biologically validate the technical methods developed in Aim 1. Specifically, TMS and Voluntary (VOL) EMG data will be collected from 16 hand-arm muscles in healthy participants while subjects mimic hand postures for static letters and numbers of the American Sign Language alphabet. Non-negative matrix factorization-extracted synergies from VOL data and TMS data will be compared to determine if the TMS-elicited synergies match those utilized during movement production and if the adaptive Active-GMP and user-guided approaches more closely match synergies derived from VOL data compared to other approaches. AIM 3 is to develop generative and inverse topographic imaging models that allow forward modeling of M1 control and reverse mapping of M1 organization, respectively, of muscles and synergies. Hybrid models combining subject-specific FE modeling of TMS-induced cortical electric fields with neural network models trained to predict evoked muscle responses will be used to answer key questions: Q1) Are synergies dominant features of motor control? Q2) Do direct M1 motorneuron projections augment a synergy model of control? and Q3) Are muscles and synergies discretely organized in M1?<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1734430","NCS-FO: Collaborative Research: Relationship of Cortical Field Anatomy to Network Vulnerability and Behavior","BCS","IntgStrat Undst Neurl&Cogn Sys","09/01/2017","08/07/2017","Thomas Grabowski","WA","University of Washington","Standard Grant","Jonathan Fritz","08/31/2021","$849,938.00","Andrea Stocco, David Haynor","tgrabow@uw.edu","4333 Brooklyn Ave NE","Seattle","WA","981950001","2065434043","SBE","8624","8089, 8091, 8551","$0.00","Cognitive abilities such as memory and attention are supported by specialized brain networks made up of specific patches of the cerebral cortex called cortical fields. Cortical fields are thought to be anatomically distinct, with neurons connecting between them. Until recently, cortical fields could only be identified after death, by microscopic examination of autopsy brain tissue. Their number, function, and location in individual brains have been unknown.  Now however, Magnetic resonance imaging (MRI) can detect neural activity in the cerebral cortex with relatively high resolution, and diffusion MRI (dMRI) can detect white-matter fibers that connect brain regions. Networks made up of cortical fields become active when individuals accomplish a task, and also spontaneously, when the mind is ""at rest.""  We will use all this information to delineate the specific cortical fields in individual brains as well as patterns of connectivity between them. Cortical fields vary in size up to threefold from person to person, and we intend to study whether this variability is reflected in individual abilities or susceptibilities. The overarching goal is to test the idea that the size of cortical fields matters to the strength and vulnerability of brain networks. We use the MRI approaches outlined above to measure network strength, and we temporarily disrupt networks with transcranial magnetic stimulation (TMS) to assess network vulnerability. The work is important because it will allow us to better understand the reasons people have variable mental abilities. <br/><br/>The project focuses on two established brain networks: the default mode network (DMN) and the lateral frontoparietal network (LFPN), which have components in the inferior parietal lobes.  Connectivity-based parcellation distinguishes two angular gyrus fields, PgA and PgP, which are nodes within the LFPN and DMN networks, respectively. We will use dMRI to parcellate the cortex using a probabilistic parcel atlas of the Human Connectome Project data as prior information. Using functional connectivity, we will evaluate if PgP belongs to DMN, and PgA to LFPN. We will also analyze the strength of functional connectivity across network nodes in resting state fMRI using the dual-regression approach and ascertain the degree to which cortical field size variability across subjects is correlated with network-size variability. We will evaluate whether connectivity-defined cortical parcels maximize fMRI task contrast and show higher levels of EEG gamma and theta activities. Finally we relate the variability of cortical parcel size to task vulnerability by applying transcranial magnetic stimulations (TMS) to PgP and PgA. We hypothesize that low-frequency repetitive TMS (rTMS) over PgA will impair task performance on a working memory task and on a flanker task, and more so for individuals with smaller surface area of PgA. Furthermore, because endogenous reduction of DMN activity is associated with successful deployment of attentional resources, we also hypothesize that rTMS over DMN nodes will positively affect performance on the same tasks, and more so for individuals with smaller surface areas of these nodes.  This project is funded by Integrative Strategies for Understanding Neural and Cognitive Systems (NSF-NCS), a multidisciplinary program jointly supported by the Directorates for Computer and Information Science and Engineering (CISE), Education and Human Resources (EHR), Engineering (ENG), and Social, Behavioral, and Economic Sciences (SBE)."
"1912286","CRCNS Research Proposal: Understanding Cortical Networks Related to Speech Using Deep Learning on ECOG Data","IIS","CRCNS-Computation Neuroscience, Robust Intelligence, CCSS-Comms Circuits & Sens Sys, IntgStrat Undst Neurl&Cogn Sys","10/01/2019","04/09/2020","Yao Wang","NY","New York University","Standard Grant","Kenneth Whang","09/30/2022","$848,574.00","Adeen Flinker","yw523@nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","CSE","7327, 7495, 7564, 8624","7327, 8089, 8091, 9251","$0.00","Despite significant advances in neural science, the dynamics by which neural activity propagates across cortex while we think of a word and produce it remains poorly understood. This proposal will develop novel, data-driven approaches for understanding functions and interactions of various brain regions by leveraging rare neural recordings obtained with electrocorticography (ECoG) sensors while neurosurgical patients participate in tasks involving language perception, semantic access and word production.  This project will produce a set of validated novel computational tools for estimating neural representations and their dynamics as well as elucidate the cortical networks subserving perception, semantic access, and production of speech. Although these tools will be developed for ECoG data, the proposed frameworks are applicable to other neural data modalities including fMRI and EEG, and thus have broad applications in neuroscience. The ability to robustly translate between speech and its neural representations is vital to the development of speech prosthetics, which would allow patients with degenerative conditions (Amyotrophic Lateral Sclerosis) or neurological damage (locked-in syndrome) to drive a speech synthesizer via control from intact cortical structures. The network connectivity tools could shed light on the propagation dynamics of epileptic seizures as well as on how cortical communication, when impaired, gives rise to language aphasias and disconnection syndromes. Furthermore, the decoding and network connectivity tools could help develop novel language mapping approaches for brain surgery without the associated risks of electrical stimulation mapping.<br/><br/>The project consists of three core thrusts: developing neural decoders for language processing, developing directed connectivity models, and experimental validation. The neural decoders will be based on deep-learning architectures able to learn a transformation between neural signals and the speech heard by the patient, the speech produced by the patient, or the semantic concept represented by the stimulus word. The connectivity models will generalize and coalesce current approaches for estimating the task-dependent, time-varying directed connectivity between cortical regions. Lastly, these findings will be experimentally validated via clinical electrical stimulation data and cortico-cortico evoked potential (CCEP) stimulation experiments. Current modeling approaches of ECoG data have mostly focused on variants of linear models and on speech acoustics. This project will harness the potential of highly non-linear and deep networks for modeling neural responses to both speech acoustics and access to semantics. Additionally, tools for inferring direct connectivity and interactions among neural regions will provide a detailed characterization of the network dynamics, which is largely overlooked by most ECoG decoding studies.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1910473","AF: Small: Collaborative Research: A Computational Theory of Brain Function","CCF","Robust Intelligence, Algorithmic Foundations","10/01/2019","08/23/2019","Tatiana Aloi Emmanouil","NY","CUNY Baruch College","Standard Grant","A. Funda Ergun","09/30/2022","$98,807.00","Tony Ro","Tatiana.Emmanouil@baruch.cuny.edu","One Bernard Baruch Way","New York","NY","100105526","6463122211","CSE","7495, 7796","7923, 7927, 8089, 8091","$0.00","This project seeks to identify, explore, render rigorous, and validate one piece of the solution to the puzzle ""how does the brain work?"" - one of the truly fundamental and most challenging frontiers in all of science. Computation in the brain will be approached at an intermediate level of scale, far larger than that of individual neurons and synapses yet significantly smaller than that of the whole brain. The core hypothesis is that ""assemblies,"" large and highly interconnected sets of neurons, are the engine of brain computation. Studying computation at this level is crucial for understanding higher cognitive functions, especially in humans, such as reasoning, planning, and language; and this formulation of brain computation is particularly amenable to the methodology and point of view of the theory of computation, and will further its reach. This project is quintessentially interdisciplinary, and will provide multi-faceted training to graduate and undergraduate students in Computer Science Theory, Machine Learning, and Cognitive Neuroscience and Psychology. It will develop interdisciplinary graduate courses in this particular scientific interface. The results of the project will be disseminated broadly via conferences and journals in all these disciplines, but also in colloquia and public lectures, while students of a great variety of backgrounds will participate in a cutting-edge research experience.<br/> <br/>Assemblies can be the basis of a powerful computational system involving a repertoire of operations including project, associate, and merge. These operations can be shown, through theorems and simulations, to be plausible (that is, they can be ""compiled down"" to the level of neurons and synapses) and useful (in the sense that they can help explain extant experimental results). The project will pursue this assembly hypothesis through: (1) expanding our modeling and our mathematical techniques of analysis for the study of assembly computation; (2) developing more accurate and efficient simulation methodology; (3) embarking on a multi-pronged exploration of the computational power of assemblies in novel modalities beyond formal computation, in particular (a) probabilistic and dynamical systems-like computation through pattern completion and (b) learning and prediction; (4) mathematical modeling and algorithmic investigation of the ways in which the dynamics and biases of synaptic connectivity, as well as assembly overlap, affect the various modes of brain computation; and, importantly, (5) functional magnetic resonance imaging (fMRI) experiments, and the analysis of the results of these experiments and extant electrocorticography (ECoG) data through novel algorithmic and machine learning techniques for the purpose of identifying evidence of assembly computation in the human brain.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1920653","Collaborative Research: Measuring and Enhancing Scientific Creative Thinking for STEM Education and Research: Classroom-Aligned Assessment and Network Neuroscience-Based Mechanisms","DRL","ECR-EHR Core Research","09/01/2019","08/01/2019","Roger Beaty","PA","Pennsylvania State Univ University Park","Continuing Grant","Gregg Solomon","08/31/2022","$405,073.00","","rebeaty@psu.edu","201 Old Main","University Park","PA","168021503","8148651372","EHR","7980","7261, 8089, 8091, 8817","$0.00","This collaborative award to research teams at Pennsylvania State University, Georgetown University, and Johns Hopkins University will focus on creative thinking in STEM education and research.  Creative thinking is critical for success in STEM fields, which often require generating novel hypotheses, flexibly connecting diverse information, and envisioning solutions to ill-defined problems. Creative innovation is a valuable attribute of the U.S. workforce in the global economy, and the ability to maximize the nation's creative potential is projected to become even more essential for opportunity as creativity emerges as the human ability least achievable by artificial intelligence. The increasing value of creative thinking for STEM coincides with new applications of neuroscience methods that have the potential to predict, and perhaps even to enhance, creativity. Yet creativity is an under-researched contributor to STEM success. Indeed, there is not currently a measure of scientific creative thinking that educators can use to reliably determine what works (and what does not) in STEM education to foster creative thinking. This project will bring together a research team that represents an uncommon bridging of neuroscience and classroom-focused expertise. They will work with middle school and university educators to develop a new measure of scientific creative thinking and to use new neuroscientific tools to test whether a brain network that predicts an individual's general capacity for creative thinking can also predict their ability to think creatively with scientific content beyond what can be explained by their baseline cognitive ability. By testing whether neural data add value to traditional academic measures in predicting students' future creative thinking and STEM performance, this project will inform timely debates on the value of neuroscience for education. This work will also bridge the laboratory and the classroom in novel ways by longitudinally measuring change in brain network strength associated with of real-world STEM learning. By providing foundational knowledge on the nature and measurement of scientific creative thinking, the project will inform educational efforts to promote creative thinking in the classroom. This project will have additional impacts for broadening participation in STEM Fields by working with teachers of minority student populations underrepresented in STEM fields to optimize classroom usability for a test of scientific creative thinking. The project is funded by the EHR Core Research (ECR) program, which supports work that advances the fundamental research literature on STEM learning. The project directly fits the intent of ECR to facilitate the development, refinement, and testing of new education research, measurement, and evaluation methodologies.<br/><br/><br/>This project aims to provide foundational knowledge on the cognitive and neural basis of scientific creative thinking. To this end, we will collaborate with educators to develop and psychometrically validate a new test of scientific creative thinking, assessing students' ability to generate novel hypotheses, research questions, and experimental designs. We will also leverage developments in the network neuroscience of domain-general creativity, including the recent discovery of a specific network of brain regions in which functional connectivity strength can predict an individual's creative performance. Specifically, the project will 1) construct a new assessment of scientific creative thinking, incorporating classroom-usability (working with STEM teachers in urban Baltimore) and expanded psychometric scale development, and 2) use functional magnetic resonance imaging (fMRI) to extend our recent findings on the functional brain networks that support domain-general creativity to identify neural overlap/distinctness between domain-general and scientific creativity, and longitudinally to test whether strength of neural networks adds value to standard academic measures (e.g., grades) in predicting future creative thinking and STEM performance. This study will also provide the first large-scale analysis of cognitive and affective traits that support scientific creative thinking in STEM undergraduates, as well as preliminary data on whether network neuroscience methods developed in the lab can be used to measure neural strengthening of creative thinking ability through real-world STEM learning.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1910700","AF: Small: Collaborative Research: A Computational Theory of Brain Function","CCF","Robust Intelligence, Algorithmic Foundations","10/01/2019","08/23/2019","Christos Papadimitriou","NY","Columbia University","Standard Grant","A. Funda Ergun","09/30/2022","$200,000.00","","cp3007@columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","CSE","7495, 7796","7923, 7927, 8089, 8091","$0.00","This project seeks to identify, explore, render rigorous, and validate one piece of the solution to the puzzle ""how does the brain work?"" - one of the truly fundamental and most challenging frontiers in all of science. Computation in the brain will be approached at an intermediate level of scale, far larger than that of individual neurons and synapses yet significantly smaller than that of the whole brain. The core hypothesis is that ""assemblies,"" large and highly interconnected sets of neurons, are the engine of brain computation. Studying computation at this level is crucial for understanding higher cognitive functions, especially in humans, such as reasoning, planning, and language; and this formulation of brain computation is particularly amenable to the methodology and point of view of the theory of computation, and will further its reach. This project is quintessentially interdisciplinary, and will provide multi-faceted training to graduate and undergraduate students in Computer Science Theory, Machine Learning, and Cognitive Neuroscience and Psychology. It will develop interdisciplinary graduate courses in this particular scientific interface. The results of the project will be disseminated broadly via conferences and journals in all these disciplines, but also in colloquia and public lectures, while students of a great variety of backgrounds will participate in a cutting-edge research experience.<br/> <br/>Assemblies can be the basis of a powerful computational system involving a repertoire of operations including project, associate, and merge. These operations can be shown, through theorems and simulations, to be plausible (that is, they can be ""compiled down"" to the level of neurons and synapses) and useful (in the sense that they can help explain extant experimental results). The project will pursue this assembly hypothesis through: (1) expanding our modeling and our mathematical techniques of analysis for the study of assembly computation; (2) developing more accurate and efficient simulation methodology; (3) embarking on a multi-pronged exploration of the computational power of assemblies in novel modalities beyond formal computation, in particular (a) probabilistic and dynamical systems-like computation through pattern completion and (b) learning and prediction; (4) mathematical modeling and algorithmic investigation of the ways in which the dynamics and biases of synaptic connectivity, as well as assembly overlap, affect the various modes of brain computation; and, importantly, (5) functional magnetic resonance imaging (fMRI) experiments, and the analysis of the results of these experiments and extant electrocorticography (ECoG) data through novel algorithmic and machine learning techniques for the purpose of identifying evidence of assembly computation in the human brain.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1835279","NCS-FO: Spatial Intelligence for Swarms Based on Hippocampal Dynamics","IIS","IntgStrat Undst Neurl&Cogn Sys","10/01/2018","07/28/2020","Kechen Zhang","MD","Johns Hopkins University","Standard Grant","Kenneth Whang","09/30/2021","$997,996.00","Grace Hwang, Marvin Carr, Kevin Schultz, Robert Chalmers, Joseph Monaco","kzhang4@jhmi.edu","1101 E 33rd St","Baltimore","MD","212182686","4439971898","CSE","8624","8089, 8091, 8551","$0.00","This project brings together theories of brain functions and principles of robotic swarm control to develop smarter swarms and to better understand the neural processes underlying spatial representations, navigation, and planning. Our world is constantly changing, and mammals have evolved the cognitive ability to plan new paths or new strategies as needed. By contrast, autonomous robots are less robust, and often have difficulty operating in complex, changing environments. This research project is grounded in the idea that individual robots in a group can be thought of analogously to neurons in an animal's brain, which interact with one another to form dynamic patterns that collectively signal locations in space and time relative to brain rhythms. This distribution of information across space and time will enable a new paradigm of swarm control, in which swarms automatically adapt to changes in the world in the same way that a rat knows which detour to take around an unexpected obstacle. Unmanned robots are rapidly becoming a crucial technology for commercial, military, and scientific endeavors throughout the nation and across the globe. Critical future applications such as disaster relief and search & rescue will require intelligent spatial coordination among many robots spread over large geographical areas. This project will advance neural swarming as a control paradigm for this next generation of technological development. Additionally, this project will drive an extensive science, technology, engineering, and mathematics education program to bring the concepts of spatial intelligence, hippocampal information processing, and swarm control to high school students to improve literacy in neuroscience and robotics.<br/><br/>The project's goal is to build a unified framework for self-organized, bottom-up control of spatial task planning that synergistically advances theoretical neuroscience and swarm control paradigms. In the project's brain-to-swarm metaphor, neurons are autonomous agents, spikes are agent-based phase signals, and emergent circuit activity is emergent swarm behavior. The approach targets neural computations in hippocampal circuits and related systems that may contribute to online dynamic replanning. The research thrusts comprise data-driven dynamical network and point-process models of neural activity sequences, mathematical analysis of swarming dynamics using matrix manifolds, and autonomous systems simulations in realistic virtual environments. The project will advance understanding of emergent hippocampal dynamics and autonomous methods for dynamic replanning, motivating new research in distributed control. The project's framework may enable mass-scalability for large, agile swarms of simple robotic agents.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1631912","NCS-FO: Collaborative Research: Rebuilding neural pathway function using miniature integrated optics for neuron-level readout and feedback","CBET","IntgStrat Undst Neurl&Cogn Sys","08/01/2016","08/09/2016","Emily Gibson","CO","University of Colorado at Denver-Downtown Campus","Standard Grant","Christina Payne","07/31/2021","$600,000.00","Diego Restrepo","Emily.Gibson@ucdenver.edu","F428, AMC Bldg 500","Aurora","CO","800452571","3037240090","ENG","8624","8089, 8091, 8551","$0.00","1631912/1631704<br/>Gibson/Gopinath<br/><br/>Development of a miniature implantable device to allow transfer of neural information from one brain area to another will have a major impact on the understanding of brain function and will be applicable to treatment of brain disease. The proposed research spans neuroscience, materials science, physics and engineering, and will provide excellent interdisciplinary research opportunities for students. Dissemination of the work will occur through teaching, additional educational outreach, opportunities for undergraduates, and journals and conference publications. The capability of this research to develop an optical feedback control to repair brain function will captivate these future scientists. <br/><br/>Non-invasive feedback control to repair brain function is one of the ultimate goals in neuroscience. The recent and evolving development of genetically encoded fluorescent indicators and optogenetics makes optical readout and control a real possibility.  However, there is still a critical need to understand how an optical feedback system can fully recover function in an awake behaving animal. This proposal seeks to demonstrate for the first time the actual recovery of function in an awake-behaving animal using an engineered optical feedback system.  The project will be performed by a highly interdisciplinary team with extensive expertise in neuroscience, optogenetics, and cognitive research in awake behaving animals along with experts in optical and MEMS devices.  The proposal combines the technology development side with behavioral research with the potential for major discoveries. Unprecedented progress in the study of brain function will be enabled with the proposed device. The PIs have recently developed technology for a lightweight head-mounted miniature multiphoton microscope that can image over hundreds of neurons in three dimensions in brain tissue.  The technology is the first to use electrowetting optics for non-mechanical steering of the excitation laser and enables single cell resolution imaging.  We propose to combine a spatially shaped second laser at a different wavelength from our excitation laser to allow both imaging and directed optogenetic stimulation of neurons.  Importantly, modulation of neural activity on the level of individual neurons is essential for controlling function in the brain.  Therefore readout and control by optics has a real potential to restore function as opposed other methods such as ultrasound, EEG, and fMRI that are theoretically limited in spatial resolution.  We propose to readout and control firing of individual neurons in the piriform cortex using a real-time feedback control system. We will use behavior studies in mice to determine if association of olfactory identity with reward can be recovered as we selectively turn on and off the input nerve connections to the piriform cortex where odor identity is thought to be represented. The study will allow us to identify which neurons contain information essential for decision making. The oscillatory basis for information transfer can be tested using certain frequency ranges or phases of neural activity. These studies will be useful for testing models of neural circuit function and applicable for neuroengineering devices for therapeutic use."
"1839308","TRIPODS+X:RES: Investigations at the Interface of Data Science and Neuroscience","CCF","TRIPODS Transdisciplinary Rese, OFFICE OF MULTIDISCIPLINARY AC, Cognitive Neuroscience, IntgStrat Undst Neurl&Cogn Sys","10/01/2018","09/10/2018","Nicholas Turk-Browne","CT","Yale University","Standard Grant","Christopher Stark","09/30/2021","$599,992.00","Jeffrey Brock, Damon Clark, John Lafferty","nicholas.turk-browne@yale.edu","Office of Sponsored Projects","New Haven","CT","065208327","2037854689","CSE","041Y, 1253, 1699, 8624","047Z, 062Z, 8089, 8091","$0.00","This project will build a transformative bridge between data science and neuroscience. These two young fields are driving cutting-edge progress in the technology, education, and healthcare sectors, but their shared foundations and deep synergies have yet to be exploited in an integrated way - a new discipline of ""data neuroscience."" This integration will benefit both fields: Neuroscience is producing massive amounts of data at all levels, from synapses and cells to networks and behavior. Data science is needed to make sense of these data, both in terms of developing sophisticated analysis techniques and devising formal, mathematically rigorous theories. At the same time, models in data science involving AI and machine learning can draw insights from neuroscience, as the brain is a prodigious learner and the ultimate benchmark for intelligent behavior. Beyond fundamental scientific gains in both fields, the project will produce additional outcomes, including: new collaborations between universities, accessible workshops, graduate training, integration of undergraduate curricula in data science and neuroscience, research opportunities for undergraduates that help prepare them for the STEM workforce, academic-industry partnerships, and enhanced high-performance computing infrastructure.<br/><br/>The overarching theme of this project is to develop a two-way channel between data science and neuroscience. In one direction, the project will investigate how computational principles from data science can be leveraged to advance theory and make sense of empirical findings at different levels of neuroscience, from cellular measurements in fruit flies to whole-brain functional imaging in humans. In the reverse direction, the project will view the processes and mechanisms of vision and cognition underlying these findings as a source for new statistical and mathematical frameworks for data analysis. Research will focus on four related objectives: (1) Distributed processing: reconciling work on communication constraints and parallelization in machine learning with the cellular neuroscience of motion perception to develop models of distributed estimation; (2) Data representation: examining how our understanding of the different ways that the brain stores information can inform statistically and computationally efficient learning algorithms in the framework of exponential family embeddings and variational inference; (3) Attentional filtering: incorporating the cognitive concept of selective attention into machine learning as a low-dimensional trace through a high-dimensional input space, with the resulting models used to reconstruct human subjective experience from brain imaging data; (4) Memory capacity: leveraging cognitive studies and natural memory architectures to inform approaches for reducing/sharing memory in artificial learning algorithms. The inherently cross-disciplinary nature of the project will provide novel theoretical and methodological perspectives on both data science and neuroscience, with the goal of enabling rapid, foundational discoveries that will accelerate future research in these fields.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1640800","SL-CN: Understanding and Promoting Spatial Learning Processes in the Geosciences","SMA","Science of Learning, ECR-EHR Core Research","09/01/2016","08/11/2016","Thomas Shipley","PA","Temple University","Standard Grant","Soo-Siang Lim","08/31/2021","$749,712.00","Nicole LaDue, Doug Lombardi, Alexandra Davatzes","TSHIPLEY@temple.edu","1801 N. Broad Street","Philadelphia","PA","191226003","2157077547","SBE","004Y, 7980","1545, 8089, 8091","$0.00","This Science of Learning Collaborative Network of cognitive psychologists, education researchers, and geoscience educators from Temple University, Carleton College, and Northern Illinois University focuses on spatial learning.  The team will develop new spatial learning principles by designing teaching tools that can be applied across classroom and field courses in the geosciences - a field of science that depends very heavily on spatial skills and spatial reasoning. The tools will be designed to allow students to self-correct conceptual errors in their understanding of scientific concepts, and will be made available through a project web site.  Courses on using the tools will also be offered at meetings of geoscience professionals and teachers.  The research will expand fundamental understanding of the science of learning by characterizing the different types of spatial reasoning that are required for the practice of a complex spatial science. The research will develop new supports for spatial learning challenges that have been barriers for student learning.  The findings could ultimately improve retention and learning in geosciences and in many other Science, Technology, Engineering and Mathematics (STEM) domains that depend on spatial thinking.<br/> <br/>Spatial thinking plays a critical role in STEM-related course achievement. Supporting the development of spatial thinking in a science curriculum requires an interdisciplinary effort that combines knowledge of the specific disciplinary science with education and psychology expertise.  This collaborative network will develop two new fundamental and complementary spatial learning principles.  One is spatial feedback, which is feedback in the form of a spatial error that allows the mind and brain to guide learning. Providing feedback about spatial information is essential to supporting learning about complex spatial concepts across the geosciences.  The other is spatial accommodation, which is the constructing and reconstructing of mental models to accurately incorporate spatial information to improve inaccurate mental models from spatial feedback. The network will create a ""trading zone"" where theory and practice converge so that research on education and cognitive psychology can be influenced by disciplinary geoscience content, and vice versa.  The expected results include new designs for teaching tools and new insights into the working of the human mind and brain.<br/><br/>The award is from the Science of Learning-Collaborative Networks (SL-CN) Program, with funding from the SBE Division of Behavioral and Cognitive Sciences (BCS), the SBE Office of Multidisciplinary Activities (SMA), and the EHR Core Research (ECR) Program."
"2011514","CRCNS US-Spain Research Proposal: Serial dependence in working memory","IIS","CRCNS-Computation Neuroscience, IntgStrat Undst Neurl&Cogn Sys","01/01/2021","10/19/2020","Christos Constantinidis","NC","Wake Forest University School of Medicine","Standard Grant","Jonathan Fritz","12/31/2023","$670,680.00","","cconstan@wfubmc.edu","Medical Center Blvd","Winston-Salem","NC","271571023","3367162382","CSE","7327, 8624","7327, 8089, 8091","$0.00","Working memory, the ability to retain and manipulate information over a period of seconds, represents a core component of higher cognitive functions, including language, problem solving, reasoning, and abstract thought. Working memory capacity accounts for a great proportion of individual variability in academic performance, and it is impaired in clinical conditions including schizophrenia, stroke, traumatic brain injury, and ADHD. Understanding the neural basis of working memory has been a question in the forefront of scientific research over the past few years. This project relies on an ?imperfection? of working memory, serial dependence: the contents of memory in a previous trial often affect what is being recalled in a following one, even though this is no longer useful. Serial dependences can provide insight into cellular mechanisms and neurotransmitter systems. Patients with genetic conditions such as schizophrenia, autism, and encephalitis exhibit different patterns of serial dependence. This project forms a collaborative experimental and theoretical approach to understand the role of different neurotransmitter systems and brain areas in serial dependence, which will reveal fundamental properties of the circuits that mediate working memory. Beyond the immediate goals of the experiments, understanding the neural basis of working memory and developing mechanistic models that capture its properties is expected to have broader impacts on a number of scientific fields, including neuroscience, psychology, cognitive science, computer science, and machine learning. The combined experimental-modeling approach has also direct relevance to understanding and treating these clinical conditions. The approach opens new avenues of model-guided research in neuropsychiatric conditions and enhances the reach of computational psychiatry.<br/><br/>Working memory has been linked to the prefrontal cortex, an area central to cognitive processing, with unique anatomical and cellular organization. NMDA receptors, which are abundant in the prefrontal cortex, are suspected to play a critical role for the maintenance of information in working memory, by virtue of their ability to maintain neurons at an excited state for an extended period of time, and to induce plasticity of synaptic connections. Direct evidence linking their cellular role to working memory behavior has been scant, however. This project will address the circuit mechanisms by which NMDA receptors support working memory function. We will rely on a novel approach, by investigating the mechanisms of history biases, as a manifestation of long-lasting NMDAR-dependent mechanisms in working memory. Serial dependencies are systematically affected in patients with schizophrenia and anti-NMDAR encephalitis, suggesting an underlying NMDAR-dependent mechanism. Experiments will train non-human primates to perform spatial working memory tasks; obtain single neuron neurophysiological recordings and local field potentials from dorsolateral prefrontal and posterior parietal cortex; administer NMDAR antagonists systemically; and use optogenetic cortical stimulation to test behavioral and physiological predictions of a computational model of serial biases. Analysis of neural data and computational modeling will integrate the results of the experiments in a fronto-parietal network model. This will shed light on the role of prefrontal NMDA receptors in shaping history-dependent biases, and the importance of local-circuit (intrinsic) connections and long-range connections. Specifying subunit-specific NMDAR mechanisms, and the role of the fronto-parietal network, will inform a new computational framework with biophysical detail and enhanced predictive power for subsequent experimentation. The project is expected to advance understanding of cognitive processes and the neural networks mediating them. <br/><br/>A companion project is being funded by the National Institute of Health Carlos III, Spain (ISCIII).<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2024418","NCS-FO: SOUND: Understanding the Functional Neural Dynamics Underpinning Auditory Processing Dysfunctions through a Multiscale Recording-Stimulation Framework","CBET","IntgStrat Undst Neurl&Cogn Sys","10/01/2020","10/13/2020","Yalda Shahriari","RI","University of Rhode Island","Standard Grant","Jonathan Fritz","09/30/2023","$499,888.00","Ming Shao, Kevin Spencer","yalda_shahriari@uri.edu","RESEARCH OFFICE","KINGSTON","RI","028811967","4018742635","ENG","8624","8089, 8091, 8551, 9150","$0.00","Auditory processing dysfunction (APD) is a common feature of many types of psychosis, including schizophrenia, and is associated with multiple core symptoms, including auditory verbal hallucinations (i.e. hearing voices). Despite APD?s high prevalence, affecting up to 80% of the psychotic population, pharmaceutical therapy is ineffective: 70% of patients either have undesirable side effects or experience persistent symptoms despite treatment. A non-pharmacological treatment strategy, such as neuromodulation (targeted stimulation of nerves), would meet an important medical need. Although neuromodulation has recently emerged as a plausible therapeutic tool for a range of neuropsychological conditions, little is understood of the abnormal neural patterns underlying APD. This project will utilize an innovative framework, integrating multiscale recording and stimulation, to explore APD and to elucidate its underlying mechanisms. The project unites a multidisciplinary team of researchers, including experts in neural signal processing, neuroscience, psychiatry, and deep learning. The proposed work will develop computational, data-driven approaches in real-world settings. These will investigate multimodal signals with distinct spatiotemporal properties, integrated with a neuroimaging study of psychosis with APD. In addition to the scientific impacts of this proposal, the proposed work will advance national health by addressing multiple existing gaps in neuroscience and psychiatry. The educational and outreach plans will provide training opportunities for women and under-represented minoroties, promoting STEM diversity in the Northeastern United States.<br/><br/>This project has three main thrusts. All of the proposed frameworks are data-driven and will be tested on healthy controls and patients with schizophrenia, in whom APD is a core feature. The first thrust will develop a computational statistical approach to quantify hierarchical couplings between hemodynamic infra-slow oscillations (using fNIRS), and electrical high-frequency oscillations (using EEG), through a nested multimodal approach in auditory task-related settings. The second thrust introduces an innovative multimodal data fusion approach to exploit complementary strengths from electrical and vascular dynamics, toward an integrative understanding of APD. This will enable identification of across-subject and within-subject signals underlying APD. The third thrust will extent beyond functional investigations and into causal dynamics across large-scale networks. The research will develop fused causal models, to identify subject-specific causal patterns of APD, and to create individualized spatial target mapping for optimal site stimulation. The precise locations of aberrant causal patterns will be targets for transcranial direct-current stimulation (tDCS). Project outcomes include the introduction of an innovative computational data fusion approach to bridge distinct spatiotemporal scales; discovery of latent signatures and causal patterns of APD through novel neural information processing; insight into APD hierarchical mechanisms, and understanding of the cortical modulatory properties of APD.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1926781","NCS-FR: Protecting the Aging Brain: Self-Organizing Networks and Multi-Scale Dynamics under Energy Constraints","IIS","ECR-EHR Core Research, IntgStrat Undst Neurl&Cogn Sys","10/01/2019","09/04/2019","Lilianne Mujica-Parodi","NY","SUNY at Stony Brook","Standard Grant","Jonathan Fritz","09/30/2022","$2,500,000.00","Steven Skiena, Ken Dill, Nathan Smith, Eva-Maria Ratai","lilianne.strey@stonybrook.edu","WEST 5510 FRK MEL LIB","Stony Brook","NY","117940001","6316329949","CSE","7980, 8624","8089, 8091, 8551","$0.00","The brain's ability to use energy has been strongly implicated in age-based cognitive impairment, which will dramatically affect a disproportionally aging demographic. Globally, the number of adults aged 65 or older is estimated to more than double by 2030, with dementia rates exponentially increasing from 1-2% of the population for those age 65, to 58% for those age 94.  This project probes the hypothesis that age-based cognitive impairment reflects insulin resistance (Type 2 diabetes) within the brain, limiting neurons' access to blood sugar, and tests whether one can reverse aging effects through the use of an alternative brain fuel:  ketones.  <br/><br/>This project addresses individuality and variation, leveraging the interdisciplinary team's expertise in neuroscience, statistical physics, and machine learning, to tackle one of neurobiology's most fundamental unanswered questions: what are the ""rules"" by which the brain self-organizes in response to resource constraints? Unifying the project across scales and disciplines is a computational model designed to predict single-subject network trajectories in response to tightening and releasing of energy constraints, a first step towards understanding individuality and variation in brain aging. The project team have previously shown that aging is associated with destabilization of brain networks, an effect that the team's preliminary results suggest can be modulated by switching neuro-metabolism from glucose to ketones. Others have shown that age-based cognitive deterioration accelerates with insulin resistance. Thus, the team hypothesizes that network destabilization may result from reorganization as the brain attempts to optimize networks to conserve energy in response to neuron insulin-resistance. Using insulin resistance to tighten energy constraints and ketones to release them, the team plans to use animal (DREADD/patch-clamp/calcium imaging) and human (31P/1H-MRS, 7T fMRI) data to characterize changes in excitatory/inhibitory neuron firing dynamics and their implications for connectivity. Techniques adapted from ""optimization under constraint"" problems in statistical physics (e.g., Maximum Caliber) will then be applied to these data to identify cellular automaton-like ""rules"" that neurons might follow in guiding emergent self-organization. In so doing, the project considers optimization based upon biological principles as well as developing generative techniques for identifying constraints unbiased by the a priori hypotheses. Using an iterative approach, in which each individual subject's network trajectory provides feedback, informing the models, which then make predictions that are tested against the next individual's data, models will eventually converge in predicting human network trajectories based upon individually variable parameters.  These would provide first steps towards personalized neurology, by being able to simulate - for a single individual - the potential consequences of different initial conditions and/or clinical interventions.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1734795","NCS-FO:   Collaborative Research:  Seizure control through state-specific manipulation of cell assemblies","SMA","IntgStrat Undst Neurl&Cogn Sys","08/01/2017","07/05/2017","Sarah Muldoon","NY","SUNY at Buffalo","Standard Grant","Jonathan Fritz","07/31/2021","$237,000.00","","smuldoon@buffalo.edu","520 Lee Entrance","Buffalo","NY","142282567","7166452634","SBE","8624","8089, 8091, 8551","$0.00","How activity of individual brain neurons results in the emergence, spread, and eventual termination of seizures is a basic and unsolved issue. Extensive research has examined brain activity during seizures using invasive and non-invasive tools, but there is a gap in our understanding of the cellular-level basis of large-scale phenomena such as seizures. Here, Dr. Sarah F. Muldoon (University at Buffalo, SUNY) and Dr. Ethan M. Goldberg (The Children's Hospital of Philadelphia and The University of Pennsylvania) use methods for recording neural activity from multiple single neurons in mice, as well as methods for recording large-scale neuroelectric activity (EEG), to identify groups of neurons whose activity is associated with time-evolving features of seizures. This project combines newly developed theoretical and computational neuroscience approaches with state-of-the art experimental techniques for imaging and manipulating brain activity. It evaluates a novel hypothesis that transitions to seizure onset and between seizure sub-states represent changes in the activity of small, identifiable clusters of neurons, and that such clusters can be identified and manipulated to modulate seizures. This multidisciplinary collaborative approach is expected to produce novel insights into the mechanisms of seizure generation and propagation, inform novel treatments for epilepsy, and provide a framework generalizable to larger efforts to link data related to changes in brain state across scales.<br/><br/>Recent work suggests a fine-grained and evolving heterogeneity in individual neuronal dynamics during seizures. However, relatively little is known about the relationship between single neuron activity and large-scale seizure dynamics. Here, we combine multilayer network theory with two-photon calcium imaging in an experimental in vivo epilepsy model to identify functional cell assemblies (small groups of neurons with similar, functionally-relevant activity patterns) associated with transition to and between seizure states. We characterize the ability of defined subsets GABAergic inhibitory interneurons to impact cell assembly dynamics, using optogenetics to manipulate interneurons to interrupt transition to seizure. The overall goal of this proposal is to develop a means for rapid detection of spatially- and functionally-defined neuronal assemblies associated with these sub-state transitions so as to predict and manipulate such transitions. The results will provide the first large-scale imaging data on the cellular architecture of epileptic seizures in vivo as well as a set of novel tools for the analysis of such data. This work will lead to the development of neural control strategies designed to specifically target subpopulations of neurons that have been functionally identified as key elements in driving epileptic dynamics.<br/><br/>This project is funded by Integrative Strategies for Understanding Neural and Cognitive Systems (NSF-NCS), a multidisciplinary program jointly supported by the Directorates for Computer and Information Science and Engineering (CISE), Education and Human Resources (EHR), Engineering (ENG), and Social, Behavioral, and Economic Sciences (SBE)."
"1748377","CAREER: New Learning-based Algorithms for the Analysis of Very-Large-Scale Neuroimaging Data","IIS","Robust Intelligence, IntgStrat Undst Neurl&Cogn Sys","10/01/2018","09/08/2018","Mert Sabuncu","NY","Cornell University","Standard Grant","Kenneth Whang","09/30/2023","$581,438.00","","ms3375@cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","CSE","7495, 8624","075Z, 1045, 7495, 8089, 8091","$0.00","Artificial intelligence, fueled by recent advances in machine learning, is poised to transform healthcare and biomedical research. Machine learning algorithms allow researchers to analyze complex patterns in large datasets, in the service of advancing our understanding of biological mechanisms and developing clinical tools. This project considers very large scale brain imaging studies, including, for example, tens of thousands of individuals contributing head MRI scans and other biomedical data such as whole-genome sequences or clinical records. Such data allow researchers to map the effects of genetic, environmental, and other factors on the structure and function of the brain, which in turn advances our knowledge of disorders like Alzheimer's. Today, the primary obstacle in exploiting very large scale brain imaging datasets is computational, because existing software tools don't scale well and lack in quality assurance capabilities. This project will produce a machine-learning based computational pipeline that will fill this gap. In the largest study of its kind, we will showcase the developed software tools to chart the heritability of shapes of brain structures.  In addition, the project will implement a diverse set of educational outreach initiatives, such as a customized research experience for under-represented minority high-school students.   <br/><br/>Neuroimaging is entering a new era of unprecedented scale and complexity. Soon, we will have datasets including more than 100,000 individuals. The fundamental challenge in analyzing and exploiting these data is computational. Today, widely-used neuroimage analysis tools are computationally demanding, produce results that are sensitive to confounds, and are limited in quality control capabilities, making them infeasible at scale. This project will extend recent advances in machine learning to develop an innovative computational pipeline that addresses the drawbacks of existing methods. First, a computationally efficient and flexible brain MRI segmentation framework will be developed that integrates rich neuroanatomical prior models. The segmentation tool will be made robust to confounding effects such as subject motion via the use of an adversarial learning strategy. Learning-based methods will be further investigated to obviate the time-consuming manual quality control of segmentations. Finally, an innovative metric learning approach will be used to study genetic influences on brain morphology in the UK Biobank. The project will also implement an integrated educational plan that is focused on interdisciplinary, hands-on and lifelong learning. The researchers will devote significant effort to developing core educational material that will be adapted and utilized for audiences of various backgrounds and stages.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1849946","CRII: RI: Neuromodulated Deep Vision: Continual Learning and Goal-Oriented Adaptation","IIS","Robust Intelligence, IntgStrat Undst Neurl&Cogn Sys","10/01/2019","08/30/2019","Rolando Estrada","GA","Georgia State University Research Foundation, Inc.","Standard Grant","Kenneth Whang","09/30/2021","$175,000.00","","restrada1@gsu.edu","58 Edgewood Avenue","Atlanta","GA","303032921","4044133570","CSE","7495, 8624","7495, 8089, 8091, 8228","$0.00","Deep neural networks are revolutionizing many fields and industries. These systems can learn to solve problems ranging from parsing natural language to discovering new drugs. However, current networks can only solve individual, static problems; they cannot learn gradually over time or adapt their computations in real time. This project seeks to bridge the gap between human and machine intelligence by modeling a chemical process in the brain that help humans learn and adjust their behavior based on context. Specifically, the chemical acetylcholine (ACh) has been shown to modulate responses to visual stimuli by selectively raising or lowering the activity level of individual neurons. This chemical is also crucial for visual learning in infants. An insufficient concentration of ACh in the brain leads to poor visual attention and has also been linked to memory deficits and Alzheimer?s disease. Thus, adding ACh-like mechanisms to deep neural networks can potentially allow them to learn over time and adapt their behavior to rapidly changing conditions--a growing need in domains ranging from forest conservation to cybersecurity.<br/><br/>In more detail, deep convolutional neural networks (CNNs) are the state-of-the-art approach for a wide variety of image processing tasks, such as object recognition and semantic segmentation. This project will investigate how to add ACh-like regulation to CNNs by modeling the spatial and temporal dynamics of this chemical process. Specifically, the CNN will be connected to a set of spatially and temporally heterogeneous sources of modulation. Each neuron in the CNN will have different receptors that determine how that particular neuron responds to different ambient levels of ACh. The system will use two controllers: one to determine the current level of ACh across different parts of the network and another to set the correct context (i.e., to model top-down feedback from higher cortical areas). The first controller will allow the system to quickly adjust its behavior, while the second will enable long-term learning. This project constitutes an initial step in developing intelligent systems that, like biological organisms, can autonomously cope with changing, dynamic environments. In addition to its technical contributions, this project will allow students at Georgia State University, one of the most diverse institutions in the country, to foster interdisciplinary connections between artificial intelligence, neuroscience, and related STEM disciplines.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1631428","NCS-FO: Collaborative Research: Operationalizing Students' Textbooks Annotations to Improve Comprehension and Long-Term Retention","DRL","ECR-EHR Core Research, IntgStrat Undst Neurl&Cogn Sys","09/01/2016","05/10/2017","Michael Mozer","CO","University of Colorado at Boulder","Standard Grant","Gregg Solomon","08/31/2021","$307,176.00","","mozer@cs.colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","EHR","7980, 8624","8089, 8091, 8551, 8816, 8817, 9251","$0.00","While traditional textbooks are designed to transmit information from the printed page to the learner, contemporary digital textbooks offer the opportunity to study learners as they interpret and process information being read. With a better understanding of a learner's state of mind, textbooks can make personalized recommendations for further study and review. How can the learner's state of mind be determined? Open a used printed textbook and the answer is clear: students feel compelled to engage with their texts by annotating key passages with highlights, tags, questions, and notes. Despite students' spontaneous desire to annotate as they read, this form of interaction has reaped few educational benefits in the past. At best, highlighted passages are re-read to study for exams, a strategy not nearly as effective as other strategies such as self-quizzing. This project will develop a new methodology that: assesses student knowledge level automatically based on annotations, transforms highlighted passages into appropriate study questions, and provides each student with well-timed, personalized review. Because the project is based on free, peer-reviewed, openly licensed materials from OpenStax that have been widely adopted at a range of institutions, particularly community colleges, the technology will reach beyond elite institutions to provide a broad spectrum of underserved students with access to a potentially powerful learning tool.<br/><br/>This project adopts a big-data approach that involves collecting annotations from a population of learners to draw inferences about individual learners. The project will determine how to exploit these data to model cognitive state, enabling the team to infer students' depth of understanding of facts and concepts, predict subsequent test performance, and perform interventions that improve learning outcomes. A tool will be developed that administers appropriately timed quizzes on material related to a student's highlights. A collaborative-filtering methodology will be employed that leverages population data to suggest specific passages for an individual to review. The proposed tool will reformulate selected passages into review questions that encourage the active reconstruction and elaboration of knowledge. The design and implementation of the tool will be informed by both randomized controlled studies within the innovative OpenStax textbook platform and coordinated laboratory studies. These studies will address basic scientific questions pertaining to why students annotate, how to improve their annotation skills, and techniques to optimize the use of annotations for guiding active review."
"1724218","CRCNS Research Proposal: Collaborative Research: Studying Competitive Neural Network Dynamics Elicited By Attractive and Aversive Stimuli and their Mixtures","EF","Cross-BIO Activities, CRCNS-Computation Neuroscience","09/01/2017","07/25/2018","ShiNung Ching","MO","Washington University","Continuing Grant","Edda Thiels","08/31/2021","$469,503.00","Baranidharan Raman","shinung@ese.wustl.edu","CAMPUS BOX 1054","Saint Louis","MO","631304862","3147474134","BIO","7275, 7327","1228, 7327, 8089, 8091, 9150, 9178, 9179","$0.00","This award supports basic research regarding the question of how networks in the brain allow odors to be detected and perceived.  Such a question is of fundamental interest in neuroscience because responding to odors or scents is one of the most basic ecological abilities exhibited across different animal species.  Further, responses to odors are highly dependent on context.  For example, certain smells may create both attractive and repulsive reactions, depending on small differences in dilution or whether they are encountered alone or as components in a cocktail.  Thus, studying how the brain processes odors can provide important clues regarding how animals and humans sense and perceive in complex environments.  In seeking such understanding, this project uses a unique combination of methods from neuroscience, mathematics, and engineering.  Brain activity from two different animal species are recorded during experiments in which odors are presented in isolation and in mixtures.  Subsequently, data analysis and mathematical modeling is used to identify brain activity patterns that distinguish the reaction of the animals to the odors in question.  Hence, the project uncovers how particular brain networks transform and transmit odor information in a way that is central to the sense of smell.  To broaden the impact of these studies, the project includes the development of a summer internship in sensory neural engineering, intended to allow undergraduate and high school students to learn about and experience how different academic disciplines contribute to future brain science.<br/><br/>The extent to which sensory networks amplify or suppress perceived differences in odor valence remains a fundamental, unanswered question in sensory neuroscience.  The overarching hypothesis of this project is that indeed, there exists a well-defined set of transformations, governed by neuronal dynamics, which map sensory network activity to behavior.  Specifically, the project will determine: (a) How neural networks enable the formation of time-varying neural activation patterns, or, trajectories, in response to sensory stimuli, (b) The mapping from trajectories to behavioral outcome, and (c) The commonality of this mapping across species.  The research goals use an interdisciplinary approach combining sensory systems neuroscience in two species, locusts (Schistocerca americana) and round worms (C. elegans), with computational modeling and dynamical systems theory.  Neural and behavioral responses are recorded from animals receiving nominally attractive and aversive odors, and these data inform computational models of the sensory networks and ensuing behaviors.  The models generate predictions on how behavioral responses might be modulated by a change in selectivity, or background state.  The latter is tested through a paradigm wherein animals are systematically fed or starved, thus shifting their response dynamics on the aversive-attractive spectrum.  Subsequently, model-based sensitivity analyses is used to predict mixture response curves and paradoxical mixtures (e.g., two aversive stimuli that when mixed, elicit an attractive response).  These predictions are tested by delivering component stimuli in systematic ratios.  Thus, the overall methodology combines physiological experiments with new systems-level analysis in an integrated, multidisciplinary modeling-theory loop."
"2011088","CRCNS Research Proposal: Coupled Learning for Anatomically and Developmentally Consistent Analysis of Macaque-Human Fetal Brain Growth","DMS","CRCNS-Computation Neuroscience, MATHEMATICAL BIOLOGY","08/15/2020","10/19/2020","Colin Studholme","WA","University of Washington","Standard Grant","Zhilan Feng","07/31/2023","$541,402.00","","colin.studholme@ieee.org","4333 Brooklyn Ave NE","Seattle","WA","981950001","2065434043","MPS","7327, 7334","7327, 8089, 8091","$0.00","Neurodevelopmental disorders such as autism spectrum disorder, attention deficit/hyperactivity disorder, fetal alcohol spectrum disorders, and complications associated with premature birth, impact the quality of life of affected individuals over the entire lifespan. Neuroanatomical anatomical differences between people affected by these conditions and ?typically developing? individuals have been identified with magnetic resonance imaging (MRI), but the biological mechanisms leading to such differences, and their link to the disease processes, are incompletely understood. It is safe to perform MRI on pregnant women, and recent developments in the ability to account for fetal motion during image acquisition, have enabled high-resolution 3D imaging of the fetal brain. In order to better understand the developmental mechanisms that underlie the trajectory of anatomical changes observed by MRI in humans, longitudinal measurements are also collected in nonhuman primates. Human and nonhuman primates share many similarities in both brain structure and function that allow findings in one to be translated to the other. Advantages of nonhuman primate studies are that many factors that may vary between human pregnancies can be experimentally controlled, and much more detailed longitudinal imaging is possible. This research will develop computational approaches to more precisely link fetal growth between human and nonhuman brains. The work leverages unique human and nonhuman primate imaging datasets with new methods for systematically labeling the brain into corresponding sub-regions and establish closer links between developmental events. This increased precision will enhance knowledge gained from ongoing human observational studies and enable new clinical approaches to address neurodevelopmental diseases.<br/><br/>The ability to non-invasively monitor fetal brain growth in both human and nonhuman primates using magnetic resonance imaging (MRI) provides a new opportunity to characterize brain development with longitudinal experimental designs. However, given the increased frequency with which data can be acquired, and quality of high-resolution images, an important new limitation is the inability to translate developmental time points between species at the level of precision of the acquired data. Conventional approaches for studying postnatal brain images utilize processing steps such as spatial normalization to a common anatomical coordinate frame, segmentation into tissue classes, and parcellation into known neuroanatomical regions. Adaptation of these techniques to study the developing fetal brain requires age and species-specific definitions for quantities such as transient developmental zones, or emergence of cortical gyri and sulci. This project makes use of increasingly powerful machine learning techniques and leverages the increasingly rich fetal imaging data now being collected, to extract consistent cross-species measures of brain development. An additional objective is to develop fine scale anatomically and temporally consistent definitions across species. These neuroanatomically localized definitions will then be used to quantify regional morphometric growth during fetal brain development in both species. This work contributes to the computational science and the neuroscience that supports neuroimaging studies of fetal brain development. These developments will provide a new translational resource to link anatomically and temporally specific information about brain development, both in normal growth and in clinical and animal model experiments focused on neurodevelopmental disorders.<br/><br/>This award is being co-funded by the CISE Information and Intelligent Systems (IIS) through the CRCNA and BRAIN Programs, and the MPS Division of Mathematical Sciences (DMS) through the Mathematical Biology Program.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2024607","NCS-FO: Foundations of Biologically Informed Intelligent Machines for Spatial Navigation","CCF","IntgStrat Undst Neurl&Cogn Sys","01/01/2021","10/13/2020","Aurel Lazar","NY","Columbia University","Standard Grant","Mitra Basu","12/31/2023","$1,000,000.00","Mingoo Seok","aurel@ee.columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","CSE","8624","8089, 8091, 8551","$0.00","While mammals evolved some of the largest brains in the animal kingdom, fruit flies, despite their miniature brains, exhibit remarkably sophisticated capabilities. They can navigate and fly in most wind conditions, and maneuver directly towards or evasively away from stimuli while remembering their location, as well as rest or walk in any angular orientation even in the dark. The smaller brain of the navigationally agile fruit fly thus presents a good road map for studying the fundamental principles of spatio-temporal navigation. Recent studies have shown that a brain area called the central complex (CX) gives rise to the internal compass and spatial memory of the fruit fly. The CX also exhibits ``hardware'' simplicity, efficiency and robust operation matched by scalable integration of sensory information. The CX circuit architecture is a prime candidate for building biologically informed intelligent machines for spatial navigation. The overriding goal of this project is to create silicon hardware that can incorporate the essence of the spatial-navigation circuits of the CX into neuromorphic hardware. By interweaving the two research directions of computational neuroscience and computer engineering, the project has a strong potential to develop an intelligent machine prototype for spatial navigation meeting the most demanding requirements of autonomous vehicles.<br/><br/>The goals of this project are three-fold: (1) distill the foundations underlying the navigation circuits in the CX, (2) expand upon its principles of computation and (3) provide an implementation of the resulting functionality in silicon. Achieving these goals calls for (i) developing a comprehensive, biologically informed circuit architecture for vision-based spatial navigation, (ii) investigating the circuit mechanisms that encode and store spatio-temporal information, and (iii) studying the roles that different types of visual information flows play in shaping the decision making circuits of the CX. Informed by this bio-architecture, the investigators will develop a silicon CX prototype that will substantially enhance programmability, size, power, and accuracy over conventional neuromorphic architectures.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2024526","NCS-FO: Identification and control of neural cognitive systems","IIS","IntgStrat Undst Neurl&Cogn Sys","10/01/2020","10/13/2020","Jochen Ditterich","CA","University of California-Davis","Standard Grant","Ellen Carpenter","09/30/2023","$995,777.00","Zhaodan Kong","jditterich@ucdavis.edu","OR/Sponsored Programs","Davis","CA","956186134","5307547700","CSE","8624","8089, 8091, 8551","$0.00","Implantable devices provide an alternative for treating neurological disorders in patients who do not respond well to available drugs. A good example are deep brain stimulators for the treatment of Parkinson?s Disease, which have been very successful. Many neurological and psychiatric disorders are associated with cognitive deficits, which tend to be difficult to ameliorate through drug therapy. In the future, it might be possible to treat cognitive deficits with implantable devices, but this requires much more advanced technology than the currently available stimulators. This project will lay the foundation for interfacing technology with neural cognitive systems. Being able to steer or control a system of any kind requires a model or mathematical description of the system. The project will establish a framework for deriving such a model directly from neural activity. It will further develop strategies for moving the cognitive system into a desired target state through the application of electrical microstimulation, with the intent to allow for correction of disease-related maladaptive states.<br/><br/>This interdisciplinary project, which involves investigators from both neuroscience and engineering, has the following components: 1) System identification: Using a large number of implanted electrodes, the recorded neural activity will be used to identify a dynamical system that is able to capture (and predict) the temporal pattern of neural activity. The focus will be on piecewise linear models for approximating nonlinear dynamics. 2) State decoding: With the help of the identified model and based on the current and recent activity pattern, the current internal state of the neural system can be identified. 3) System control: In the case of the current state of the system deviating from a desired target state, the identified model in combination with control-theoretic strategies can be used to determine a stimulation pattern that needs to be applied to drive the system towards the desired state. The project will use simple cognitive tasks, like working memory and perceptual decision-making tasks, to provide a proof of principle that the state of a cognitive neural system can be adjusted in real time to improve, for example, overall performance on the task. This is an ambitious goal, which, in this form, has not been achieved before, but a successful outcome has the potential to revolutionize how mental disorders might be treated in the future.  This work is supported by the Integrative Strategies for Neural and Cognitive Systems (NCS) Program.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2024364","NCS-FO:  Variability and the Global Brain","IIS","IntgStrat Undst Neurl&Cogn Sys","10/01/2020","10/13/2020","Eric Shea-Brown","WA","University of Washington","Standard Grant","Kenneth Whang","09/30/2024","$999,612.00","Nicholas Steinmetz","etsb@amath.washington.edu","4333 Brooklyn Ave NE","Seattle","WA","981950001","2065434043","CSE","8624","8089, 8091, 8551","$0.00","While the brain's computational abilities are in many respects unrivaled, its workings appear to be far noisier than those of almost any engineered computational system. Even in carefully controlled experiments in which the same conditions are presented over multiple trials, neural activity is strikingly variable from one trial to the next. This project aims to resolve the apparent contradiction between the brain's computational proficiency and its apparently high levels of noise. The core hypothesis is that much of the observed neural variability is driven not by noise but by internal brain modes -- that is, by coordinated patterns of activity across the brain. Thus, variability may be a signature of dynamic and uniquely biological computations rather than noisy fluctuations. If this hypothesis is correct, then observation of these global modes should explain choices that subjects make in behavioral tasks, and perturbation of the modes should alter their patterns of choices in systematic ways. To test this hypothesis, the project employs a novel joint experimental and theoretical approach to measure the variability in brain-wide neural activity across scales, to define its relationship to behavior, and to dynamically perturb these modes to impact behavioral performance both within and across individuals. <br/><br/>To build a transformative understanding of the link between neural and behavioral variability, the project will use multi-probe Neuropixels technology that enables simultaneous recording at submillisecond resolution from thousands of individual neurons distributed across the brain, coupled with advanced data analytic and dynamical modeling tools to extract activity modes from these data. These analyses will be performed together with behavioral assays that probe multiple aspects of behavioral performance, including engagement, perceptual sensitivity, and vigor. Statistical modeling will then be used to identify the functional role of these modes in regulating behavioral performance, and how their activity drives behavioral differences both across trials and across individuals. Beyond correlative analysis, control theory tools will design patterned optogenetic perturbations to provide direct causal tests of this novel functional role for brain-wide activity modes. If the project succeeds, the result will be a new understanding of the nature of the ongoing fluctuations in brain-wide activity patterns trial by trial and individual by individual in terms of behavior rather than noise -- a key step in deciphering the logic of distributed computation underlying perception and cognition. The project will develop and disseminate novel open data and code to impact research and training nationwide. It will also build a dynamic, team-mentored environment led by investigators from very distinct disciplines -- from neuroscience to applied mathematics to control engineering -- which will prepare both undergraduate and graduate trainees to bridge disciplines and scientific cultures.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2040622","2021 CRCNS Principal Investigators Meeting","IIS","CRCNS-Computation Neuroscience","01/01/2021","10/14/2020","Zhe Chen","NY","New York University Medical Center","Standard Grant","Kenneth Whang","12/31/2021","$49,619.00","","Zhe.Chen@nyulangone.org","One Park Avenue, 6th FL","New York","NY","100165800","2122638822","CSE","7327","7327, 7556, 8089, 8091","$0.00","Computational and quantitative approaches are a longstanding aspect of neuroscience; however, recent advances in the ability to scale up data collection, simulation, and analysis are leading to an even more central role for computational thinking in this field. The goal of this meeting is to foster interaction and collaboration among experimental and computational neuroscientists. The meeting will highlight both the intellectual advances and broader impacts of CRCNS awardees. A workshop will focus on machine learning for large-scale neuroscience.<br/><br/>The Principal Investigators and Co-Principal Investigators of grants supported through the NSF-NIH-ANR-BMBF-BSF-NICT-AEI-ISCIII Collaborative Research in Computational Neuroscience (CRCNS) program meet annually to report on projects; to discuss scientific, educational, and program-related issues; and to develop a cohesive investigator community representing many different approaches to computational neuroscience. This 16th meeting of CRCNS investigators brings together a broad spectrum of computational neuroscience researchers supported by the program, and includes plenary lectures, oral and poster presentations, and panel discussions. The meeting and workshop are scheduled for July 8-10, 2021 and will be hosted by New York University.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1630178","NCS-FO: Understanding Neural Processing in Long-Term, Naturalistic Human Brain Recordings Using Data-Intensive Approaches","IIS","IntgStrat Undst Neurl&Cogn Sys","09/01/2016","08/17/2016","Bingni Brunton","WA","University of Washington","Standard Grant","Mitra Basu","08/31/2021","$899,318.00","Rajesh Rao","bbrunton@uw.edu","4333 Brooklyn Ave NE","Seattle","WA","981950001","2065434043","CSE","8624","8089, 8091, 8551","$0.00","Much knowledge about how human brains process information and generate actions has been informed by carefully controlled experiments in laboratory settings. However, understanding the brain in action requires exploration of its functions outside structured tasks. The current project explores neural processing over many days using large-scale recordings of brain activity augmented with video, audio and depth camera recordings, all simultaneously and continuously monitoring a subject. Importantly, unlike the majority of existing studies, here the subjects receive no instructions but are simply behaving as they wish in their hospital room-including eating, sleeping, and conversing with family. The project will advance data-intensive science and human neuroscience, leveraging external monitoring of the subjects to interpret naturalistic neural activity. The results of this project will be catalytic in understanding of the human brain, opening the door to study of brain function outside the structured confines of laboratory experiments. <br/><br/>The neural decoding algorithms developed will be directly applicable to current Brain-Computer Interfacing (BCI) technologies, enabling the deployment of systems that can predict the user's needs and improve quality of life outside the laboratory. Further, ongoing collaborations with neurosurgeons focus on evaluating this novel data-intensive approach to ethological brain mapping and how it may complement existing clinical functional brain mapping. The project will support and enable the education of students at the intersection of data science and neuroscience, including training scientists at the undergraduate, graduate, and post-doctoral career stages. Results from the research will be distributed as open access publications and code repositories, supporting a commitment to reproducible science. <br/><br/>This proposal focuses on data-driven innovations to enable more accurate decoding and inference of actions from long-term, naturalistic neural recordings. The first aim proposes to develop algorithms for automated decoding of natural motor and speech behaviors. Unsupervised clustering will be used to discover coherent patterns in brain activity, and clusters will be annotated with behaviors automatically parsed from external monitoring streams. Motivated by the size of the dataset and substantial variety between individuals, this scalable computational approach circumvents tedious manual annotation and fine-tuning of parameters.  The second aim proposes to infer networks of dynamic causality of cortical networks engaged in task-free, naturalistic behaviors. This aim focuses on testing the hypothesis that neural correlates of naturalistic behaviors differ from those of repeated, instructed behaviors. Functional networks and the dynamic causality of cortical areas will be explored using methods from nonlinear dynamical systems theory. These networks will be compared to results from clinical brain mapping. This project will improve state-of-the-art neural decoding in naturalistic contexts and uncover neural correlates of task-free behaviors in humans."
"2024926","NCS-FO: Neural mechanisms underlying second language learning","IIS","ECR-EHR Core Research, IntgStrat Undst Neurl&Cogn Sys","10/01/2020","10/13/2020","Santiago Jaramillo","OR","University of Oregon Eugene","Standard Grant","D.  Langendoen","09/30/2023","$1,000,000.00","Melissa Baese-Berk","sjara@uoregon.edu","5219 UNIVERSITY OF OREGON","Eugene","OR","974035219","5413465131","CSE","7980, 8624","8089, 8091, 8551","$0.00","Second language learning is critically important in our increasingly global society. Success in second language learning varies substantially across individuals, but the reasons for this variability are unclear. An improved understanding of how language learning works, from neurons to behavior, will enable the development of highly efficient learning strategies that take into account differences across individuals. In this project, the investigators focus on one key aspect of acquiring a new language, namely learning to differentiate new sounds; for example, when an English speaker must learn the difference between a trilled 'r' in 'perro' and tapped 'r' in 'pero' in Spanish. Current approaches to investigate second language learning typically use human behavior to infer what factors affect language acquisition. However, neuroscience tools for research in humans lack the necessary precision to directly uncover how changes in the brain underlie these factors. To address this limitation, the research team will combine insights from human behavior with observations of how animals process sound to allow for precise measurement of the brain processes underlying learning to differentiate new sounds.<br/><br/>The proposed work will compare learning performance under different learning scenarios in both mice and humans to identify which scenarios are most efficient, and to evaluate to what extent the way mice learn to differentiate sounds is comparable to that of humans. The research team will then use advanced techniques for measuring the activity of individual neurons as mice learn new sounds to investigate the neural changes responsible for effective learning. The project also includes a range of outreach objectives toward integration with education, broadening participation in STEM, and bridging theory and practice of language learning.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1724421","CRCNS US-France-Israel-Research Proposal: Processing of Complex Sounds: Cortical Network Mechanisms and Computations","IIS","GVF - Global Venture Fund, CRCNS-Computation Neuroscience, Robust Intelligence, IntgStrat Undst Neurl&Cogn Sys","10/01/2017","10/06/2020","Tatyana Sharpee","CA","The Salk Institute for Biological Studies","Continuing Grant","Kenneth Whang","09/30/2021","$950,000.00","","sharpee@salk.edu","10010 N TORREY PINES RD","LA JOLLA","CA","920371002","8584534100","CSE","054Y, 7327, 7495, 8624","014Z, 5905, 5918, 5976, 5980, 7327, 8089, 8091","$0.00","What are the relationships between the complex and constantly changing soundscapes that surround us and the electrical activity that represents them in the brain? This project brings together three groups, one experimental and two computational, to address this question at two different levels. First, mechanistic models will be developed, based on known properties of neural networks, to describe how different types of neurons cooperate to represent sounds. Second, the function of these neurons will be characterized by describing the features of sounds that they represent. These two goals will be achieved by combining experimental studies of neural responses to sounds with computational analyses to test candidate mechanisms for how sounds are represented in large cortical circuits. In addition to deeper understanding of auditory perception, this research will provide insights into general principles of cooperation between neurons within a single neural network. As such, the research has implications for understanding representation of signals in other sensory modalities as well as the general principles of neural coding in the brain. The research has a number of potential practical applications, including the design of advanced hearing aids and artificial speech recognition systems. Further, given that the altered balance between excitatory and inhibitory neurons has been implicated in a number of attention deficits and psychiatric disorders, including autism and schizophrenia, the project has potential medical relevance. The outreach component of the project will involve demonstration involving music and speech perception for K-12 students and exhibitions.<br/><br/>Technically, the experimental group will produce recordings of neural responses from the auditory thalamus and cortex in response to pure tones and complex sounds known as tone clouds. The tone clouds have sharp transitions like natural sounds, but with well-controlled spectral and temporal power distributions. Computational components of this project will aim to reproduce neural recordings through analytical modeling and simulations of large scale neural circuits composed of multiple cell types. The experimental and computational results will be matched not only in statistical terms, such as average dynamics of neural responses across the population, but also in terms of specific features of sounds that are encoded by different types of neurons in the network.<br/><br/>This award is cofunded by the Office of International Science and Engineering. Companion projects are being funded by the French National Research Agency (ANR) and the US-Israel Binational Science Foundation (BSF)."
"1835345","Collaborative Research: NCS-FO: Discovering Dynamics in Massive-Scale Neural Datasets Using Machine Learning","IIS","IntgStrat Undst Neurl&Cogn Sys","10/01/2018","08/28/2018","Lee Miller","IL","Northwestern University at Chicago","Standard Grant","Todd Leen","09/30/2021","$189,045.00","","lm@northwestern.edu","750 N. Lake Shore Drive,","Chicago","IL","606114579","3125037955","CSE","8624","8089, 8091, 8551","$0.00","For decades, neuroscientists have recorded from single brain cells (neurons) to understand how the brain senses, makes decisions, and controls movements. We can now record from hundreds of neurons simultaneously but are still at an early stage in developing tools for determining how networks of neurons work together to perceive the world and to generate the control signals needed to produce coordinated movement. Focusing on movement, this project brings to bear the power of deep learning --- powerful new machine learning algorithms --- on the problem of understanding neural activity. Because deep learning thrives on big data, the investigators can leverage massive-scale brain recordings.  These include month-long recordings chronicling the activity of 100 neurons as a monkey goes about its daily business, or recording from thousands of neurons for hours in the mouse, each identified with an exact location in the brain and tied to the mouse's on-going behaviors. These approaches will open new windows on how neurons act together moment-by-moment to produce movement. The investigators will develop simple descriptions of the underlying processes to be shared with the public through venues including online tutorials, a new open course that will be developed at Emory University and Georgia Tech, the Atlanta Science Festival, and Atlanta's Brain Awareness Month. They will also make their data sets publicly available, and host data tutorial and modeling competitions at key scientific meetings, to accelerate progress by engaging the broader scientific community.<br/><br/>In the fifty years since Ed Evarts first recorded single neurons in M1 of behaving monkeys, great effort has been devoted to understanding the relation between these individual signals and movement-related signals collected during highly constrained motor behaviors performed by over-trained monkeys. In parallel, theoreticians posited that the computations performed in the brain depend critically on network-level phenomena: dynamical laws in brain circuits that constrain the activity and dictate how it evolves over time. The goal of this project is to develop a powerful new suite of tools, based on deep learning, to analyze these dynamics at unprecedented temporal and spatial scales. The investigators will leverage recordings with month-long M1 electrophysiology, EMG, and behavioral data during natural behaviors from monkeys, and vast numbers of neurons recorded with two-photon imaging from behaving mice. Novel machine learning techniques using sequential auto-encoders will enable the investigators to learn the dynamics underlying these data. This combination will provide windows into the brain's control of motor behavior that have never before been possible. The novel analytical framework developed here will be extensible from motor behaviors to higher level problems of error processing, decision making, and learning.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1764010","RI: Medium: Neuromorphic and Data-Driven Speech Segregation","IIS","Robust Intelligence, IntgStrat Undst Neurl&Cogn Sys","10/01/2018","09/17/2018","Shihab Shamma","MD","University of Maryland, College Park","Standard Grant","Kenneth Whang","09/30/2021","$851,674.00","Carol Espy-Wilson","sas@isr.umd.edu","3112 LEE BLDG 7809 Regents Drive","College Park","MD","207425141","3014056269","CSE","7495, 8624","7495, 7924, 8089, 8091","$0.00","This project investigates how neural representations of speech and music in the cortex can be adapted and applied to overcome the challenge of robust perception in extremely noisy and cluttered environments, mimicking processing and capabilities of the brain. More specifically, the project will formulate algorithms inspired by the architecture of the brain to segregate and track targeted speakers or sound sources, test their performance, and relate them to state-of-the-art approaches that utilize deep artificial neural networks to accomplish these tasks. Human psychoacoustic and physiological experiments with these algorithms will be conducted to test the validity of these ideas for mimicking human abilities. This effort will spur the development of new neuromorphic computational tools modeled after the brain and its cognitive functions. In turn, these will provide a theoretical framework to guide future experiments into how complex cognitive functions originate and how they influence sensory perception and lead to robust behavioral performance.<br/><br/>The planned projects will be organized into two flavors. The first attempts to borrow from existing neuromorphic approaches that rely on cortical representations to develop new embeddings within the deep neural networks framework, which will in turn endow the latter with brain-like robustness in challenging unanticipated environments. Three specific efforts within this flavor will be conducted: Learning DNN embeddings using cortical representations of speech and music, exploring unsupervised clustering of cortical features using adversarial auto-encoders, and exploiting pitch and timbre representations to enhance segregation of sound. The second flavor of projects borrows from the DNN approach to build into neuromorphic algorithms the desirable performance and flexibility attained by training on available databases. Two broad areas of studies are planned: one focuses on questions of neuromorphic implementations that benefit from DNN toolboxes and ideas, especially in segregation and reconstruction. The other focuses on investigating how autoencoders can be exploited to implement feature reduction and clustering efficiently.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1844660","EAGER: Soft-Actuated Bionic Regenerative Engineering","CBET","EFRI Research Projects","10/01/2018","08/09/2018","Cato Laurencin","CT","University of Connecticut Health Center","Standard Grant","Grace Hwang","09/30/2021","$300,000.00","Yusuf Khan","laurencin@uchc.edu","263 Farmington Ave.","Farmington","CT","060321956","8606793951","ENG","7633","7916, 8089, 8091","$0.00","This project will develop a model system of a soft-robotic prosthetic designed to treat joint disease. Through the use of models of osteoarthritis progression and how mechanical loading impacts disease onset, progression, and regression, combined with models of continuous, compliant and configurable prosthetics, the research team will develop a soft-robotic prosthetic that is capable of responding in real time, based on implanted sensors, to the changing pressures of the joint while moving, such that the optimal dislocation will be achieved to promote healing. The research brings together two radically different concepts and approaches: (1) that the manipulation of mechanical forces can bring about regeneration of the knee cartilage and be curative for osteoarthritis, and (2) through the novel use of a robotic system, precise determination of forces and precise manipulation of the knee joint environment can occur to provide evidence of repair and regeneration of the knee joint.  <br/><br/>The research team will evaluate knee osteoarthritis as their testbed, but the program could have far reaching capabilities for other musculoskeletal disorders like hip-related osteoarthritis, gait-dependent back pain, and other disorders that would benefit from dynamic input rather than static control. Development of an engineered bioactive soft-robotic brace would be transformative to the field of musculoskeletal regeneration, as it is unlike any previous attempt to treat osteoarthritis. The approach is non-invasive, responds dynamically to the physical loads imposed upon the joint, is informed by the actual extent of disease progression of the joint, and is highly cost-effective. The project is high-risk, but may create a new engineered paradigm for the treatment of one of the world?s most prevalent diseases. The results of this project will be shared amongst the greater research community through peer-reviewed publications, conference proceedings, podium presentations, and poster presentations, and as content of any invited chapters or reviews on topics germane to the work described.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1835390","Collaborative Research: NCS-FO: Discovering Dynamics in Massive-Scale Neural Datasets Using Machine Learning","IIS","IntgStrat Undst Neurl&Cogn Sys","10/01/2018","08/28/2018","Matthew Kaufman","IL","University of Chicago","Standard Grant","Todd Leen","09/30/2021","$189,049.00","","mattkaufman@uchicago.edu","6054 South Drexel Avenue","Chicago","IL","606372612","7737028669","CSE","8624","8089, 8091, 8551","$0.00","For decades, neuroscientists have recorded from single brain cells (neurons) to understand how the brain senses, makes decisions, and controls movements. We can now record from hundreds of neurons simultaneously but are still at an early stage in developing tools for determining how networks of neurons work together to perceive the world and to generate the control signals needed to produce coordinated movement. Focusing on movement, this project brings to bear the power of deep learning --- powerful new machine learning algorithms --- on the problem of understanding neural activity. Because deep learning thrives on big data, the investigators can leverage massive-scale brain recordings.  These include month-long recordings chronicling the activity of 100 neurons as a monkey goes about its daily business, or recording from thousands of neurons for hours in the mouse, each identified with an exact location in the brain and tied to the mouse's on-going behaviors. These approaches will open new windows on how neurons act together moment-by-moment to produce movement. The investigators will develop simple descriptions of the underlying processes to be shared with the public through venues including online tutorials, a new open course that will be developed at Emory University and Georgia Tech, the Atlanta Science Festival, and Atlanta's Brain Awareness Month. They will also make their data sets publicly available, and host data tutorial and modeling competitions at key scientific meetings, to accelerate progress by engaging the broader scientific community.<br/><br/>In the fifty years since Ed Evarts first recorded single neurons in M1 of behaving monkeys, great effort has been devoted to understanding the relation between these individual signals and movement-related signals collected during highly constrained motor behaviors performed by over-trained monkeys. In parallel, theoreticians posited that the computations performed in the brain depend critically on network-level phenomena: dynamical laws in brain circuits that constrain the activity and dictate how it evolves over time. The goal of this project is to develop a powerful new suite of tools, based on deep learning, to analyze these dynamics at unprecedented temporal and spatial scales. The investigators will leverage recordings with month-long M1 electrophysiology, EMG, and behavioral data during natural behaviors from monkeys, and vast numbers of neurons recorded with two-photon imaging from behaving mice. Novel machine learning techniques using sequential auto-encoders will enable the investigators to learn the dynamics underlying these data. This combination will provide windows into the brain's control of motor behavior that have never before been possible. The novel analytical framework developed here will be extensible from motor behaviors to higher level problems of error processing, decision making, and learning.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1835364","Collaborative Research: NCS-FO: Discovering Dynamics in Massive-Scale Neural Datasets Using Machine Learning","IIS","IntgStrat Undst Neurl&Cogn Sys","10/01/2018","10/17/2019","Chethan Pandarinath","GA","Emory University","Standard Grant","Todd Leen","09/30/2021","$621,897.00","","chethan.pandarinath@emory.edu","1599 Clifton Rd NE, 4th Floor","Atlanta","GA","303224250","4047272503","CSE","8624","8089, 8091, 8551","$0.00","For decades, neuroscientists have recorded from single brain cells (neurons) to understand how the brain senses, makes decisions, and controls movements. We can now record from hundreds of neurons simultaneously but are still at an early stage in developing tools for determining how networks of neurons work together to perceive the world and to generate the control signals needed to produce coordinated movement. Focusing on movement, this project brings to bear the power of deep learning --- powerful new machine learning algorithms --- on the problem of understanding neural activity. Because deep learning thrives on big data, the investigators can leverage massive-scale brain recordings.  These include month-long recordings chronicling the activity of 100 neurons as a monkey goes about its daily business, or recording from thousands of neurons for hours in the mouse, each identified with an exact location in the brain and tied to the mouse's on-going behaviors. These approaches will open new windows on how neurons act together moment-by-moment to produce movement. The investigators will develop simple descriptions of the underlying processes to be shared with the public through venues including online tutorials, a new open course that will be developed at Emory University and Georgia Tech, the Atlanta Science Festival, and Atlanta's Brain Awareness Month. They will also make their data sets publicly available, and host data tutorial and modeling competitions at key scientific meetings, to accelerate progress by engaging the broader scientific community.<br/><br/>In the fifty years since Ed Evarts first recorded single neurons in M1 of behaving monkeys, great effort has been devoted to understanding the relation between these individual signals and movement-related signals collected during highly constrained motor behaviors performed by over-trained monkeys. In parallel, theoreticians posited that the computations performed in the brain depend critically on network-level phenomena: dynamical laws in brain circuits that constrain the activity and dictate how it evolves over time. The goal of this project is to develop a powerful new suite of tools, based on deep learning, to analyze these dynamics at unprecedented temporal and spatial scales. The investigators will leverage recordings with month-long M1 electrophysiology, EMG, and behavioral data during natural behaviors from monkeys, and vast numbers of neurons recorded with two-photon imaging from behaving mice. Novel machine learning techniques using sequential auto-encoders will enable the investigators to learn the dynamics underlying these data. This combination will provide windows into the brain's control of motor behavior that have never before been possible. The novel analytical framework developed here will be extensible from motor behaviors to higher level problems of error processing, decision making, and learning.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1734892","NCS-FO: Extracting Functional Cortical Network Dynamics at High Spatiotemporal Resolution","SMA","IntgStrat Undst Neurl&Cogn Sys","08/01/2017","08/07/2017","Jonathan Simon","MD","University of Maryland, College Park","Standard Grant","Betty Tuller","07/31/2021","$909,153.00","Behtash Babadi","jzsimon@umd.edu","3112 LEE BLDG 7809 Regents Drive","College Park","MD","207425141","3014056269","SBE","8624","8089, 8091, 8551","$0.00","This project is funded by Integrative Strategies for Understanding Neural and Cognitive Systems (NSF-NCS), a multidisciplinary program jointly supported by the Directorates for Computer and Information Science and Engineering (CISE), Education and Human Resources (EHR), Engineering (ENG), and Social, Behavioral, and Economic Sciences (SBE). Neuroscientists have been remarkably successful in understanding the function of numerous brain regions by studying them in isolation and characterizing their individual roles in behavior. Growing evidence in recent years, however, suggests that sophisticated brain function emerges from the co-activation of multiple brain regions that exhibit networked activity. These networks organize rapidly in order to allow the brain to adapt to changes in the environment, resulting in robust behavior. Deciphering the neural mechanisms underlying these network dynamics is therefore crucial in understanding how the brain carries out cognitive processes such as attention, decision-making and learning. Recent technological advances in noninvasive neuroimaging have largely addressed the experimental challenges in studying these dynamic networks in humans and have provided abundant neural data under countless clinical and experimental conditions. However, the sheer high-dimensionality of these data together with the complexity of these networks has created various bottlenecks in data analysis, modeling, and statistical inference. In order to exploit the unique window of opportunity provided by the abundance of noninvasive neural data, this project is (1) developing a unified methodology for inferring the dynamics and statistical characteristics of these cortical networks, in a computationally efficient fashion, and (2) applying this methodology to magnetoencephalography (MEG) data from behaving human subjects to address several fundamental questions about auditory processing. This work brings new insight as to the dynamic organization of brain networks at unprecedented spatiotemporal resolutions, and can thereby affect technology in the areas of brain-computer interfacing and neuromorphic engineering. It also allows for the creation of engineering solutions for early detection and monitoring of cognitive disorders involving auditory perception and attention. The outcome of this project will be disseminated to the broader scientific community in the form of publicly accessible data analysis toolboxes accompanied with tutorials and webinars. The research plan is complemented by educational activities at the K-12, undergraduate, and graduate levels, including workshops, undergraduate projects, and course development, with an emphasis on the involvement of women and underrepresented minorities.<br/><br/>The existing paradigm for extracting cortical functional network dynamics faces challenges, including loss of temporal resolution due to the common sliding window processing, loss of spatial resolution due to the constraints of noninvasive recording, and statistical bias due to the heavy usage of linear estimation techniques given that network properties are intrinsically non-linear. This project provides a unified research plan for addressing these challenges, by combining high temporal resolution non-invasive recordings with high spatial resolution in a statistically robust way, using modern signal processing techniques. This methodology will specifically be applied to MEG data acquired from behaving human subjects, and will be used to decipher the neural mechanisms of adaptive auditory processing."
"1848029","Convergence: RAISE Integrating machine learning and biological neural networks","CBET","GCR-Growing Convergence Resear, SSA-Special Studies & Analysis, Information Technology Researc, IntgStrat Undst Neurl&Cogn Sys","10/01/2018","09/13/2018","Xue Han","MA","Trustees of Boston University","Standard Grant","Leon Esterowitz","09/30/2021","$999,999.00","Bobak Nazer","xuehan@bu.edu","881 COMMONWEALTH AVE","BOSTON","MA","022151300","6173534365","ENG","062Y, 1385, 1640, 8624","049Z, 7236, 8089, 8091","$0.00","The field of neuroscience is undergoing a rapid transformation, and within the next decade, it may become possible to capture data from millions of individual neurons at the same time.  Such a technological advancement would allow scientists to record and analyze a significant fraction of the brain's neural network at unprecedented spatial and time resolutions.  The goal of this research project is to advance our understanding of brain activity through the integration of bioengineering, systems neuroscience and data science and their application to the study of networks of neurons.  The research team will engineer new sensors designed to image the activity of individual neurons within a large network and then apply this method to the study of functioning neural systems.  The team will also develop computational methods to extract information from the resulting, extremely large datasets.  This research will have broader impact through training STEM students in a convergent science area and through deepening our understanding of the science underlying neurological disease and thereby improving mental health treatment.<br/><br/>This research project aims to create novel protein sensors to acquire single-neuron-resolution imaging data.  This methodology could serve as the basis for ultra-large-scale neural network imaging.  The researchers will establish the architectural principles and fundamental limits for fluorescence imaging systems and inference algorithms that extract underlying neural activity.  They will then develop machine learning techniques to extract network-level phenomena from high-dimensional neural data.  Finally, the researchers will study large networks of neurons during behavior and learning via carefully-designed experiments and machine learning techniques.  The technologies developed in this work, to acquire and to analyze, single-neuron-resolution imaging data, will facilitate the understanding of brain's neural network computation at an ultra-large scale, directly confronting challenging societal problems related to the human brain.  The project participants will also educate the next generation of engineers and scientists in the convergent area of neuroscience with data science.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1607518","CRCNS: Functional Dissection of a Looming-Sensitive Neural Pathway in Drosophila","IIS","Cross-BIO Activities, CRCNS-Computation Neuroscience, Robust Intelligence","09/01/2016","06/24/2019","Fabrizio Gabbiani","TX","Baylor College of Medicine","Continuing Grant","Sridhar Raghavachari","08/31/2021","$878,090.00","Herman Dierick","gabbiani@bcm.edu","ONE BAYLOR PLAZA","HOUSTON","TX","770303411","7137981297","CSE","7275, 7327, 7495","1228, 2886, 7327, 7495, 8089, 8091, 9178, 9179","$0.00","The goal of the proposal is to elucidate the neural computations carried out by the visual system to identify an impending threat and their use for the generation of collision avoidance behaviors. The proposal will develop advanced genetic, behavioral and imaging techniques to address these questions. The experimental data will be summarized in a biophysical model of the neural circuits generating collision avoidance behaviors that will be validated using the experimental data acquired during the project. The project will advance our understanding of how the visual system goes about reliably identifying a threat in the natural visual environment without reacting to irrelevant visual stimuli. The knowledge gained from the project is expected to allow the future design of efficient, neurally-inspired collision avoidance systems.  <br/><br/>The proposed experiments will be carried out in the fruit fly Drosophila, a model system in which sophisticated genetics tools are available, including genetically encoded Ca2+ indicators and modifiers of neural activity that can be expressed in specific neural subpopulations. These tools, paired with the recent anatomical description of visual pathways at the electron microscopic level, offer the possibility of investigating how networks of neurons process information leading to visually guided escape behaviors at an unprecedented level of detail. In particular, these tools will allow (1) to carry out behavioral experiments where specific populations of neurons belonging to the visually-guided escape pathway are silenced; (2) to perform imaging experiments allowing to study the activation of the neurons belonging to the visually-guided escape pathway at all successive stages of the visual system and determine how/when the specificity for looming stimuli arises; (3) to apply localized stimuli and advanced microstimulation techniques allowing to isolate the contribution of individual photoreceptors to the processing of visual information related to looming stimuli in single neurons; (4) to develop genetic tools allowing to silence populations of neurons by using novel anion channel rhodopsins and allowing to sparsely label neurons of the pathway at two successive stages, either with an indicator of neuronal activity or with an optogenetic activator; (5) to test the functional connectivity at successive stages of the pathway using these tools in conjunction with three dimensional random access imaging; and (6) to model the neural computations carried out along the visually guided escape pathway."
"1822598","CRCNS Research Proposal: Collaborative Research: New dimensions of visual cortical organization","IIS","CRCNS-Computation Neuroscience","10/01/2018","09/07/2018","Michael Stryker","CA","University of California-San Francisco","Standard Grant","Kenneth Whang","09/30/2022","$775,776.00","","stryker@phy.ucsf.edu","1855 Folsom St Ste 425","San Francisco","CA","941034249","4154762977","CSE","7327","7327, 8089, 8091","$0.00","The visual system of the mouse is now widely studied as a model for developmental neurobiology, as well as for the understanding of human disease, because it can be studied with the most powerful modern genetic and optical tools.  This project aims to discover how neurons in the visual cortex of the mouse allow it to see well by measuring how the cortex represents ecologically-relevant properties of the visual world.  Quantitative studies of neurons in the mouse's primary visual cortex to date reveal only very poor vision, but their behavior indicates that mice can see much better than that -- they avoid predators and catch crickets in the wild. To understand mouse vision, the investigators will study responses to novel, mathematically tractable stimuli resembling the flow of images across the retina as the mouse moves through a field of grass.  Studies based on these new stimuli indicate that most V1 neurons respond reliably to fine details of the visual scene.  A mathematical understanding of how the brain takes in the visual world should have real implications for how we see, and should have great benefits for artificial vision by computers and robots.  Bringing these ideas into the classroom will provide the foundation for new technologies, and will expose students to both real and artificial vision systems.<br/><br/>Analyses of the brain's visual function are limited by the stimuli used to probe them. Conventional quantitative approaches to understanding biological vision have been based on models with linear kernels in which only the output might be subject to a nonlinearity, all derived from responses of neurons in the brain to gratings of a range of spatial frequencies.  This analysis fails to capture relevant features of natural images, which can not be constrained to linearity. The goal of this project is to probe the mouse visual system beyond the linear range but below the barrier posed by the complexity of arbitrary natural images. The investigators have identified an intermediate stimulus class--visual flow patterns--that formally approximate important features of natural visual scenes, resembling what an animal would see when running through grass. Flow patterns have a rich geometry that is mathematically tractable.  This project will develop such stimuli and test them on awake-behaving mice, while recording the resultant neural activity in the visual cortex.  Studying the mouse opens up the possibility of applying the entire range of powerful modern neuroscience tools-- genetic, optical, and electrophysiological. Visual responses will be analyzed using a novel variety of machine learning algorithms, which will allow the investigators to model the possible neural circuits and then test predictions from those model circuits.  Such an understanding of the brain will inform both primate vision and the next generation of artificially-intelligent algorithms which, as a result, should benefit from being more ""brain-like.""<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2023985","NCS-FO: Edge-centric maps of functional brain network organization and dynamics","IIS","IntgStrat Undst Neurl&Cogn Sys","10/01/2020","09/17/2020","Richard Betzel","IN","Indiana University","Standard Grant","Kenneth Whang","09/30/2023","$737,019.00","Olaf Sporns, Yong-Yeol Ahn, Amanda Mejia","rbetzel@indiana.edu","509 E 3RD ST","Bloomington","IN","474013654","3172783473","CSE","8624","8089, 8091, 8551","$0.00","The human brain is made up of functionally and structurally connected neural elements that form a brain-wide complex network. A principal goal of network neuroscience is to understand how the organization of this network helps support cognition, evolves over the course of the human lifespan, and becomes compromised in disease and neuropsychiatric disorders. However, virtually all progress made towards addressing these questions has relied upon one particular network model for mathematically representing patterns of brain connectivity, at the expense of other models that could provide complementary or unique insight. This project aims to extend and validate an alternative edge-centric framework for representing and analyzing patterns of brain connectivity. The project will deliver new insights into the relationship of brain network organization with cognitive/behavioral phenotypes and shed light on brain network dynamics at ultra-fast timescales are paralleled by changes in subjects' cognitive states. This research will support cross-disciplinary collaboration among the brain sciences, informatics, and statistics, and will support a diverse set of trainees at all levels, from high school to postdoctoral.<br/><br/>This principal innovation of the edge-centric framework is a spatiotemporal decomposition of functional connections into their framewise contributions. This decomposition yields a time series of co-fluctuations for every pair of brain regions (edges in the network). The first aim investigates the novel construct of edge functional connectivity -- the correlation pattern estimated among all pairs of co-fluctuation time series. Edge connectivity will be generated for a large cohort of subjects (N > 1000) using imaging data acquired both at rest and while subjects were performing cognitively demanding tasks. Multivariate statistical methods will be used to discover robust associations between edge connectivity and subjects' behavioral, demographic, and clinical measures. The second aim analyzes co-fluctuation time series directly, taking advantage of the ultra-fast timescale at which they are estimated to investigate potential drivers of brain network reconfiguration during naturalistic viewing (movie-watching). This project advances the edge-centric framework as a viable tool for general neuroscientific discovery and will open the door for future studies to investigate brain-behavior relationships and network dynamics in applied contexts and not restricted to large-scale imaging data.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1822650","CRCNS Research Proposal:  Collaborative Research: New Dimensions of Visual Cortical Organization","IIS","CRCNS-Computation Neuroscience, Robust Intelligence","10/01/2018","09/07/2018","Steven Zucker","CT","Yale University","Standard Grant","Kenneth Whang","09/30/2022","$625,115.00","","steven.zucker@yale.edu","Office of Sponsored Projects","New Haven","CT","065208327","2037854689","CSE","7327, 7495","075Z, 7327, 8089, 8091","$0.00","The visual system of the mouse is now widely studied as a model for developmental neurobiology, as well as for the understanding of human disease, because it can be studied with the most powerful modern genetic and optical tools.  This project aims to discover how neurons in the visual cortex of the mouse allow it to see well by measuring how the cortex represents ecologically-relevant properties of the visual world.  Quantitative studies of neurons in the mouse's primary visual cortex to date reveal only very poor vision, but their behavior indicates that mice can see much better than that -- they avoid predators and catch crickets in the wild. To understand mouse vision, the investigators will study responses to novel, mathematically tractable stimuli resembling the flow of images across the retina as the mouse moves through a field of grass.  Studies based on these new stimuli indicate that most V1 neurons respond reliably to fine details of the visual scene.  A mathematical understanding of how the brain takes in the visual world should have real implications for how we see, and should have great benefits for artificial vision by computers and robots.  Bringing these ideas into the classroom will provide the foundation for new technologies, and will expose students to both real and artificial vision systems.<br/><br/>Analyses of the brain's visual function are limited by the stimuli used to probe them. Conventional quantitative approaches to understanding biological vision have been based on models with linear kernels in which only the output might be subject to a nonlinearity, all derived from responses of neurons in the brain to gratings of a range of spatial frequencies.  This analysis fails to capture relevant features of natural images, which can not be constrained to linearity. The goal of this project is to probe the mouse visual system beyond the linear range but below the barrier posed by the complexity of arbitrary natural images. The investigators have identified an intermediate stimulus class--visual flow patterns--that formally approximate important features of natural visual scenes, resembling what an animal would see when running through grass. Flow patterns have a rich geometry that is mathematically tractable.  This project will develop such stimuli and test them on awake-behaving mice, while recording the resultant neural activity in the visual cortex.  Studying the mouse opens up the possibility of applying the entire range of powerful modern neuroscience tools-- genetic, optical, and electrophysiological. Visual responses will be analyzed using a novel variety of machine learning algorithms, which will allow the investigators to model the possible neural circuits and then test predictions from those model circuits.  Such an understanding of the brain will inform both primate vision and the next generation of artificially-intelligent algorithms which, as a result, should benefit from being more ""brain-like.""<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1822929","CRCNS Research Proposal: Collaborative Research: Evaluating Machine Learning Architectures Using a Massive Benchmark Dataset of Brain Responses to Natural Scenes","IIS","CRCNS-Computation Neuroscience, IntgStrat Undst Neurl&Cogn Sys","10/01/2018","09/10/2018","Thomas Naselaris","SC","Medical University of South Carolina","Standard Grant","Kenneth Whang","09/30/2021","$422,619.00","Kendrick Kay","tnaselar@musc.edu","171 ASHLEY AVE","CHARLESTON","SC","294258908","8437923838","CSE","7327, 8624","7327, 8089, 8091, 9150","$0.00","Machine learning technologies have the potential to radically transform the study of the human brain, but require far more data than is typically collected during conventional neuroscience experiments. The goal of this project is to drive the application of ML techniques to neuroscience research by generating a massive dataset of brain responses from the human visual system. The resulting dataset will be freely available to scientists, educators, and students. Through a yearly modeling competition, neuroscientists will gain experience in the application of advanced computational methods and ML researchers will gain a deeper understanding of the challenges and complexities of the human brain. Results of the modeling competition will be presented at an annual conference attended by both machine learning and neuroscience researchers and students, providing an opportunity for the two groups to interact and discuss approaches. This project will foster open collaboration between neuroscientists and artificial intelligence researchers and a culture of sharing data, ideas, and progress. <br/><br/>The long-term goal of this work is to generate data that will lead to the development of experimentally validated and computationally powerful models of the human visual system. The project leaders will use high-field (7 Tesla) functional magnetic resonance imaging (fMRI) to measure brain responses to a broad sampling of natural images in human observers. The specific objectives are as follows: (1) Acquire, pre-process, and distribute a massive, high-resolution fMRI dataset that exploits state-of-the-art imaging techniques. The dataset will include multiple samples of brain responses to roughly eighty thousand photographs drawn from an image collection that is widely used by the ML community. (2) Establish and host an annual competition for modeling this rich dataset at the conference on Cognitive Computational Neuroscience. (3) Bridge the gap between ML architectures and the human brain by testing new ML-inspired architectures as models of the visual system. The project leaders will focus specifically on recent developments in ML that suggest new hypotheses about the dorsal visual stream.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1718991","RI: Small: Extracting and Understanding Sparse Structure in Spatiotemporal Data in Neuroscience and Other Applications","IIS","Robust Intelligence, IntgStrat Undst Neurl&Cogn Sys","09/01/2017","11/22/2019","Friedrich Sommer","CA","University of California-Berkeley","Standard Grant","Kenneth Whang","08/31/2021","$449,999.00","Bruno Olshausen, Saeed Saremi","fsommer@berkeley.edu","Sponsored Projects Office","BERKELEY","CA","947101749","5106433891","CSE","7495, 8624","7495, 7923, 8089, 8091","$0.00","Sparse coding and manifold learning are two methods that, each in its own right, have proven essential for understanding the structure in complex high dimensional data. The goal of this project is to combine these two methods to yield a qualitatively more powerful approach to analyze data. The investigators will develop the mathematics of sparse coding of spatiotemporal data and combine it with approaches from manifold learning. The tools emerging from this research will bring benefits to society since they are applicable to many areas of technology and medicine, such as signal processing, image and video coding, medical imaging, neural data analysis,  neuroprosthetics, and can be expected to have implications for understanding information processing in the visual cortex. <br/><br/>Sparse coding is a concept originally developed in neuroscience to account for sensory representations in the brain, which now sees widespread use in many image and signal processing and data analysis tasks. However, there are critical limitations with current approaches to sparse coding. One major issue is that sparse representations can be brittle, changing abruptly over time or in response to small changes in the input, and they can be quite sensitive to parameter settings, initial conditions, and the particular choice of sparse solver. Another limitation is that if the data lie in a low dimensional manifold, such as sound waveforms or images, the connection between the sparse codes of the data and the geometry of the underlying low dimensional space is lost. The team conjectures that both of these limitations should be addressed together. Building on previous work and their own preliminary studies, they will develop a theoretical framework for sparse coding to reveal conditions under which the results of sparse coding are unique. Based on these theoretical insights, they will design novel algorithms for robustly revealing persistent sparse structure in spatiotemporal data. Finally they will develop a new signal transform, called sparse manifold transform, that combines traditional sparse coding with manifold learning."
"1734981","NCS-FO: Collaborative Research: Understanding the neural basis for sensorimotor control loops using whisker-based robotic hardware platforms","BCS","IntgStrat Undst Neurl&Cogn Sys","09/01/2017","08/07/2017","Mitra Hartmann","IL","Northwestern University","Standard Grant","Betty Tuller","08/31/2021","$666,298.00","L. Brinson","m-hartmann@northwestern.edu","750 N. Lake Shore Drive","Chicago","IL","606114579","3125037955","SBE","8624","8089, 8091, 8551, 9251","$0.00","This project will construct robots in order to understand how animals gather information through the sense of touch and how animals use touch information to perform complex behaviors. The results will be important to both neuroscience and engineering. On the neuroscience side, the results will address how the brain combines information about movement and touch, thereby improving our understanding of stroke and brain injury. On the engineering side, the work will develop novel robots and sensors that use touch to sense object location, shape, and texture, to track fluid wakes in water, and to sense the direction of airflow. These capabilities will improve the ability of robots to work in challenging environments; for example, robots could explore dark areas more easily or provide surgeons with a better sense of touch during surgery. To train the next generation of scientists and engineers, both undergraduate and graduate students will help construct the robots and will explore industry- and government-related applications of whisker-based touch sensing. The research team will investigate technology transfer opportunities in robotics and medicine, flow sensing, instrument placement, corrosion detection, three-dimensional tactile profilometry, and compliance sensing. <br/><br/>The fundamental scientific rationale for the work is that understanding how animal nervous systems process complex sensory and motor information necessarily requires quantification of the input. However, it is currently impossible for neuroscientists to record from all primary sensory neurons involved in a particular sensorimotor behavior. The three stages of this project exploit the whisker system of mammals in an endeavor to completely quantify whisker-based input and early neural processing in the rat (Rattus norvegicus) and the harbor seal (Phoca vitulina). The first stage of work will focus on the development of modular, reconfigurable, artificial whiskers that can sense both touch and fluid flow. The materials, manufacturing, and sensor designs necessary for whiskers at multiple length scales will be investigated and signals from the whiskers will be represented based on known coding properties of primary whisker-sensitive neurons in the trigeminal ganglion (TG). The second stage of work will involve the construction of whisker arrays that anatomically match those of the rat and the seal. These arrays will be used to develop combined hardware and software models of the responses of the entire population of TG neurons. Finally, in the third stage of work, the whisker arrays will be mounted on robotic platforms, and the robots will be put through the same head movements as real animals during natural behavior. This process will allow us to simulate the entire TG neuron population response during complex, natural behaviors. Overall, the project will help unlock the basis by which low-level but powerful neural circuits confer animals with flexibility and resourcefulness in sensing and movement. This project is funded by Integrative Strategies for Understanding Neural and Cognitive Systems (NSF-NCS), a mulitdisciplinary program jointly supported by the Directorates for Computer and Information Science and Engineering (CISE), Education and Human Resources (EHR), Engineering (ENG), and Social, Behavioral, and Economic Sciences (SBE)."
"1912194","CRCNS Research Proposal:Topological and Dynamical Structures of Brain Development and Sexual-Dimorphism in C. Elegans","DMS","OFFICE OF MULTIDISCIPLINARY AC, Cross-BIO Activities, CRCNS-Computation Neuroscience, MSPA-INTERDISCIPLINARY","10/01/2019","07/31/2019","Raul Rabadan","NY","Columbia University","Standard Grant","Junping Wang","09/30/2022","$999,993.00","Liam Paninski, Oliver Hobert, Andrew Blumberg","rr2579@cumc.columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","MPS","1253, 7275, 7327, 7454","7327, 8089, 8091","$0.00","The development of the nervous system, specifically the dynamics of neuronal development and wiring to build brain architecture and their constructive role in emergent brain activity, constitutes a central unexplained phenomenon in living systems. The study of developing brains requires a comprehensive and systematic characterization of the brain of an organism at different ages and a suitable mathematical framework, able to capture the structure of the growing nervous system and the emerging networks therein. We propose to address this fundamental challenge by developing such a mathematical framework capable of characterizing underlying network changes in living brains and their consequences for functional neural activity and resulting behavior. This mathematical framework will be applied to analyze the complete nervous system, at single-cell precision, of the model organism C. elegans. To address these important challenges, we have assembled an interdisciplinary team with expertise in topology, computational biology, statistics, theoretical physics, neuroscience and biology of the model organism. Our group will develop new mathematical, statistical, and computational tools to characterize the structure of developing brain networks. This analysis will reveal shared-organizational, emergent principles of nervous-system development and function. Based on the widespread representation of biological data as complex networks and the universality of the mathematical, statistical, and computational methods we will develop, we expect wide applicability beyond the original system.<br/><br/>The aforementioned approach will be led by experiments that aim at providing multiple views of a developing network and their functional consequences to whole-brain activity. We will analyze the brain at two levels: changes to the underlying network as a consequence of extensive neural additions and connective neural (re-)wiring. We will compare the developing network at two transition periods: early maturation from the first to the second larval stage and, later, maturation of the two different sexes. In both of these developmental periods, newborn neurons grow the existing brain network, considerably, by roughly a third in size. In order to characterize the global properties of the data collected from these two different layers (neural network and brain activity) and to study the maps between them, we will develop tools based on topological data analysis (TDA) and Bayesian inference techniques. TDA provides methodology derived from algebraic topology that can be used to extract global features in large datasets. As a relatively new field, there are several major roadblocks that obstruct the wide applicability of TDA to biological systems, including the development of statistical approaches, comparison (homomorphisms) of networks (simplicial complexes), and time-series analysis. These tools will be then applied to study biological datasets that describe the developing brain network and changes to neurobehavioral activity therein. In particular, we will characterize basal networks and those for attractive and aversive behavior, for whole brains at a single-cell level, during developmental transitions that are known to restructure this behavioral network at both the level of input and output.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1912030","CRCNS Research Proposal: Collaborative Research: The Space of Riemannian Metrics for the Statistical Analysis of the Human Connectome","DMS","Special Initiatives, CRCNS-Computation Neuroscience, MSPA-INTERDISCIPLINARY, IntgStrat Undst Neurl&Cogn Sys","08/15/2019","08/06/2019","Sarang Joshi","UT","University of Utah","Standard Grant","Junping Wang","07/31/2022","$650,000.00","Jeffrey Anderson","sjoshi@sci.utah.edu","75 S 2000 E","SALT LAKE CITY","UT","841128930","8015816903","MPS","1642, 7327, 7454, 8624","7327, 8089, 8091","$0.00","The human brain is one of the most complex biological geometrical objects. The Human Connectome Project aims to make available an unparalleled compilation of neural functional and structural imaging data from healthy adults. Data from over 900 subjects has already been released. The principal data provided by the Human Connectome Project are diffusion-weighted MRI and functional MRI. Due to the amount and complexity of the data generated in this project, new techniques to analyze, compare and represent these data are needed, which is the motivation and driving force for the research outlined in this proposal. This collaborative project has three fundamental goals: (1) to further develop the mathematical theory of geometrical statistics, in particular the role of the infinite-dimensional manifold of all Riemannian metrics; (2) to develop practical tools for the statistical study of the connectivity of the human brain; and (3) to demonstrate the utility of the developed techniques for the segmentation and parcellation of the thalamus and other subareas of the subcortical gray matter that are not visible in structural MRI. <br/><br/>This project will develop for the first time statistical techniques on the infinite-dimensional manifold of Riemannian metrics. The project team believes that the space of Riemannian metrics is the natural framework for analyzing the variability of the architecture of the human brain. Diffusion-weighted MRI allows the investigators to model an individual human brain as a Riemannian manifold with axonal connections that are geodesic curves of an appropriate metric. The team will study the space of all Riemannian metrics and develop methods based on geometrical statistics for the analysis of the whole population. An immediate practical application of the techniques developed will be the parcellation of the thalamus based on thalamocortical connectivity. The internal architecture of the thalamus is not visible in standard structural MRI but rather is defined via the connections to the different areas of the cortex. In this project, the investigators will partition the thalamus by projecting the functional partition of the cortex onto the thalamus via the connectomics. The aim is to use geometric statistical mapping methods to produce a statistically informed partition of an individual patient's thalamus. The primary driving motivation is to eventually improve outcomes of deep brain stimulation as a therapy for essential tremor, in which the thalamus is the primary target. The subcortical white matter is also implicated in many neurological disorders, such as ischemic vascular disease, Huntington's, Multiple Sclerosis, and HIV/AIDS dementia. The PIs envision that the statistical techniques developed for qualifying the detailed architecture of the white matter in the normal population will have implications for all these diseases. This project will provide novel analytical tools to unravel the mysteries of the human brain.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1631329","NCS-FO: Probing the Functional Significance of Brain Oscillations through Closed-Loop Phase-Locked Stimulation","IIS","IntgStrat Undst Neurl&Cogn Sys","09/01/2016","01/30/2017","Jochen Ditterich","CA","University of California-Davis","Standard Grant","Kenneth Whang","08/31/2021","$802,272.00","Naoki Saito, W. Martin Usrey","jditterich@ucdavis.edu","OR/Sponsored Programs","Davis","CA","956186134","5307547700","CSE","8624","8089, 8091, 8551","$0.00","Oscillatory activity in the brain has been known for a long time, but its functional significance is still being debated. It has recently been proposed that neural oscillations play an important role in controlling how information flows in the brain and which ensembles of neurons are able to exchange information, allowing the brain to flexibly adjust to varying task demands. While this view has been supported by recordings of brain activity from particular subsystems, a rigorous test of the ideas requires manipulation of brain activity to establish a causal link between synchronized brain activity and neural communication. While experimental techniques for generally suppressing or enhancing neural activity are readily available, addressing this scientific question requires new technology for manipulating neural activity with a precise timing relationship relative to ongoing neural activity. The goal of this research project is to develop a closed-loop stimulation system that can analyze ongoing brain oscillations in real time and that uses the resulting information to trigger neural stimulation. This allows manipulating neural activity time-locked to ongoing activity at another location in the brain. Sharing this tool with the scientific community is expected to provide novel, fundamental insights into the functional significance of synchronized brain activity in a variety of neural systems, which cannot be obtained with currently available technology. The technique might also find application in neural prostheses and brain stimulation systems for the treatment of neurologic and psychiatric disorders. <br/><br/>The project involves: 1) Developing an algorithm that reliably extracts instantaneous frequency and phase of a dominant oscillatory component from a local field potential and accurately predicts the next occurrence of particular phase angles. 2) Implementing the algorithm(s) in a combination of software and hardware that is fast enough for real-time control of a stimulation device. 3) Validating the closed-loop stimulation technique in vivo and developing applications for studying cortico-cortical and thalamo-cortical communication. Successful development of such a system would remove a major obstacle for testing theories about the functional significance of the timing of neural signals, in particular synchronized rhythmic activity. It would allow going beyond correlational measures and exploring the behavioral (and neural) consequences of artificial manipulation of neural signals contingent on the timing of currently ongoing neural activity. With the help of this technology, a major advance in understanding the role of the timing of neural signals in coding and transmitting information between ensembles of neurons is expected."
"1912037","CRCNS Research Proposal: Collaborative Research: The Space of Riemannian Metrics for the Statistical Analysis of the Human Connectome","DMS","MSPA-INTERDISCIPLINARY","08/15/2019","08/06/2019","Martin Bauer","FL","Florida State University","Standard Grant","Junping Wang","07/31/2022","$249,937.00","","bauer@math.fsu.edu","874 Traditions Way, 3rd Floor","TALLAHASSEE","FL","323064166","8506445260","MPS","7454","7327, 8089, 8091","$0.00","The human brain is one of the most complex biological geometrical objects. The Human Connectome Project aims to make available an unparalleled compilation of neural functional and structural imaging data from healthy adults. Data from over 900 subjects has already been released. The principal data provided by the Human Connectome Project are diffusion-weighted MRI and functional MRI. Due to the amount and complexity of the data generated in this project, new techniques to analyze, compare and represent these data are needed, which is the motivation and driving force for the research outlined in this proposal. This collaborative project has three fundamental goals: (1) to further develop the mathematical theory of geometrical statistics, in particular the role of the infinite-dimensional manifold of all Riemannian metrics; (2) to develop practical tools for the statistical study of the connectivity of the human brain; and (3) to demonstrate the utility of the developed techniques for the segmentation and parcellation of the thalamus and other subareas of the subcortical gray matter that are not visible in structural MRI. <br/><br/>This project will develop for the first time statistical techniques on the infinite-dimensional manifold of Riemannian metrics. The project team believes that the space of Riemannian metrics is the natural framework for analyzing the variability of the architecture of the human brain. Diffusion-weighted MRI allows the investigators to model an individual human brain as a Riemannian manifold with axonal connections that are geodesic curves of an appropriate metric. The team will study the space of all Riemannian metrics and develop methods based on geometrical statistics for the analysis of the whole population. An immediate practical application of the techniques developed will be the parcellation of the thalamus based on thalamocortical connectivity. The internal architecture of the thalamus is not visible in standard structural MRI but rather is defined via the connections to the different areas of the cortex. In this project, the investigators will partition the thalamus by projecting the functional partition of the cortex onto the thalamus via the connectomics. The aim is to use geometric statistical mapping methods to produce a statistically informed partition of an individual patient's thalamus. The primary driving motivation is to eventually improve outcomes of deep brain stimulation as a therapy for essential tremor, in which the thalamus is the primary target. The subcortical white matter is also implicated in many neurological disorders, such as ischemic vascular disease, Huntington's, Multiple Sclerosis, and HIV/AIDS dementia. The PIs envision that the statistical techniques developed for qualifying the detailed architecture of the white matter in the normal population will have implications for all these diseases. This project will provide novel analytical tools to unravel the mysteries of the human brain.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1640893","SL- CN: The role of gesture in mathematics learning: from research to practice","SMA","Science of Learning, ECR-EHR Core Research","09/01/2016","08/11/2016","Susan Goldin-Meadow","IL","University of Chicago","Standard Grant","Soo-Siang Lim","08/31/2021","$747,903.00","Ruth Church","sgm@uchicago.edu","6054 South Drexel Avenue","Chicago","IL","606372612","7737028669","SBE","004Y, 7980","1545, 8089, 8091","$0.00","This Science of Learning Collaborative Network brings together researchers and practitioners at the University of Chicago and Northeastern Illinois University to investigate the impact of nonverbal cues on math learning, and to develop online math lessons accessible to diverse learners based on this research-based evidence.  Online education offers the promise that it can serve as an ""equity lever"" by making education accessible to all children, including low-income and disadvantaged children. But it is not clear that online teaching is as effective as face-to-face teaching, in part because it eliminates many of the nonverbal cues, including gesture, that have been found to promote learning. This network will conduct basic research exploring the impact that nonverbal cues have on math learning in both deaf and hearing children, and then use this research to develop online instruction that makes effective use of nonverbal cues for diverse learners. Deaf scientists are underrepresented in Science, Technology, Engineering and Mathematics (STEM) fields, suggesting a pipeline problem for deaf students and highlighting a need to improve math teaching for these students. The studies will also consider the socioeconomic levels of the homes from which the students come, and thus have relevance not only to learners who come to school from privileged backgrounds, but also to learners who have access to fewer resources. <br/><br/>This Science of Learning Collaborative Network consists of collaborators representing ten universities from psychology, linguistics, computer science, and neuroscience with three types of expertise: scientists who study gesture and its role in learning math and science; scientists who study language development from a linguistic perspective; and scientists who are at the intersection of basic and applied research, and are involved in educational practice or policy and technology development. The purpose of the network is three-fold: (1) To advance knowledge of the impact that nonverbal cues have on mathematics instruction. (2) To explore whether nonverbal cues have different effects on different learners, in particular hearing vs. deaf learners from low vs. high SES homes. (3) To translate research into practice by developing an online teaching tool that is accessible to learners with diverse backgrounds. The proposed studies involve presenting lessons on mathematical equivalence and fraction magnitudes in different input mediums to different groups of learners. The studies include quantitative measures of behavioral and neurological learning outcomes. The research findings will be used to inform the development of online math lessons that can be adapted to the needs of different types of learners. <br/><br/>The award is from the Science of Learning-Collaborative Networks (SL-CN) Program, with funding from the SBE Division of Behavioral and Cognitive Sciences (BCS), the SBE Office of Multidisciplinary Activities (SMA), the EHR Core Research (ECR) Program, and the CISE Division of Computer and Network Systems (CNS)."
"1561716","Cognitive and Neural Correlates of Mathematics Problem Solving Using Diagnostic Modeling and Dynamic Real-Time fMRI","DRL","ECR-EHR Core Research","08/01/2016","07/30/2019","Curtis Tatsuoka","OH","Case Western Reserve University","Standard Grant","Gregg Solomon","07/31/2021","$1,699,573.00","Satya Sahoo, H. Gerry Taylor, Sarah Carr","cmt66@case.edu","Nord Hall, Suite 615","CLEVELAND","OH","441064901","2163684510","EHR","7980","1545, 8089, 8091, 8212, 8551, 8817","$0.00","The broad objective of this study, led by a team of researchers at Case Western Reserve University, is to further understanding of the neural and cognitive basis for mathematics learning. The focus will be on mathematics problem-solving strategies used by adolescents, and how these strategies are adopted and changed as problems become systematically more difficult. The project will examine the association of these strategies with mathematics-related cognitive skills, scores on tests of mathematics achievement, and patterns of brain activations displayed by adolescents while engaged in these strategies. Problem-solving strategies are of interest because of their relation to higher-level mathematic achievement and the insights they can offer into the basis of individual differences in mathematics learning. The longer-term objective of the project is to discover new ways to tailor mathematical learning strategies to individual cognitive and neural capacities. The project will also undertake innovative methods of collecting information about neural functioning during math tasks with the potential to influence future studies of the brain systems involved in learning and behavior. The project is funded by the EHR (Education and Human Resources directorate) Core Research program, which supports fundamental research that advances the literature on STEM (Science, Technology, Engineering and Mathematics) learning. <br/><br/>Participants will be adolescents, 14-16 years of age, who were previously enrolled in a longitudinal study of the consequences of preterm versus term birth on academic progress across the first 3 years in school. Measures will include tests of spatial skills, attention, executive functions such as working memory, number sense, and mathematics achievement; sets of mental arithmetic and fractions problems of varying difficulty designed to reveal individual differences in problem-solving strategies; and functional magnetic resonance imaging (fMRI) procedures to examine the neural correlates of these strategies. Following piloting with a separate sample of young adults, cognitive and achievement tests and assessments of problem-solving strategies will be administered to 100 adolescents, 50 of whom will be selected on the basis of their problem-solving strategies to complete in-magnet problem-solving tasks. Adolescents with more advanced problem-solving strategies (characterized by reliance on retrieval of solutions) are hypothesized to display more intact cognitive profiles and higher levels of mathematics achievement than those using less advanced approaches (characterized by more effortful multi-step procedures). Adolescents using more advanced strategies are also hypothesized to show patterns of brain activation in regions specialized for efficient mathematics processing, such as the hippocampus and posterior parietal region, as compared to regions that are less specialized such as the prefrontal area. These participants are also expected to display less pronounced changes in activation patterns with increased problem difficulty, suggestive of greater neural efficiency in mathematics problem-solving and less reliance on compensatory systems. The project will include novel statistical methods for cognitive modeling and an exciting new approach to assess brain functioning during math problem solving. This research will provide insight into the cognitive skills and neural processes associated with successful strategy adoption for problem solving, with an emphasis on neural capacity, efficiency, and compensation."
"1718705","CHS: Small: Auditory and Haptic Based Brain-Computer Interfaces Using In-Ear Electrodes","IIS","HCC-Human-Centered Computing, IntgStrat Undst Neurl&Cogn Sys","09/01/2017","08/16/2017","Melody Jackson","GA","Georgia Tech Research Corporation","Standard Grant","Ephraim Glinert","08/31/2021","$497,745.00","","melody@cc.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7367, 8624","7367, 7923, 8089, 8091","$0.00","Brain Computer Interfaces (BCIs) are systems that allow people to control computers and other devices with brain signals alone.   BCIs have the potential to improve the lives of many individuals with severe physical disabilities, by allowing them to communicate and control their environment without needing muscle movement or voice.  After more than two decades of research, BCIs have become robust and reliable enough to consider them for mainstream applications, such as hands-free and voice-free control of devices.  However, the most common BCIs require visual attention, which restricts their utility for people with visual impairments, or for mobile environments (such as driving) where diverting visual attention is dangerous or not possible.  Intriguing alternatives to visual displays are auditory (sounds) or haptic (touch or sensations such as vibrations) based BCI interfaces, or multimodal BCI interfaces which are a combination of these.  In addition to providing an alternate interface for people with visual impairments or for special purposes, nonvisual BCI control of devices could also be useful in everyday life, such as when responding to a text message in a movie theater without looking at a device screen or speaking.  This project will extend the state of the art in BCIs by evolving the body of knowledge in auditory, haptic, and multimodal stimuli, which are relatively unexplored areas of the field.  Additionally, the research will create and explore small, wearable in-ear electrodes to detect brain signals, and thus will contribute to the emerging field of mobile BCIs which will open possibilities for large numbers of mainstream users. Current BCI systems cover a wide and varying range of brain signals and recording technologies; this research focuses on ""evoked-response"" electroencephalograph (EEG) approaches, that is to say brain signals that are triggered due to a stimulus such as a sound, flashing light, or touch.<br/><br/>To these ends, the project will study auditory and haptic cues to determine the best ways to map them to input choices.  One of the biggest challenges with auditory and haptic interfaces is how to label a stimulus so it is meaningful to the BCI user.  To address this problem, the project will explore novel methods of encoding the labeling and mapping of auditory and haptic stimuli into the stimuli themselves (in a manner analogous to how it is possible to label visual stimuli, such as when the target is a flashing letter so the user can determine the meaning of a cue by looking at it).  The plan is to leverage research in sonification (which largely focuses on presenting data in auditory ""displays"") to devise techniques for encoding speech or patterned tones (such as Morse code) into audio cues in such a way that a user can simply listen to the cue to determine its meaning.  The team will also experiment with a variety of multimodal approaches (combining visual, auditory, and haptic cues in a single system) in order to achieve higher accuracy than is possible with a single stimulus mode alone.  Finally, the project will evaluate the effectiveness of in-ear EEG electrodes in detecting brain responses to auditory and haptic stimuli, experimenting with electrode design, placement within the ear, and various filters and classifiers to improve the signal-to-noise ratio.   The results of the experiments in alternative stimuli will be combined with the optimized wearable electrode system, to create the first hands-free, voice-free, vision-free interfaces for mainstream users."
"1839356","TRIPODS+X:EDU:  An MBI TGDA+Neuro Program for Undergraduates","CCF","TRIPODS Transdisciplinary Rese, OFFICE OF MULTIDISCIPLINARY AC, IntgStrat Undst Neurl&Cogn Sys","10/01/2018","09/10/2018","Janet Best","OH","Ohio State University","Standard Grant","Christopher Stark","09/30/2021","$199,983.00","Yusu Wang, Sebastian Kurtek, Facundo Memoli, Yune Lee","jbest@math.ohio-state.edu","Office of Sponsored Programs","Columbus","OH","432101016","6146888735","CSE","041Y, 1253, 8624","047Z, 062Z, 8089, 8091","$0.00","This project develops an educational program for undergraduate students, introducing them to methods at the forefront of modern mathematical and statistical data analysis through application to problems in neuroscience. The program consists of a one-semester interactive online course followed by an in-person research experience held at the Mathematical Bioscience Institute in Columbus, OH. Faculty from Ohio State University (OSU) and Pennsylvania State University (PSU) will lecture in the online course; participating student cohorts will reside at OSU, PSU, and a diverse collection of six additional US institutions - including two liberal arts colleges, two universities in Puerto Rico, an historically black university (HBCU), and a regional university with a primarily commuter student body. The project will introduce a modern area of research -- topological and geometric data analysis, to undergraduate students with different backgrounds and educational experiences, better preparing these students for graduate education and/or entry into the workforce. A flexible and accessible undergraduate curriculum in topological and geometric methods for the analysis of neuroscience data will be developed and made broadly available. A diverse community of educators will be trained to facilitate the delivery of the curriculum at their home institution, and their own research opportunities will be enhanced; an important outcome of the project is the engagement of experimental and mathematical neuroscientists in the emerging field of topological and geometric data analysis.<br/><br/>In this project, researchers in topological and geometric data analysis at Ohio State University (OSU) will collaborate with an experimental neuroscientist, director of the Speech, Language, and Music Lab (SLAM Lab) at OSU to develop scientific methods, curricular materials and educational projects.  Research in the SLAM lab involves the use of structural and functional MRI data to identify anatomical structures and networks underlying varied abilities in speech processing, as well as the nature of brain plasticity. A flexible and accessible undergraduate curriculum in topological and geometric methods for the analysis of neuroscience data will be developed and made broadly available. An interactive online course, using the broadband facilities of the Mathematical Biosciences Institute (MBI) will be given to undergraduates at eight institutions with participation by local faculty. A following workshop at the MBI will bring together the OSU researchers, the remote faculty and the undergraduates to work on research projects. This project provides the opportunity for two cohorts of undergraduates from eight colleges and universities to participate in a unique education/research experience and for the development of a novel curriculum in topological and geometric methods for neuroscience applications. In addition, it will allow faculty from participating institutions to learn the principles of topological and geometric data analysis, providing the opportunity to broaden their research programs to include this modern area of data science.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1822553","CRCNS Research Proposal: Collaborative Research: Modeling and Manipulating Dynamic Network Activity in the Brain","CBET","Special Initiatives, CRCNS-Computation Neuroscience","09/15/2018","09/05/2018","Constantinos Dovrolis","GA","Georgia Tech Research Corporation","Standard Grant","Aleksandr Simonian","08/31/2021","$245,000.00","","dovrolis@cc.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","ENG","1642, 7327","7327, 8089, 8091","$0.00","CRCNS Research Proposal: Collaborative Research: Modeling and Manipulating Dynamic Network Activity in the Brain<br/><br/>Connectome-based Dynamic Network Modeling (CDNM) is a recent approach in computational neuroscience, made possible by the availability of structural and functional brain connectivity data. This project aims to understand how the interaction between structure and dynamics of  neural populations leads to brain functional networks and brain states. Understanding mechanistically and being able to predict how the combination of macroscale structure and local neural activity leads to complex whole-brain dynamics is a major research goal for every aspect of brain science, ranging from basic neuroscience to clinical psychiatry and neurology. This project can also have an important impact in understanding both how Major Depressive Disorder emerges from specific structural abnormalities, and the conditions under which Deep Brain Stimulation is an effective treatment. The developed methods can be also applied to numerous other mental and neurological disorders. The project will also develop and openly disseminate new computational models, and optimization methods for speeding up the simulation of complex CDNMs. <br/><br/>The project consists of three Aims: 1) Leverage dynamic functional connectivity to further constrain and evaluate CDNM: The first goal is to clearly separate the parameterization of a CDNM from the evaluation of its accuracy. It is possible that several models, or parameterizations of the same model, lead to realistic average functional connectivity. However, not all of these models may be able to reproduce the more complex, dynamic functional connectivity patterns observed in practice. The project relies on state-of-the-art methods that infer dynamic functional connectivity between brain regions, applying these methods to both empirical data and CDNM-based simulation results. Each candidate CDNM model will be evaluated in terms of how well it can reproduce the dynamic FC patterns observed in empirical data. 2) Using CDNM to understand the connection between structural and functional connectivity in Major Depression Disorder: The ultimate test for any model is its predictive power. The project will utilize structural and functional connectivity data for a patient group that exhibits known and significant differences from healthy controls. Starting with the best model from Aim-1, that CDNM will be run on a perturbed connectome that captures the major structural abnormalities in depression. Then, the CDNM results will be analyzed to determine if the model can reproduce the FC abnormalities observed in the group of patients. 3) Modeling the effects of interventions such as deep brain stimulation: The use of this experimental treatment in depression is a ?network intervention?. CDNM can play a significant role in understanding how and when it works as an effective treatment. The effect of deep brain stimulation will be modeled by modifying either the local dynamics of certain regions or the weights of specific connections in the model, such as increasing or decreasing the weight of the connection. The project will investigate whether there is a specific weight adjustment with which the stimulated model produces dynamics that resemble the normal FC of healthy subjects. If that adjustment needs to be in a very narrow range, it might explain why deep brain stimulation is unsuccessful in some patients.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1822606","CRCNS Research Proposal: Collaborative Research: Modeling and Manipulating Dynamic Network Activity in the Brain","CBET","Special Initiatives","09/15/2018","09/05/2018","Shella Keilholz","GA","Emory University","Standard Grant","Aleksandr Simonian","08/31/2021","$236,999.00","Helen Mayberg","shella.keilholz@bme.gatech.edu","1599 Clifton Rd NE, 4th Floor","Atlanta","GA","303224250","4047272503","ENG","1642","7327, 8089, 8091","$0.00","CRCNS Research Proposal: Collaborative Research: Modeling and Manipulating Dynamic Network Activity in the Brain<br/><br/>Connectome-based Dynamic Network Modeling (CDNM) is a recent approach in computational neuroscience, made possible by the availability of structural and functional brain connectivity data. This project aims to understand how the interaction between structure and dynamics of  neural populations leads to brain functional networks and brain states. Understanding mechanistically and being able to predict how the combination of macroscale structure and local neural activity leads to complex whole-brain dynamics is a major research goal for every aspect of brain science, ranging from basic neuroscience to clinical psychiatry and neurology. This project can also have an important impact in understanding both how Major Depressive Disorder emerges from specific structural abnormalities, and the conditions under which Deep Brain Stimulation is an effective treatment. The developed methods can be also applied to numerous other mental and neurological disorders. The project will also develop and openly disseminate new computational models, and optimization methods for speeding up the simulation of complex CDNMs. <br/><br/>The project consists of three Aims: 1) Leverage dynamic functional connectivity to further constrain and evaluate CDNM: The first goal is to clearly separate the parameterization of a CDNM from the evaluation of its accuracy. It is possible that several models, or parameterizations of the same model, lead to realistic average functional connectivity. However, not all of these models may be able to reproduce the more complex, dynamic functional connectivity patterns observed in practice. The project relies on state-of-the-art methods that infer dynamic functional connectivity between brain regions, applying these methods to both empirical data and CDNM-based simulation results. Each candidate CDNM model will be evaluated in terms of how well it can reproduce the dynamic FC patterns observed in empirical data. 2) Using CDNM to understand the connection between structural and functional connectivity in Major Depression Disorder: The ultimate test for any model is its predictive power. The project will utilize structural and functional connectivity data for a patient group that exhibits known and significant differences from healthy controls. Starting with the best model from Aim-1, that CDNM will be run on a perturbed connectome that captures the major structural abnormalities in depression. Then, the CDNM results will be analyzed to determine if the model can reproduce the FC abnormalities observed in the group of patients. 3) Modeling the effects of interventions such as deep brain stimulation: The use of this experimental treatment in depression is a ?network intervention?. CDNM can play a significant role in understanding how and when it works as an effective treatment. The effect of deep brain stimulation will be modeled by modifying either the local dynamics of certain regions or the weights of specific connections in the model, such as increasing or decreasing the weight of the connection. The project will investigate whether there is a specific weight adjustment with which the stimulated model produces dynamics that resemble the normal FC of healthy subjects. If that adjustment needs to be in a very narrow range, it might explain why deep brain stimulation is unsuccessful in some patients.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1920510","Modeling Brain and Behavior to Uncover the Eye-Brain-Mind Link during Complex Learning","DRL","ECR-EHR Core Research","09/01/2019","07/22/2019","Sidney D'Mello","CO","University of Colorado at Boulder","Continuing Grant","Gregg Solomon","08/31/2022","$691,498.00","Leanne Hirshfield","sidney.dmello@gmail.com","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","EHR","7980","8089, 8091, 8244, 8817","$0.00","The project, based at the University of Colorado, will advance fundamental knowledge on learning from complex STEM texts. This is a critical skill for success in an increasingly information-driven world and workforce, but it is also an area where students consistently struggle. Scores on standardized assessments are stubbornly stagnant, troublesome achievement gaps remain, and the U.S. continues to lag behind its international peers. This is especially relevant to the reading of complex STEM content. The main idea of the project is that learning from text is fundamentally about the coordination of vision (the eye) with thought (the mind) in a manner constrained by the content (the text), the context (the task), and the individual (the learner). Thus, there is a need to understand how these factors interact in order to advance basic knowledge and to inform effective interventions. The team will study how brain and behavioral signals can be used to understand the reading process and associated learning outcomes in a manner that is sensitive to individual differences. Anticipated near-term broader impacts include the interdisciplinary training of students, especially those from groups underrepresented in STEM fields, community outreach, and promoting scientific reasoning skills relevant to multiple STEM areas. In the longer term, the results of the project will inform the design of future interventions that aim to make learning from text more efficient, engaging, and effective. The project is funded by the EHR Core Research (ECR) program, which supports work that advances the fundamental research literature on STEM learning.<br/><br/>The intellectual merit of the project is to gain fundamental knowledge on how the eye and brain dynamically coordinate to construct mental representations during complex learning from STEM texts. The project will address this goal by collecting eye movements, reading behaviors, noninvasive brain signals, and learning outcomes from high-school and college students in controlled lab settings and in school environments. It is expected that students will improve critical thinking and scientific reasoning skills by engaging with multiple texts on scientific research methods. The project will use behavioral (eye tracking and reading times) and non-invasive brain measures (high-density functional near-infrared spectroscopy and electroencephalography) to identify neurobehavioral markers of core processes involved in reading comprehension (e.g., focused attention vs. mind wandering, inference generation and elaboration) and the extent to which these measures can predict learning outcomes (comprehension, knowledge, and transfer) assessed immediately after learning and a week later. The project will also leverage advances in deep machine learning to build computational neurobehavioral models of the process and outcome variables in a manner that is sensitive to textual difficulty and to individual differences (e.g., prior knowledge, interest). Thus, the project will advance fundamental knowledge by integrating three research areas: theories of low-level reading processes and associated models of eye movements, models of higher-order STEM text comprehension including multiple document comprehension, and emerging research on the cognitive neuroscience of reading including co-registration with eye movements.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1532061","MRI: Development of an Integrated Neuroimaging Instrument with Temporal and Spatial Alignments for Brain Research","CNS","Major Research Instrumentation, Information Technology Researc, CI REUSE, CSR-Computer Systems Research, IntgStrat Undst Neurl&Cogn Sys","09/15/2015","08/13/2020","Malek Adjouadi","FL","Florida International University","Standard Grant","Rita Rodriguez","08/31/2021","$3,955,110.00","Naphtali Rishe, Angela Laird, Mercedes Cabrerizo, Sergio Gonzalez-Arias","adjouadi@fiu.edu","11200 SW 8TH ST","Miami","FL","331990001","3053482494","CSE","1189, 1640, 6892, 7354, 8624","1189, 7433, 8089, 8091, 9229","$0.00","This project, developing a new integrated instrument for neuroimaging and brain mapping, based on specialized software and unique hardware designs, aims to elicit new understanding of the functional mappings of the brain in its normal and pathology states focusing on key neurological disorders. Envisioning the brain in terms of the structural, functional, and brain connectivity maps under fully integrated recording modalities breaks the barriers of very challenging time and space alignments. This also bridges scientific premises in building system designs and novel software techniques that improve the delivery of patient-care in terms of enhanced diagnosis as well as well-thought-out treatment protocols. The work focuses on challenging neurological disorders of epilepsy, Alzeimer's disease and Attention Deficit/Hyperactivity Disorder (ADD-ADHD) and related cognitive challenges so as to provide effective subject-centric care. The general construct of the software algorithms and the hardware components of this instrument facilitates research endeavors and applications that extend to other neurological disorders (such as Parkinson) to be addressed using novel hardware interfaces and related software modules and protocols. <br/><br/>This project utilizes a unique approach at collecting data in a fully integrated setting across different recording modalities to elicit new understanding of the functional mapping of the brain and in delineating normal state from the specific pathology state of these challenging neurological disorders. It performs pioneering work on integration in a same setting of non-invasive navigated transcranial magnetic stimulation (TMS) for mapping the eloquent cortex and instigating new protocols with embedded alignments and full registration to                                                                                                         <br/>  - Neuro-navigation and pre-surgical evaluation,  <br/>  - Anatomical and functional MRI for MRI/fMRI-guided magnetic stimulation, and<br/>  - Microcoil designs embedded into MRI and fully integrated with EEG electrodes for pinpointed TMS-MRI-fMRI and EEG integration, all of which are to yield a fully integrated instrument with the ability to augment capabilities for mapping, analysis, and diagnosis, followed by elaborate intervention and treatment protocols for these different neurological disorders."
"1607486","US-German Research Proposal: Neurocomputation in the Visual Periphery: Experiments and Models","IIS","CRCNS-Computation Neuroscience, Robust Intelligence","12/01/2016","09/19/2017","Ruth Rosenholtz","MA","Massachusetts Institute of Technology","Continuing Grant","Kenneth Whang","11/30/2021","$681,746.00","","rruth@mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","7327, 7495","7327, 8089, 8091","$0.00","Peripheral vision comprises over 99.99% of the visual field. Its strengths and limitations strongly constrain visual perception -- what humans can see at a glance, and the processes by which they move their eyes to piece together information about the world. Peripheral vision differs from foveal vision in complex and interesting ways, most importantly due to ""crowding,"" in which identifying a peripheral stimulus can be substantially impaired by the presence of other, nearby stimuli. This project will examine the nature of the encoding in visual cortex, through development and testing of a set of models of peripheral vision. These models will be targeted at answering key questions about the neurobiological mechanisms. The collaborating investigators, in the US and Germany, will develop models and create a benchmark dataset of behavioral results to be explained. The models and dataset will be made freely available, to aid other researchers and to inform the development of applications such as heads up displays and user interfaces. This work will provide insight into what features are encoded in visual cortex, as well as what tradeoffs may have led the visual system to develop that encoding. Understanding those tradeoffs may inform computer vision which, like human vision, faces constraints on processing capacity. <br/><br/>The development of new model variants will be based on insights from neurophysiology, natural image statistics, sparse coding, and the recent success of convolutional neural networks in artificial intelligence. The investigators will gather benchmark behavioral phenomena far richer than existing crowding datasets, through a combination of studying natural image tasks and model-driven experiments. They will then compare predictions of the new models, as well as of Dr. Rosenholtz's existing high-performing model of peripheral vision, on the benchmark dataset. Doing so will identify the best-performing model(s), and answer key questions about the nature of pooling computations and of non-linear operators, and about the complexity, nature, and purpose of the features encoded by peripheral vision.<br/><br/>A companion project is being funded by the Federal Ministry of Education and Research, Germany (BMBF)."
"1844724","CAREER: Understanding visual learning with self-supervised neural network models","IIS","Robust Intelligence, IntgStrat Undst Neurl&Cogn Sys","09/01/2019","08/12/2020","Daniel Yamins","CA","Stanford University","Continuing Grant","Kenneth Whang","08/31/2024","$600,000.00","","yamins@cs.stanford.edu","450 Jane Stanford Way","Stanford","CA","943052004","6507232300","CSE","7495, 8624","1045, 7495, 8089, 8091","$0.00","A central problem in artificial intelligence today is that machine learning algorithms often require supervised training with huge amounts of hand-curated data. As a result, such algorithms are largely limited in scope to domains where well-funded organizations can build massive, expertly-annotated, and typically proprietary, labelled datasets. In contrast, real biological systems such as human infants learn much more efficiently, combining a small amount of explicit supervision with powerful -- but not fully understood -- mechanisms of self-supervision. This proposal seeks to build biologically-inspired general-purpose self-supervised systems that can learn without needing to be spoon-fed millions of labeled examples. <br/><br/>The basic strategy to achieve this goal will be to develop and refine techniques in the emerging field of unsupervised deep learning, in which neural networks train themselves to capture the subtle statistical patterns present in their sensory surroundings. These networks will be augmented to operate as agents in a rich interactive physical domain, where they will seek out challenging but ultimately solvable self-supervised ""goals"" that will teach them to flexibly represent and respond to their environment. If successful, such systems will have the ability to use the wealth of unlabeled data that is ubiquitously available in the physical world. The proposal also seeks to use these algorithmic ideas as hypotheses for quantitative models of learning in real biological systems. Using recently developed techniques from computational neuroscience, the neural networks will be compared to neural and behavioral data collected using a wide spectrum of experimental paradigms. It will then be determined which self-supervised neural network learning models best capture the empirical data -- and equally importantly, where the most glaring mismatches between experiment and computational models lie. Quantifying these model-data comparisons will in turn allow for feedback to build better neural network algorithms. The ultimate goal of this work is to set up a tight loop between experimental observation and computational algorithm development, accelerating progress both in artificial intelligence and neuroscience.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2024587","Collaborative Research:NCS-FO: How cognitive maps potentiate new learning: constraining a computational model by decoding the thoughts of superior memorists","DRL","IntgStrat Undst Neurl&Cogn Sys","09/01/2020","08/11/2020","Kenneth Norman","NJ","Princeton University","Standard Grant","Gregg Solomon","08/31/2023","$230,000.00","","knorman@princeton.edu","Off. of Research & Proj. Admin.","Princeton","NJ","085442020","6092583090","EHR","8624","8089, 8091, 8551","$0.00","This project will break new ground in the study of memory by partnering with competitors in the USA Memory Championship.  These competitors are not savants, but instead are well-practiced in the use of mnemonic techniques and, as a result, exhibit enhanced powers of memory on a range of real-world tasks, such as memorizing the items on a shopping list.  All of these techniques rely on the practitioner structuring prior knowledge in very specific ways that facilitate the incorporation of new information.  By scanning the brains of these trained memorists with functional magnetic resonance imaging (fMRI) and comparing their brain activity to participants who are learning these mnemonic systems for the first time, the researchers will identify principles for optimal scaffolding: How can prior knowledge be structured and used to most effectively support new learning? Identifying these principles will improve our fundamental understanding of real world-memory and will also lay the foundation for future educational interventions based on these principles. This project is funded by Integrative Strategies for Understanding Neural and Cognitive Systems (NCS), a multidisciplinary program jointly supported by the Directorates for Computer and Information Science and Engineering (CISE), Education and Human Resources (EHR), Engineering (ENG), and Social, Behavioral, and Economic Sciences (SBE). <br/> <br/>The goal of the project is to extend theories of memory to address how people can optimally use cognitive maps (structured prior knowledge) to support new learning. Reinforcement learning algorithms will be applied to computational models of memory to make predictions about which strategies will result in the best performance, factoring in biological constraints on the human memory system. Model predictions about optimal memory strategies will be tested using fMRI data from memory experts who have spent years optimizing their ability to bind arbitrary information to an internal cognitive map (a ?memory palace?), and who therefore serve as a unique comparison group for optimized memory models; these subjects will be compared to a sample of young adult subjects who are being trained to use these memorization techniques. New neuroimaging approaches developed by the researchers will allow them to map the brain patterns corresponding to each room of the memory palace and the patterns corresponding to each individual memory, and then track the activation of these patterns as subjects recall memories using mental walks through their palace. Results of these analyses will be used to test detailed model predictions about how memory training will alter the structure and use of subjects? cognitive maps, and how these changes relate to memory performance. As a final test of the models, the researchers will use neural measurements of individual subjects? cognitive maps to predict which specific items they will recall. By examining how prior knowledge is deployed to support learning in experts and novices at a much finer resolution than was previously possible, this work will provide the foundation for understanding why wide variations in memory performance exist across individuals and how memory can be improved, paving the way for targeted interventions to improve memory performance.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1926352","NCS-FO: The evolutionary origins of leadership in chimpanzees: from individual minds to collective action","BCS","ECR-EHR Core Research, IntgStrat Undst Neurl&Cogn Sys","08/15/2019","08/29/2019","Melissa Thompson","NM","University of New Mexico","Standard Grant","Betty Tuller","07/31/2022","$114,263.00","Martin Muller","memery@unm.edu","1700 Lomas Blvd. NE, Suite 2200","Albuquerque","NM","871310001","5052774186","SBE","7980, 8624","8089, 8091, 8551, 8817, 9150","$0.00","Leadership is crucial for effective cooperation, especially in large and complex groups. Yet there is an empirical and theoretical gap in our understanding of the individual-level processes underpinning leadership and the group-level consequences of leadership. How does the cognition of individual leaders translate into coordinated group action in the real world?  This project proposes using chimpanzees as a new model of human-like leadership to better understand the evolutionary origins of our own leadership patterns. We will bridge the gap between individual- and group-level phenomena by conducting matched research with semi-free ranging chimpanzees living in a sanctuary where we can do detailed assessments of cognition, and with chimpanzees living in the wild where we can look at complex group behavior in a natural setting. By matching datasets across these two contexts, we will be able to see how individual cognitive process translate into group action. While humans are thought to be uniquely able to establish leadership through prestige and collaboration instead of just pure physical domination, chimpanzees are our closest living relative, also show variation in how individuals obtain and maintain status in their groups. This project will therefore illuminate the evolutionary origins of human leadership, and also set a new agenda in evolutionary cognitive science for studying cognition in the wild. Training, education, and outreach from elementary school through to graduate school will be integrated throughout the project both domestically and abroad. As part of this proposal, we will develop a leadership module for children, using animal models to demonstrate different forms of leadership. We will implement this module through outreach at local schools and museums in the US and in 16 primary schools in Uganda. Undergraduates and high school students in the US will gain hand-on research experience through internships and in coursework. Two postdoctoral researchers and a graduate student will further gain international research experiences in the course of the project. This integrated approach to research and education will train a new generation of evolutionary cognitive scientists and disseminate primate research to the public.<br/><br/>This project has three specific aims. The first aim is to identify individual leaders (those with outsized influence) in natural social groups across multiple contexts of behavior including dominance rank, initiation of group movements, resource acquisition, within-group mediation and inter-group aggression. The second aim is to create leadership profiles by characterizing individual variation in the cognitive, behavioral, and physiological mechanisms of leaders across these contexts. At the sanctuary, 100+ chimpanzees across 5 social groups will be assayed for cognition (including social cognition, cooperation, and executive function); temperament; behavior (aggression and affiliation), and physiology (hormones and body size) to predict leadership. At the field site, similar assessments will be made of temperament, behavior, and physiology, drawing on a longitudinal database with 30 years of data on 150 wild chimpanzees. These data will be used to test the hypothesis that there are distinct pathways to leadership in chimpanzees, with intimidation-based and cooperative strategies being the most important, but knowledge and motivation anchoring some forms of leadership. The final aim is to understand how variation in leadership styles shapes the outcomes of collective action by examining several short-and long-term metrics of leadership success, including group cohesion, rewards received, and biological outcomes like reproductive success that can only be studied in the wild. This project will bridge individual-level and group-level perspectives on cognition, behavior, and physiology by leveraging the strengths of two natural populations of chimpanzees. The project will match experimental and observational techniques across sites on a scale never previously done, and will develop chimpanzees as a new model for human leadership.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2024622","Collaborative Research:NCS-FO: How cognitive maps potentiate new learning: constraining a computational model by decoding the thoughts of superior memorists","DRL","ECR-EHR Core Research, IntgStrat Undst Neurl&Cogn Sys","09/01/2020","08/11/2020","Christopher Baldassano","NY","Columbia University","Standard Grant","Gregg Solomon","08/31/2023","$516,701.00","","c.baldassano@columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","EHR","7980, 8624","8089, 8091, 8551","$0.00","This project will break new ground in the study of memory by partnering with competitors in the USA Memory Championship.  These competitors are not savants, but instead are well-practiced in the use of mnemonic techniques and, as a result, exhibit enhanced powers of memory on a range of real-world tasks, such as memorizing the items on a shopping list.  All of these techniques rely on the practitioner structuring prior knowledge in very specific ways that facilitate the incorporation of new information.  By scanning the brains of these trained memorists with functional magnetic resonance imaging (fMRI) and comparing their brain activity to participants who are learning these mnemonic systems for the first time, the researchers will identify principles for optimal scaffolding: How can prior knowledge be structured and used to most effectively support new learning? Identifying these principles will improve our fundamental understanding of real world-memory and will also lay the foundation for future educational interventions based on these principles. This project is funded by Integrative Strategies for Understanding Neural and Cognitive Systems (NCS), a multidisciplinary program jointly supported by the Directorates for Computer and Information Science and Engineering (CISE), Education and Human Resources (EHR), Engineering (ENG), and Social, Behavioral, and Economic Sciences (SBE). <br/> <br/>The goal of the project is to extend theories of memory to address how people can optimally use cognitive maps (structured prior knowledge) to support new learning. Reinforcement learning algorithms will be applied to computational models of memory to make predictions about which strategies will result in the best performance, factoring in biological constraints on the human memory system. Model predictions about optimal memory strategies will be tested using fMRI data from memory experts who have spent years optimizing their ability to bind arbitrary information to an internal cognitive map (a ?memory palace?), and who therefore serve as a unique comparison group for optimized memory models; these subjects will be compared to a sample of young adult subjects who are being trained to use these memorization techniques. New neuroimaging approaches developed by the researchers will allow them to map the brain patterns corresponding to each room of the memory palace and the patterns corresponding to each individual memory, and then track the activation of these patterns as subjects recall memories using mental walks through their palace. Results of these analyses will be used to test detailed model predictions about how memory training will alter the structure and use of subjects? cognitive maps, and how these changes relate to memory performance. As a final test of the models, the researchers will use neural measurements of individual subjects? cognitive maps to predict which specific items they will recall. By examining how prior knowledge is deployed to support learning in experts and novices at a much finer resolution than was previously possible, this work will provide the foundation for understanding why wide variations in memory performance exist across individuals and how memory can be improved, paving the way for targeted interventions to improve memory performance.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2024679","Collaborative Research:NCS-FO: How cognitive maps potentiate new learning: constraining a computational model by decoding the thoughts of superior memorists","DRL","ECR-EHR Core Research","09/01/2020","08/11/2020","Robert Ajemian","MA","Massachusetts Institute of Technology","Standard Grant","Gregg Solomon","08/31/2023","$252,595.00","","ajemian@mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","EHR","7980","8089, 8091, 8551","$0.00","This project will break new ground in the study of memory by partnering with competitors in the USA Memory Championship.  These competitors are not savants, but instead are well-practiced in the use of mnemonic techniques and, as a result, exhibit enhanced powers of memory on a range of real-world tasks, such as memorizing the items on a shopping list.  All of these techniques rely on the practitioner structuring prior knowledge in very specific ways that facilitate the incorporation of new information.  By scanning the brains of these trained memorists with functional magnetic resonance imaging (fMRI) and comparing their brain activity to participants who are learning these mnemonic systems for the first time, the researchers will identify principles for optimal scaffolding: How can prior knowledge be structured and used to most effectively support new learning? Identifying these principles will improve our fundamental understanding of real world-memory and will also lay the foundation for future educational interventions based on these principles. This project is funded by Integrative Strategies for Understanding Neural and Cognitive Systems (NCS), a multidisciplinary program jointly supported by the Directorates for Computer and Information Science and Engineering (CISE), Education and Human Resources (EHR), Engineering (ENG), and Social, Behavioral, and Economic Sciences (SBE). <br/> <br/>The goal of the project is to extend theories of memory to address how people can optimally use cognitive maps (structured prior knowledge) to support new learning. Reinforcement learning algorithms will be applied to computational models of memory to make predictions about which strategies will result in the best performance, factoring in biological constraints on the human memory system. Model predictions about optimal memory strategies will be tested using fMRI data from memory experts who have spent years optimizing their ability to bind arbitrary information to an internal cognitive map (a ?memory palace?), and who therefore serve as a unique comparison group for optimized memory models; these subjects will be compared to a sample of young adult subjects who are being trained to use these memorization techniques. New neuroimaging approaches developed by the researchers will allow them to map the brain patterns corresponding to each room of the memory palace and the patterns corresponding to each individual memory, and then track the activation of these patterns as subjects recall memories using mental walks through their palace. Results of these analyses will be used to test detailed model predictions about how memory training will alter the structure and use of subjects? cognitive maps, and how these changes relate to memory performance. As a final test of the models, the researchers will use neural measurements of individual subjects? cognitive maps to predict which specific items they will recall. By examining how prior knowledge is deployed to support learning in experts and novices at a much finer resolution than was previously possible, this work will provide the foundation for understanding why wide variations in memory performance exist across individuals and how memory can be improved, paving the way for targeted interventions to improve memory performance.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2011619","CRCNS: Discovering how touch sensors in the bat?s ?hand-wing? enable agile flight control","CBET","FD-Fluid Dynamics, Special Initiatives, CRCNS-Computation Neuroscience","08/15/2020","08/07/2020","Cynthia Moss","MD","Johns Hopkins University","Continuing Grant","Ron Joslin","07/31/2024","$1,150,000.00","Joseph Katz, Rajat Mittal, Noah Cowan, Susanne Sterbing-D'Angelo","cynthia.moss@jhu.edu","1101 E 33rd St","Baltimore","MD","212182686","4439971898","ENG","1443, 1642, 7327","7327, 8089, 8091","$0.00","Bats perform feats of aerial agility that are unique in the animal kingdom, and completely unparalleled by even the very best robotic flying machines. This project aims to discover the fundamental principles that underlie how these animals achieve such superior flight control performance. Bat flight is powered by a ?hand-wing,? i.e. the wing is actually an evolutionary adaptation of the mammalian forelimb. As such, the bat hand-wing shares the same basic anatomy as the human hand and is highly sensitive to physical forces. The bat hand-wing is highly deformable and controllable, and is unlike any artificial wing that has ever been successfully constructed. The bat hand-wing is built from a very thin membrane that stretches across its fingers and is covered with small wind-sensitive hairs that enable the animal to ?feel? the complex flow of air that envelopes its wing. This unique set of flight and sensing adaptations presents a powerful model to investigate the mechanisms of sensing, brain computation, and movement control. The multidisciplinary research team will characterize and uncover the complex coupling relationships between aerodynamics, tactile sensing, and neural processing using a combination of engineering and biological techniques. This project will lead to deeper understanding of biological flight control, and will lend insights into ingredients that could one day be used in developing new robotic aerial vehicles capable of bat-like flight performance. <br/><br/>This project integrates state-of-the-art experimental measurements and computational flow modeling with behavioral and neurophysiological experimentation and dynamical control systems neural modeling. Using a multidisciplinary approach, the team will test the hypothesis that bat wing sensors carry information about complex airflow patterns and forces to the sensory cortex. The team will also elucidate sensorimotor mechanisms that guide wing adjustments to enhance lift and prevent stall. To achieve these goals, the research includes, : 1) Quantifying the mechanical stimulus inputs to receptors on the bat hand-wing using stereo-particle-image velocimetry, digital image correlation and computational fluid dynamic modeling; 2) Encoding mechanosensory signals from the wings via multichannel neural recordings from bat primary somatosensory cortex; 3) Closed-loop modeling and real-time control based on decoded output of neural signals. This research will yield a deeper understanding of sensorimotor feedback in biological systems while also contributing novel computational and experimental tools in the arena of sensorimotor control, biophysics, and mechanics, with wide applications to many arenas of neuroscience. The project will leverage the JHU?s Women in Science and Engineering (WISE) program and Baltimore Polytechnic?s Ingenuity Project to engage high school students from diverse backgrounds.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2008501","CHS: Small: Evaluating and Optimizing Wayfinding in Healthcare Settings through Biometric Data and Virtual Response Testing","IIS","HCC-Human-Centered Computing, IntgStrat Undst Neurl&Cogn Sys","08/15/2020","08/04/2020","Saleh Kalantari","NY","Cornell University","Standard Grant","Balakrishnan Prabhakaran","07/31/2023","$415,657.00","Mahsa Shoaran","sk3268@cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","CSE","7367, 8624","7367, 7923, 8089, 8091","$0.00","Wayfinding systems are the signs, color-schemes, and other features of large, complex buildings that serve as aids in navigation. Unfortunately, wayfinding is often treated as an ""afterthought"" rather than as an integral part of the architectural design process. In healthcare facilities, difficulties in wayfinding have been shown to be a major source of stress for patients and visitors, as well as a significant burden on hospital staff members and an obstacle to operational efficiency. Testing and evaluating wayfinding systems is difficult, because each facility is unique and trying out many different wayfinding options in the same building to see which one works best would be financially and logistically implausible. Thus, there is currently no good method to rigorously compare the success of different wayfinding design strategies. To help solve this problem, the researchers will develop a new platform to evaluate and optimize wayfinding design in specific healthcare facilities before those wayfinding features are physically constructed. Virtual-reality (VR) testing will be used to accomplish this purpose. Participants in the study will don VR headsets, along with various biometric sensors to help evaluate their stress levels. They will then be asked to complete common navigational tasks in a virtual replica of a hospital building, such as finding their way from the main entrance to a specific patient room. Using a virtual replica of the building allows the researchers to easily swap out different wayfinding features, thereby determining what types of navigational aids are most effective for improving wayfinding and reducing stress. The study will contribute to the development of a new type of research platform that can be used to conduct human-response testing for many different environmental design variables, even beyond wayfinding. It will promote greater attention to the needs of building users, including minority experiences (such as those of disabled users) that have been historically overlooked in design. The ultimate goal of the project is to streamline the virtual design-testing process so that other designers and researchers can easily implement this approach and benefit from rigorous pre-construction testing.<br/><br/>The VR testing platform designed and developed as part of this project will use actual design information for planned hospital complexes, importing the data directly from commonly used designed-industry software. Study participants will experience different versions of the facilities that integrate different combinations of possible wayfinding designs. As the participants complete wayfinding tasks in the virtual buildings, the researchers will collect biometric data including electroencephalography (EEG) and electrocardiography (EKG) signals to serve as objective measures of stress and confusion, as well as behavioral data about the participants? actions in the environment and their navigational success. Self-reported data about conscious evaluations and reactions to the environment will also be collected from the participants. Two pilot studies will be conducted in the context of a healthcare facility that is currently under contract by the research team?s industry partners, testing actual wayfinding designs that may be used in the final constructed facility. The first pilot study will focus on different types and combinations of color patterns, pictograms, and architectural features for wayfinding. The second pilot study will focus on the wayfinding impact of different external view conditions (the placement of windows and various exterior landmarks). As part of the research, the team will investigate and confirm brain activity (EEG) classifiers, i.e., neural signatures, for wayfinding success, by triangulating this data with the behavioral and self-reported findings. By using these neural signatures and other biometric interpretations, the project will provide specific findings to improve the facility being investigated in the pilot tests. These results will be incorporated in a platform that will be made available to other researchers as a generalized software tool to support VR-based design testing with integrated biometric sensor data. In future work, the research platform can be extended to study other implementations of wayfinding design in different types of facilities, and potentially to examine human responses to a broad range of additional design variables. Rigorous virtual testing of architectural designs has the potential to greatly expand the evidence-based design paradigm, promoting responsible, data-driven innovation in the field and leading to more effective and healthy built environments.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1911232","RI: Small: Collaborative Research: Topology-Aware Image Understanding using Deep Variational Objectives","IIS","Robust Intelligence, IntgStrat Undst Neurl&Cogn Sys","08/15/2019","08/14/2019","Fuxin Li","OR","Oregon State University","Standard Grant","Jie Yang","07/31/2022","$173,894.00","","lif@eecs.oregonstate.edu","OREGON STATE UNIVERSITY","Corvallis","OR","973318507","5417374933","CSE","7495, 8624","7495, 7923, 8089, 8091","$0.00","Image segmentation, which extracts objects of interest from given images, is a fundamental computer vision task. This project develops novel image segmentation methodology combining classic mathematical foundations and modern deep neural networks. In particular, the developed methodology will achieve high quality in segmenting fine-scale object instances, as well as their topology. Correct segmentation of fine-details and topology such as connectivity between parts is critical for downstream analysis such as reasoning about affordance of objects - what actions can be made on them - and biomedical image analysis. This project not only bridges the gap between principled mathematical theory and the practical deep image segmentation framework, but also trains the next generation of researchers and educators. Through a carefully designed integrated educational and outreach plan, the principal investigators will engage undergraduate students, high school students, women, and other underrepresented students in the research activities.<br/><br/>This project studies deep variational relaxations of segmentation problems, namely, consider the segmentation task as a continuous valued prediction problem and employ variational functionals as training loss functions for deep neural networks. The introduction of deep learning allows highly nonlinear functions to be estimated and greatly improves the capability of variational approaches such as the Mumford-Shah functional and the persistent homology, in segmenting instances with sharp boundaries and with correct topology. Applications on robotic affordance and influence prediction and medical imaging will improve state-of-the-arts in those areas. The resulting techniques and software will be validated on image segmentation, affordance and medical imaging datasets, in order to provide quantitative assessments of the proposed approaches.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1626477","An Examination of Social Support Figures as Prepared Safety Stimuli","BCS","Social Psychology, IntgStrat Undst Neurl&Cogn Sys","08/01/2016","08/02/2016","Naomi Eisenberger","CA","University of California-Los Angeles","Standard Grant","Steven J. Breckler","07/31/2021","$563,154.00","","neisenbe@ucla.edu","10889 Wilshire Boulevard","LOS ANGELES","CA","900951406","3107940102","SBE","1332, 8624","1332, 8089, 8091","$0.00","It is crucial that people develop the ability to identify and respond to threats as they navigate the world. Yet, the process by which people learn about threatening cues is inexact, often producing excessive fears, disruptive fear responses, and anxiety. Based on the importance that close social ties have for survival, this research examines social support figures as stimuli that promote survival.  Such 'prepared safety stimuli' promote feelings of safety and may reduce threat responses.  This is in contrast to 'prepared fear stimuli' that have historically threatened human survival (e.g., snakes, spiders). Considerable research has focused on prepared fear stimuli, but little prior work has examined prepared safety stimuli. This research will develop an understanding of these unique safety signals and the beneficial role they might play in both preventing people from learning new fears and aiding people in extinguishing old ones. This research will also help to develop a deeper understanding of the role of social support figures as prepared safety stimuli. In addition, this research may illuminate avenues for improving current interventions targeted at reducing maladaptive fears and anxiety, thereby improving well-being.<br/><br/> The proposed research will bridge the social support and fear learning literatures, employing a combination of fear conditioning, social buffering, and neuroimaging methods. In a series of studies, Dr. Naomi Eisenberger at the University of California, Los Angeles, will define prepared safety stimuli and test whether social support figures fulfill those parameters. The proposed studies will further the examination of social support figures as prepared safety stimuli by examining: 1) whether social support figures, but not other familiar or rewarding stimuli (which are not turned to for social support), serve as prepared safety stimuli, 2) whether ambivalent support figures, who are sources of both positivity (support) and negativity (stress/negative affect), can serve as prepared safety stimuli, 3) whether stimuli historically associated with the presence of social support (warmth, softness) act as prepared safety stimuli, 4) the neural regions that underlie the safety effects of social support figures, and 5) whether support figures inhibit fear learning and enhance fear extinction to other stimuli. Given the prevalence of anxiety and fear-related disorders in the United States, understanding the unique functions of prepared safety stimuli and the role they might play in preventing fear learning or extinguishing learned fears has the potential to pave the way for new interventions targeted at reducing maladaptive fear and anxiety."
"2035018","EAGER: Neural Behavioral Analysis (NBA) Pipeline for Behavior and Neural Activity Analysis in Autism","IIS","Info Integration & Informatics, IntgStrat Undst Neurl&Cogn Sys","10/01/2020","07/30/2020","Qian Chen","MA","Massachusetts Institute of Technology","Standard Grant","Wei Ding","09/30/2021","$200,000.00","","qianchen@mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","7364, 8624","7364, 7916, 8089, 8091","$0.00","Naturalistic behaviors are external reflections of brain's internal integration of bottom up processes that mediate inputs sent to the brain, and top down processes that mediate appropriate responses determined by the brain. Measuring behavioral data without concurrent neuronal activity monitoring would only provide an incomplete picture of brain function. One bottleneck in the field is that these behavioral data and neuronal activity data are typically collected separately under different experimental paradigms and subsequently analyzed with different analytical pipelines. It is, therefore, impractical to infer mechanistic correlation between behavior and neural activity using these existing pipelines. A system that enables simultaneous collection of behavior and neuronal activity data followed by integrated decoding of these two types of data would be a breakthrough that offers unique opportunities to explore behavior and its governing neuron activity pattern. This project will take advantage of a clinically relevant mouse model of autism, to develop a novel machine learning based pipeline for simultaneous decoding of behavioral and neuronal activity data. By providing an novel and integrated data analytic toolkit which enables analysis of high-dimensional large data sets of behaviors and neural activities in an autistic mouse model, this project will delineate the temporal and spatial pattern of neural activities underlying social deficits and sensory abnormities which might provide a novel mechanistic link between those two keys symptoms of autism. Besides providing a powerful and versatile toolkit, this project will help fill in the critical knowledge gap between brain circuit functional changes and social behavioral deficits in autism, with the potential of strong impact on other psychiatry disorders, such as schizophrenia and bipolar disorders.<br/><br/>By developing a novel machine learning based pipeline to enable simultaneous analysis of animal behaviors and neuronal activities, this project will focus on addressing the following three research challenges: (1) concurrently collecting large data sets of mouse social behaviors and neural activity in different brain areas using intravital calcium imaging, which will be used to establish and optimize the machine learning-based neural behavioral analysis pipeline, (2) validating the neural behavioral analysis pipeline in an autistic mouse model, (3) using the neural behavioral analysis pipeline to interrogate mouse behavior and calcium imaging data from different brain areas and infer causal relation between neural activity pattern and autism-like behavior traits. Using unbiased machine learning algorithms to extract videotaped behavioral and neural imaging data in a high-throughput manner, this project will be able to make sense of neural circuit data in the context of complex behavior deficits. Successful execution of the proposal will establish a general ""computational behavior-neural function"" framework capable of identifying the hierarchy of social deficits and sensory abnormalities in autistic mice, which will provide a powerful tool to the field to untangle complex animal behavior and neuronal activity pattern for mechanistic exploration.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2024856","NCS-FO: Integrated neurocognitive process models of individual differences in children?s math problem solving strategies, learning and development","DRL","ECR-EHR Core Research, IntgStrat Undst Neurl&Cogn Sys","09/01/2020","07/24/2020","Vinod Menon","CA","Stanford University","Standard Grant","Gregg Solomon","08/31/2023","$500,000.00","","Menon@stanford.edu","450 Jane Stanford Way","Stanford","CA","943052004","6507232300","EHR","7980, 8624","8089, 8091, 8551","$0.00","The goal of this project, led by a team of researchers at Stanford University, is to develop novel neurocognitive models that integrate behavioral and neural (fMRI, functional magnetic resonance imaging) data to understand the computational, cognitive, and brain mechanisms underlying individual differences in mathematical problem solving and strategy use, the effects of training, and longitudinal development. Understanding how symbols are processed in the brain has direct implications for education and the remediation of cognitive difficulties. The researchers will perform sophisticated computational analyses on a dataset derived from children 7 to 12 years of age in an fMRI study, a tutoring study, and a longitudinal study. The findings of this study will provide a basis for customized training and will provide novel platforms for diagnostic and intervention procedures for learning difficulties. This project is funded by Integrative Strategies for Understanding Neural and Cognitive Systems (NCS), a multidisciplinary program jointly supported by the Directorates for Computer and Information Science and Engineering (CISE), Education and Human Resources (EHR), Engineering (ENG), and Social, Behavioral, and Economic Sciences (SBE).<br/><br/>This research will leverage extensive behavioral data, cognitive assessments, as well as brain imaging data, to model moment-by-moment changes in latent cognitive dynamics associated with mathematical problem solving. The multidisciplinary approach described here seeks to develop unsupervised computational models to infer differences in the latent cognitive strategies used by an individual on a trial-by-trial basis. Specifically, this project aims to (1) develop computational cognitive models for inferring latent problem-solving dynamics and strategy use, (2) develop novel integrated neurocognitive models to identify distinct and overlapping brain circuits underlying latent problem-solving dynamics and strategy use, and (3) determine integrated cognitive and neural mechanisms underlying the impact of cognitive tutoring on changes in latent problem-solving dynamics and strategy use. The planned studies will help in dissociating mathematical problem solving into multiple cognitive sub-processes, characterizing sources of individual differences across these sub-processes, identifying how each of these might relate to difficulties in problem solving, and evaluate whether these cognitive sub-processes may be remediated by cognitive tutoring programs. Ultimately, this research will enhance our understanding of dynamic cognitive processes and problem-solving strategies in children?s numerical cognition and provide new insights into latent behavioral dynamics associated with typical and atypical math abilities in children.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1533688","NCS-FO: Collaborative Research: Micro-scale Real-time Decoding and Closed-loop Modulation of Human Language","BCS","IntgStrat Undst Neurl&Cogn Sys","08/01/2015","06/10/2020","Behnaam Aazhang","TX","William Marsh Rice University","Standard Grant","Betty Tuller","07/31/2021","$736,000.00","Aydin Babakhani","aaz@rice.edu","6100 MAIN ST","Houston","TX","770051827","7133484820","SBE","8624","8089, 8091, 8551, 9251","$0.00","Humans produce language, which is a defining characteristic of our species and our civilization. We can select words precisely out of a large lexicon with remarkably low error rates. It is perhaps not surprising that this complex speech production system is easily affected by disease. Brain damage induced language disorders affect millions of Americans, and there is little hope of remediation. Research on the anatomical, physiological, and computational bases of speech production has made important strides in recent years but this has been limited by a glaring lack of information on the dynamics of the process. This limitation results from the low spatio-temporal resolution of the available tools to collect data and the effectiveness of the current tools for analysis. Our driving vision in this project is to develop an unparalleled understanding of cortical connectivity in the human language system at small spatio-temporal scales. We possess much expertise in signal decoding of the processes of cued word production with intracranial recording techniques, as well as using cortical stimulation to modulate the system. FDA-approved arrays will be used to perform closed-loop decoding of sensorimotor processes during speech production and transient neuromodulation of the language system in patients with epilepsy undergoing intracranial electrode placement for the localization of seizures. Ultimately though, the fine-grained understanding and representation of sensorimotor loops in the language system necessitates the development of ultra-small energy efficient detectors that will enable the knowledge gained in this exploratory project to be eventually applied in patients who have sustained neurological injuries that have resulted in pervasive language impairments. This integrative project brings innovative microelectronics technologies together with state of the art large data analysis techniques to begin to develop a first of its kind system to remediate language disorders.<br/><br/>The engineering objective is to develop biocompatible microchips to vastly enhance our insight into language and other cognitive processes and learning. Miniaturized microchips in silicon technology will be developed that can record neural signals, digitize them, and transmit the signals to an in vitro receiver wirelessly. The three-fold thrust of the project will be integrated when the PIs develop closed-loop real time decoding and transient neuromodulation system based on a population of miniaturized detectors and neuromodulators. The system has the potential to provide an unprecedented detailed understanding of the human language system and provide the framework and hardware for neural prosthetics in patients with aphasia and other language disorders. The project embodies multiple high-risk goals that have the potential to shift neuroengineering paradigm from recording and modulating in only a few regions of the brain to deploying a population of ultra-small and energy efficient detectors-modulators."
"1704366","RI: Medium: RUI: Collaborative Research: A Structure-Math-Function Approach for Designing Robustly Intelligent Synthetic Nervous Systems","IIS","Robust Intelligence, EPSCoR Co-Funding","10/01/2017","09/07/2017","Joshua Martin","ME","Colby College","Standard Grant","Kenneth Whang","09/30/2021","$324,958.00","","jpmartin@colby.edu","4000 Mayflower Hill","Waterville","ME","049018840","2078594342","CSE","7495, 9150","7495, 7924, 8089, 8091, 9150, 9229","$0.00","Robots are becoming integrated into more areas of life, no longer confined to the predictable environment of a factory, performing the same task. Robots that work among humans require greater intelligence and the ability to adapt to changing tasks in an unpredictable environment. This work develops a sophisticated control system for robotics by modeling the control systems in the brain of a remarkably intelligent, capable, and adaptable insect: the praying mantis. This work promises to transform our understanding of intelligence in both robotics and neuroscience. A model of decision-making in the relatively simple brains of insects advances the study of more complex brains. The model will then be used to allow a legged robot to adapt its movement to suit its goals such as assisting humans, or its ""needs"" such as seeking energy or avoiding danger. These advances seek to give robots the autonomy that animals have. Instead of being programmed for every possible situation, a robot could be trained, continue to learn from experience, and improve efficiency even in novel situations. At an after-school robotics program at an inner-city school, students will benefit from hands-on experience creating robots with the unique perspective of bio-inspired design and modeling of nervous systems.  <br/><br/>This work expands the scale and sophistication of a synthetic nervous system (SNS), a continuous time dynamical model of praying mantis nervous system, and applies it to robotic control. Multi-channel neural recording and stimulation techniques are revealing how insects simplify motor control by distributing computation throughout the nervous system. This project leverages these techniques to understand how the capability of the ""higher"" level (the brain, where sensory input is processed) is directly supported by intelligence in the ""lower"" level (ganglia that coordinate the legs). These data will be used to develop and implement an SNS to control the six-legged MantisBot, endowing it with online learning and intelligent autonomy. Neurobiology will inform this work in all three specific aims: 1) Investigate the lower-level intelligence of the mantis nervous system and use the results to increase the intelligence of MantisBot's low-level control networks; 2) Investigate the correlation between descending commands and behavior and use the results to develop a simplified brain (i.e. high-level controller) for MantisBot; and 3) Investigate the effect of conflicting visual inputs (e.g. simultaneous prey and predator) on descending commands, and use these findings to endow MantisBot with robust intelligence distributed throughout its SNS."
"1706761","Neurophotonic strategies for cell-resolved, non-invasive brain machine interfaces: multicolor bioluminescence delivered by gene therapy","CBET","BioP-Biophotonics","07/15/2017","07/13/2017","Nozomi Nishimura","NY","Cornell University","Standard Grant","Leon Esterowitz","06/30/2021","$583,210.00","Chris Schaffer","nn62@cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","ENG","7236","8089, 8091","$0.00","Brain-machine interfaces (BMIs) have the potential to enhance quality of life by restoring functions lost to neurological disease. However, current minimally-invasive BMIs (e.g. cortical surface electrodes) do not provide enough information for complex control. BMIs that yield high information content (e.g. implanted electrode arrays) damage brain tissue, limiting their lifespan. This project will develop a next-generation BMI that uses light instead of electricity, is less invasive and longer-lasting than implanted electrode arrays, and is capable of high information-content recording. This proposal will enhance teaching materials and summer programs with strong emphasis on recruitment of UMR students (and those who did not have real lab research experience). This could positively influence more students and attract them to multidisciplinary sciences or STEM programs in general.<br/><br/>The project will virally express calcium-sensitive bioluminescent proteins in neurons, so light is emitted with neural activity. To distinguish different neurons, multiple colors of such sensors are stochastically expressed, so each neuron contains different amounts of each color of the bioluminescent sensor, yielding a unique spectral signature. To monitor neural activity, the wavelength and intensity of emitted light is detected as a function of time. These data are processed to yield information on the activity of a large ensemble of individual neurons. This approach could provide a path to a long-term, robust, and high-fidelity BMI."
"1919851","Collaborative Research: Measuring and Enhancing Scientific Creative Thinking for STEM Education and Research: Classroom-Aligned Assessment and Network Neuroscience-Based Mechanisms","DRL","ECR-EHR Core Research","09/01/2019","08/01/2019","Mariale Hardiman","MD","Johns Hopkins University","Standard Grant","Gregg Solomon","08/31/2022","$86,720.00","","mmhardiman@jhu.edu","1101 E 33rd St","Baltimore","MD","212182686","4439971898","EHR","7980","7261, 8089, 8091, 8817","$0.00","This collaborative award to research teams at Pennsylvania State University, Georgetown University, and Johns Hopkins University will focus on creative thinking in STEM education and research.  Creative thinking is critical for success in STEM fields, which often require generating novel hypotheses, flexibly connecting diverse information, and envisioning solutions to ill-defined problems. Creative innovation is a valuable attribute of the U.S. workforce in the global economy, and the ability to maximize the nation's creative potential is projected to become even more essential for opportunity as creativity emerges as the human ability least achievable by artificial intelligence. The increasing value of creative thinking for STEM coincides with new applications of neuroscience methods that have the potential to predict, and perhaps even to enhance, creativity. Yet creativity is an under-researched contributor to STEM success. Indeed, there is not currently a measure of scientific creative thinking that educators can use to reliably determine what works (and what does not) in STEM education to foster creative thinking. This project will bring together a research team that represents an uncommon bridging of neuroscience and classroom-focused expertise. They will work with middle school and university educators to develop a new measure of scientific creative thinking and to use new neuroscientific tools to test whether a brain network that predicts an individual's general capacity for creative thinking can also predict their ability to think creatively with scientific content beyond what can be explained by their baseline cognitive ability. By testing whether neural data add value to traditional academic measures in predicting students' future creative thinking and STEM performance, this project will inform timely debates on the value of neuroscience for education. This work will also bridge the laboratory and the classroom in novel ways by longitudinally measuring change in brain network strength associated with of real-world STEM learning. By providing foundational knowledge on the nature and measurement of scientific creative thinking, the project will inform educational efforts to promote creative thinking in the classroom. This project will have additional impacts for broadening participation in STEM Fields by working with teachers of minority student populations underrepresented in STEM fields to optimize classroom usability for a test of scientific creative thinking. The project is funded by the EHR Core Research (ECR) program, which supports work that advances the fundamental research literature on STEM learning. The project directly fits the intent of ECR to facilitate the development, refinement, and testing of new education research, measurement, and evaluation methodologies.<br/><br/><br/>This project aims to provide foundational knowledge on the cognitive and neural basis of scientific creative thinking. To this end, we will collaborate with educators to develop and psychometrically validate a new test of scientific creative thinking, assessing students' ability to generate novel hypotheses, research questions, and experimental designs. We will also leverage developments in the network neuroscience of domain-general creativity, including the recent discovery of a specific network of brain regions in which functional connectivity strength can predict an individual's creative performance. Specifically, the project will 1) construct a new assessment of scientific creative thinking, incorporating classroom-usability (working with STEM teachers in urban Baltimore) and expanded psychometric scale development, and 2) use functional magnetic resonance imaging (fMRI) to extend our recent findings on the functional brain networks that support domain-general creativity to identify neural overlap/distinctness between domain-general and scientific creativity, and longitudinally to test whether strength of neural networks adds value to standard academic measures (e.g., grades) in predicting future creative thinking and STEM performance. This study will also provide the first large-scale analysis of cognitive and affective traits that support scientific creative thinking in STEM undergraduates, as well as preliminary data on whether network neuroscience methods developed in the lab can be used to measure neural strengthening of creative thinking ability through real-world STEM learning.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1910526","CHS: Small: Enhancing EEG-based Emotion Estimation  with Transfer Learning, Priming, and Virtual Reality","IIS","NSF 2026 Fund, HCC-Human-Centered Computing, IntgStrat Undst Neurl&Cogn Sys","10/01/2019","09/03/2019","David Thompson","KS","Kansas State University","Standard Grant","Ephraim Glinert","09/30/2022","$499,973.00","","Davet@ksu.edu","2 FAIRCHILD HALL","Manhattan","KS","665061100","7855326804","CSE","081Y, 7367, 8624","7367, 7923, 8089, 8091, 9150","$0.00","Emotions influence the decisions we make every day. However, emotions are difficult to measure. Surveys, the traditional method of emotion measurement, take significant time and cause interruptions. Further, people do not always know their own emotions -- think of the times when a person has shouted, ""I'm not shouting!""  Direct emotion-measuring systems, based on sensors worn on the body or head, have shown promise but are not yet ready to compete with surveys. This project includes several new techniques designed to increase the reliability and performance of these systems.  The project will lay the groundwork for wearable devices that can be used outside the laboratory, in environments as varied as classrooms and theme parks. From there, this research could lead to the development of human-computer systems which adjust in real-time to maintain a person's interest. Such systems would be valuable for all levels of education, as well as entertainment and other fields.  During the project, women and members of underrepresented minorities will participate, both as researchers and as research participants. <br/><br/>This project is one of the first to combine emotion-estimating Brain-Computer Interfaces (BCIs) with three methods: transfer learning, emotion priming, and virtual reality. Transfer learning is expected to help BCI systems detect real emotions rather than setting-specific brain responses. Transfer learning techniques will be applied to data from different emotion elicitation paradigms to study how well training data from standard methods can be expected to work in new environments. An alternative training technique from psychology called ""emotion priming"" will be used, and the effects on transfer learning will be studied. Emotion priming is expected to increase the accuracy of emotion elicitation, increasing the quality of training data and thus system performance. Virtual reality will be used to manipulate the participants' arousal states through a larger range than is possible through pictures and videos, in order to generate more transferable results. Together, these investigations are expected to dramatically improve the performance and, critically, the cross-task reliability of these systems. Because the study of emotion impacts nearly every field of human study, the development of a system for real-time measurement of valid emotions has the potential to advance cross-disciplinary transformation. Overall, these tests will fill a knowledge gap in the scientific literature, and inform how future general-purpose emotion estimation systems are trained. In addition, the project will provide shared data that may lead to even greater advancements in the BCI field when used by future researchers.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1561217","Collaborative Research: Foundations of Quantitative Thought: Number, Space, Time, and Probability","DRL","ECR-EHR Core Research","07/01/2016","06/13/2019","Sara Cordes","MA","Boston College","Standard Grant","Gregg Solomon","06/30/2021","$177,496.00","","sara.cordes@bc.edu","140 Commonwealth Avenue","Chestnut Hill","MA","024673800","6175528000","EHR","7980","8089, 8091, 8817","$0.00","Humans have an innate ability to estimate quantities yet their intuitions often contain biases that interfere with learning new ways to think about quantity. Weaving together strands of psychology, neuroscience, economics, and education, researchers at Wesleyan University and Boston College shed light on the cognitive processes underlying our abilities to estimate 4 kinds of quantities: number, space, time, and probability. By comparing processes across these four distinct areas, the researchers aim to provide a unifying account of how children and adults estimate quantities, which has the potential to transform current understanding of the cognitive bases of how people learn in and across STEM disciplines. Achieving a simple unifying account is important because the ability to think well about quantity in all of these areas is fundamental to STEM learning. Other educational benefits include the establishment of partnerships with local museums that allow the research team to collect data from a diverse population while also supporting the museum's public education efforts. This project also contributes to STEM workforce development by training undergraduate students through a service-learning course offered at Wesleyan, and through a summer research internship exchange across the two universities. These aspects of the project, taken with its robust theoretical grounding, well-formulated research questions and tests of competing models of how people reason about quantity in childhood and adulthood, demonstrate its potential to guide and improve the design of STEM learning environments for all citizens.<br/><br/>This project exemplifies the Education and Human Resources Core Research program's commitment to fundamental research on learning in STEM that combines theory, techniques, and perspectives from a wide range of disciplines and contexts.  Specifically, it aims to provide a unifying account of how children and adults estimate quantities across four distinct domains: the development of numerical estimation; spatial categorization (remembering the location of items in space); the theoretical neuroscience of time processing (reproducing temporal durations); and decision making under risk (the processing of probabilities). Through a series of behavioral studies with adults and children, the researchers will test their hypothesis that proportion judgment underlies basic quantity estimation across these domains, across development, and across contexts (varying task constraints). This work is important because -- despite striking similarities in behaviors described across research in these literatures -- each one conceptualizes them quite differently, positing different accounts of the underlying mechanisms that yield quantity judgments. The project will advance and potentially transform our understanding of mental representations and processes involved in quantity judgments while also providing insight into how quantity biases may influence the processing of numerical information in educational contexts and real-life decisions. In this way the project builds a coherent, cumulative knowledge base, focusing on high-leverage topics."
"1811723","Large-Scale Behavior of Interacting Particle Systems","DMS","PROBABILITY","07/01/2018","05/25/2020","Mykhaylo Shkolnikov","NJ","Princeton University","Continuing Grant","Tomek Bartoszynski","06/30/2021","$210,000.00","","mykhaylo@princeton.edu","Off. of Research & Proj. Admin.","Princeton","NJ","085442020","6092583090","MPS","1263","8089, 8091","$0.00","Interacting particle systems form a mathematical framework for systems with interacting components that arise in a variety of fields in science and engineering. Examples include, among many others, financial institutions interacting with each other via borrowing and lending, synchronization of neurons in the brain via electrical signals, and physical particles interacting through the (e.g. electromagnetic) potential they themselves generate. In many situations, the systems involved are large, e.g. the number of neurons in a given part of the human brain is on the order of a million. The goal of the project is to advance the quantitative understanding of such large interacting particle systems, relying on stochastic and deterministic partial differential equations. <br/><br/>The project will tackle equations describing the large scale behavior of interacting particle systems and the blowups arising thereby. More specifically, blowups in Stefan problems for parabolic partial differential equations governing the limiting particle density in particle systems interacting through the hitting times will be investigated by a combination of probabilistic and analytic techniques. In particular, the exact timing of blowups will be determined, and the existence and uniqueness of a suitable solution will be established beyond the time of the first blowup. In addition, Gaussian approximations for the hitting times in interacting particle systems will be derived using the limiting stochastic partial differential equations. Finally, solutions to the latter arising from interacting particle systems will be shown to coincide with the entropy solutions arising naturally in the analysis of partial differential equations.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
